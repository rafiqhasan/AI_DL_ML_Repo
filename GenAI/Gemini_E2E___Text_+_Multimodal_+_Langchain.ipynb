{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quaLl3PXpEWf"
      },
      "source": [
        "# Vertex SDK LLM Usage\n",
        "\n",
        "**Comprehensive Tutorial for using Vertex GenAI SDK for Gemini**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhZ9jqg5qu1p"
      },
      "source": [
        "# Authenticating"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E4pQ6E_xpfmp"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth as google_auth\n",
        "google_auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eb6Pw6rNqrdx"
      },
      "source": [
        "# Installing the package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NQ6SdFxji8ks",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "152b9f91-d76f-488b-d762-8af9f3faf251"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-cloud-aiplatform in /usr/local/lib/python3.10/dist-packages (1.46.0)\n",
            "Requirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.11.1)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.27.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (1.23.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (3.20.3)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (24.0)\n",
            "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.8.0)\n",
            "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (3.12.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (1.12.3)\n",
            "Requirement already satisfied: shapely<3.0.0dev in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.0.3)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.6.4)\n",
            "Requirement already satisfied: docstring-parser<1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (0.16)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.63.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2.31.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.62.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.48.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (4.9)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.3.3)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.7.0)\n",
            "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.8.2)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform) (0.13.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3->google-cloud-aiplatform) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3->google-cloud-aiplatform) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3->google-cloud-aiplatform) (4.10.0)\n",
            "Requirement already satisfied: numpy<2,>=1.14 in /usr/local/lib/python3.10/dist-packages (from shapely<3.0.0dev->google-cloud-aiplatform) (1.25.2)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.5.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0dev,>=2.7.2->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2024.2.2)\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.1.14-py3-none-any.whl (812 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m812.8/812.8 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core\n",
            "  Downloading langchain_core-0.1.40-py3-none-any.whl (276 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m276.8/276.8 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-google-vertexai\n",
            "  Downloading langchain_google_vertexai-0.1.2-py3-none-any.whl (47 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.8/47.8 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.30 (from langchain)\n",
            "  Downloading langchain_community-0.0.31-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.40-py3-none-any.whl (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.6.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Collecting packaging<24.0,>=23.2 (from langchain-core)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-cloud-aiplatform<2.0.0,>=1.44.0 in /usr/local/lib/python3.10/dist-packages (from langchain-google-vertexai) (1.46.0)\n",
            "Collecting google-cloud-storage<3.0.0,>=2.14.0 (from langchain-google-vertexai)\n",
            "  Downloading google_cloud_storage-2.16.0-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.6/125.6 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting types-protobuf<5.0.0.0,>=4.24.0.4 (from langchain-google-vertexai)\n",
            "  Downloading types_protobuf-4.24.0.20240311-py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.9/61.9 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting types-requests<3.0.0,>=2.31.0 (from langchain-google-vertexai)\n",
            "  Downloading types_requests-2.31.0.20240403-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.44.0->langchain-google-vertexai) (2.11.1)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.44.0->langchain-google-vertexai) (2.27.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.44.0->langchain-google-vertexai) (1.23.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.44.0->langchain-google-vertexai) (3.20.3)\n",
            "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.44.0->langchain-google-vertexai) (3.12.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.44.0->langchain-google-vertexai) (1.12.3)\n",
            "Requirement already satisfied: shapely<3.0.0dev in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.44.0->langchain-google-vertexai) (2.0.3)\n",
            "Requirement already satisfied: docstring-parser<1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.44.0->langchain-google-vertexai) (0.16)\n",
            "Collecting google-api-core<3.0.0dev,>=2.15.0 (from google-cloud-storage<3.0.0,>=2.14.0->langchain-google-vertexai)\n",
            "  Downloading google_api_core-2.18.0-py3-none-any.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.3/138.3 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage<3.0.0,>=2.14.0->langchain-google-vertexai) (2.3.3)\n",
            "Requirement already satisfied: google-resumable-media>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage<3.0.0,>=2.14.0->langchain-google-vertexai) (2.7.0)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage<3.0.0,>=2.14.0->langchain-google-vertexai) (1.5.0)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.8/144.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage<3.0.0,>=2.14.0->langchain-google-vertexai) (1.63.0)\n",
            "INFO: pip is looking at multiple versions of google-api-core[grpc] to determine which version is compatible with other requirements. This could take a while.\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage<3.0.0,>=2.14.0->langchain-google-vertexai) (1.62.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage<3.0.0,>=2.14.0->langchain-google-vertexai) (1.48.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.44.0->langchain-google-vertexai) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.44.0->langchain-google-vertexai) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.44.0->langchain-google-vertexai) (4.9)\n",
            "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.44.0->langchain-google-vertexai) (2.8.2)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform<2.0.0,>=1.44.0->langchain-google-vertexai) (0.13.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.44.0->langchain-google-vertexai) (0.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0dev,>=2.7.2->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.44.0->langchain-google-vertexai) (1.16.0)\n",
            "Installing collected packages: types-requests, types-protobuf, packaging, orjson, mypy-extensions, jsonpointer, typing-inspect, marshmallow, jsonpatch, langsmith, google-api-core, dataclasses-json, langchain-core, langchain-text-splitters, langchain-community, google-cloud-storage, langchain, langchain-google-vertexai\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "  Attempting uninstall: google-api-core\n",
            "    Found existing installation: google-api-core 2.11.1\n",
            "    Uninstalling google-api-core-2.11.1:\n",
            "      Successfully uninstalled google-api-core-2.11.1\n",
            "  Attempting uninstall: google-cloud-storage\n",
            "    Found existing installation: google-cloud-storage 2.8.0\n",
            "    Uninstalling google-cloud-storage-2.8.0:\n",
            "      Successfully uninstalled google-cloud-storage-2.8.0\n",
            "Successfully installed dataclasses-json-0.6.4 google-api-core-2.18.0 google-cloud-storage-2.16.0 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.14 langchain-community-0.0.31 langchain-core-0.1.40 langchain-google-vertexai-0.1.2 langchain-text-splitters-0.0.1 langsmith-0.1.40 marshmallow-3.21.1 mypy-extensions-1.0.0 orjson-3.10.0 packaging-23.2 types-protobuf-4.24.0.20240311 types-requests-2.31.0.20240403 typing-inspect-0.9.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "bc9d9ae629374f8cb8e1510c94072afe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.25.2)\n",
            "Installing collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.8.0\n"
          ]
        }
      ],
      "source": [
        "!pip install google-cloud-aiplatform --upgrade --user\n",
        "!pip install langchain langchain-core langchain-google-vertexai\n",
        "!pip install faiss-cpu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTVPxOKh1l-i"
      },
      "source": [
        "#### ! ^^^^ Do not forget to click the \"Restart runtime\" button above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pN1p1xEqp4fI"
      },
      "source": [
        "# Authenticating again"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hD8yqHHv1k3R"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth as google_auth\n",
        "google_auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "V_lJmgNRrQz4"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = \"<YOUR PROJECT ID>\"  # @param {type:\"string\"}\n",
        "LOCATION = \"us-central1\"  # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "oiraqRwdooE0"
      },
      "outputs": [],
      "source": [
        "from google.cloud import aiplatform\n",
        "# from vertexai.preview.language_models import TextGenerationModel, ChatModel\n",
        "from vertexai.generative_models import GenerativeModel, Part, ChatSession, Image, FunctionDeclaration, Tool, Content\n",
        "from langchain_google_vertexai import VertexAI\n",
        "import http.client\n",
        "import typing\n",
        "import urllib.request\n",
        "\n",
        "from google.cloud import aiplatform, storage\n",
        "from vertexai.preview.language_models import TextGenerationModel, ChatModel, TextEmbeddingModel\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "import pprint\n",
        "import re\n",
        "import io\n",
        "\n",
        "from langchain.llms import VertexAI\n",
        "from langchain import hub\n",
        "from langchain.text_splitter import TextSplitter, CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
        "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.document_loaders import TextLoader, GCSFileLoader\n",
        "from langchain.embeddings import VertexAIEmbeddings\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "from langchain.chains.mapreduce import MapReduceChain\n",
        "from langchain.chains import ReduceDocumentsChain, MapReduceDocumentsChain\n",
        "from langchain.chains.llm import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "aiplatform.init(project=PROJECT_ID, location=LOCATION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCriCYpOjZv0"
      },
      "source": [
        "# Text generation ( no stream )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import aiplatform\n",
        "# from vertexai.preview.language_models import TextGenerationModel, ChatModel\n",
        "from vertexai.generative_models import GenerativeModel, Part, ChatSession, Image, FunctionDeclaration, Tool, Content\n",
        "\n",
        "aiplatform.init(project=PROJECT_ID, location=LOCATION)"
      ],
      "metadata": {
        "id": "3Q5jgvAPpQlS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "fkAkKn-ijJR5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113
        },
        "outputId": "ec241776-2a84-45f8-a20f-2ac815c2808b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'**Origin and Evolution:**\\n\\n* The universe is estimated to be 13.8 billion years old.\\n* It originated from a singularity, an infinitely dense and hot point.\\n* It expanded rapidly in the Big Bang, forming the first atoms and galaxies.\\n* Over time, galaxies clustered together to form larger structures, such as superclusters and filaments.\\n\\n**Structure and Composition:**\\n\\n* The universe is vast and mostly empty space.\\n* It is composed of approximately 68% dark energy, 27% dark matter, and 5% ordinary matter.\\n* Dark energy is a mysterious force that causes the expansion of the universe to accelerate.\\n* Dark matter is an invisible substance that interacts only through gravity.\\n* Ordinary matter includes stars, planets, galaxies, and all living things.\\n\\n**Galaxies:**\\n\\n* Galaxies are vast collections of stars, gas, and dust.\\n* They come in various shapes and sizes, including spirals, ellipticals, and irregulars.\\n* Our galaxy, the Milky Way, is a spiral galaxy with an estimated 100-400 billion stars.\\n\\n**Stars:**\\n\\n* Stars are massive, self-luminous balls of plasma.\\n* They generate energy through nuclear fusion in their cores.\\n* Stars vary in size, temperature, and lifespan.\\n* The Sun is a medium-sized star that provides light and heat to Earth.\\n\\n**Planets:**\\n\\n* Planets are celestial bodies that orbit stars.\\n* They are not self-luminous and reflect light from their parent stars.\\n* Planets can be rocky, gaseous, or icy.\\n* Earth is the only known planet in the universe that supports life.\\n\\n**Other Celestial Objects:**\\n\\n* Moons: Natural satellites that orbit planets.\\n* Asteroids: Small, rocky bodies that orbit the Sun.\\n* Comets: Icy bodies that release gas and dust as they approach the Sun.\\n* Black holes: Regions of spacetime with such intense gravity that nothing, not even light, can escape.\\n\\n**Expansion and Fate:**\\n\\n* The universe is expanding at an accelerating rate.\\n* The ultimate fate of the universe is uncertain, but it could end in a \"Big Freeze\" or a \"Big Crunch.\"\\n\\n**Exploration and Research:**\\n\\n* Humans have explored the universe through telescopes, space probes, and manned missions.\\n* Ongoing research aims to understand the origin, evolution, and composition of the universe.\\n* The study of the universe is known as cosmology.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "model = GenerativeModel(\"gemini-1.0-pro\")\n",
        "\n",
        "response = model.generate_content(\n",
        "    \"What do you know about the universe?\",\n",
        "    # Optional:\n",
        "    generation_config={\n",
        "        'temperature': 0,\n",
        "        'top_p': 0,\n",
        "        'max_output_tokens': 1000\n",
        "    }\n",
        ")\n",
        "\n",
        "response.text"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text generation ( streaming )"
      ],
      "metadata": {
        "id": "jP8rjqAp4rGj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = GenerativeModel(\"gemini-1.0-pro\")\n",
        "\n",
        "response = model.generate_content(\n",
        "    \"What do you know about the universe?\",\n",
        "    stream = True,\n",
        "    # Optional:\n",
        "    generation_config={\n",
        "        'temperature': 0,\n",
        "        'max_output_tokens': 1000\n",
        "    }\n",
        ")\n",
        "\n",
        "for resp in response:\n",
        "  print(resp.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7v19XJg042r5",
        "outputId": "83ccfa86-93ac-44d3-903b-25a775befa0c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Origin and Evolution\n",
            ":**\n",
            "\n",
            "* The universe is estimated to be 13.8 billion years old.\n",
            "* It originated from a singularity, an infinitely dense and hot point.\n",
            "\n",
            "* It expanded rapidly in the Big Bang, forming the first atoms and galaxies.\n",
            "* Over time, galaxies clustered together to form larger structures, such as\n",
            " superclusters and filaments.\n",
            "\n",
            "**Structure and Composition:**\n",
            "\n",
            "* The universe is vast and mostly empty space.\n",
            "* It is composed of approximately 68% dark energy, 27% dark matter, and 5% ordinary matter.\n",
            "* Dark energy is a mysterious force that\n",
            " causes the expansion of the universe to accelerate.\n",
            "* Dark matter is an invisible substance that interacts only through gravity.\n",
            "* Ordinary matter includes stars, planets, galaxies, and all living things.\n",
            "\n",
            "**Galaxies:**\n",
            "\n",
            "* Galaxies are vast collections\n",
            " of stars, gas, and dust.\n",
            "* They come in various shapes and sizes, including spirals, ellipticals, and irregulars.\n",
            "* Our galaxy, the Milky Way, is a spiral galaxy with an estimated 100-400 billion stars.\n",
            "\n",
            "**Stars:**\n",
            "\n",
            "* Stars are massive, self-luminous balls of plasma.\n",
            "* They generate energy through nuclear fusion\n",
            " in their cores.\n",
            "* Stars vary in size, temperature, and lifespan.\n",
            "* The Sun is a medium-sized star that provides light and heat to Earth.\n",
            "\n",
            "**Planets:**\n",
            "\n",
            "* Planets are celestial bodies that orbit stars.\n",
            "* They are typically smaller and less massive than stars.\n",
            "* Planets can be rocky, gaseous, or icy.\n",
            "* Earth is the only known planet in\n",
            " the universe that supports life.\n",
            "\n",
            "**Other Celestial Objects:**\n",
            "\n",
            "* Moons: Natural satellites that orbit planets.\n",
            "* Asteroids: Small, rocky bodies that orbit the Sun.\n",
            "* Comets: Icy bodies that release gas and dust as they approach the Sun.\n",
            "* Black holes: Regions of spacetime with such intense gravity that nothing, not even light, can escape.\n",
            "\n",
            "**Expansion and Fate:**\n",
            "\n",
            "* The universe is expanding at an accelerating rate.\n",
            "* The ultimate fate of the universe is uncertain, but it\n",
            " could end in a \"Big Freeze\" or a \"Big Crunch.\"\n",
            "\n",
            "**Exploration and Research:**\n",
            "\n",
            "* Humans have explored the universe through telescopes, space probes, and manned missions.\n",
            "* Ongoing research aims to understand the origin, evolution, and composition of the universe.\n",
            "* The study of the universe is known as cosmology.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wl2AZceWjXoy"
      },
      "source": [
        "# Chat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_vLprtHAjNOO"
      },
      "outputs": [],
      "source": [
        "model = GenerativeModel(\"gemini-1.0-pro\")\n",
        "chat = model.start_chat()\n",
        "\n",
        "parameters = {\n",
        "    \"temperature\": 0.2,\n",
        "    \"max_output_tokens\": 256,\n",
        "    \"top_p\": 0.95,\n",
        "    \"top_k\": 40,\n",
        "    }\n",
        "\n",
        "def send_msg(msg):\n",
        "  return chat.send_message(msg, stream=False).text\n",
        "\n",
        "prompt = \"Hello my name is hasan\"\n",
        "send_msg(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "send_msg(\"so what is your name\")"
      ],
      "metadata": {
        "id": "ryxUcaL4uJ6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "send_msg(\"what can you do for me ?\")"
      ],
      "metadata": {
        "id": "1j3zYd8yyAVb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multimodal prompt\n",
        "\n",
        "Send images / files in prompt along with text"
      ],
      "metadata": {
        "id": "tmWzgmkUzgzU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create helper function\n",
        "def load_image_from_url(image_url: str) -> Image:\n",
        "    with urllib.request.urlopen(image_url) as response:\n",
        "        response = typing.cast(http.client.HTTPResponse, response)\n",
        "        image_bytes = response.read()\n",
        "    return Image.from_bytes(image_bytes)\n",
        "\n",
        "# Load images from Cloud Storage URI\n",
        "landmark1 = load_image_from_url(\n",
        "    \"https://storage.googleapis.com/cloud-samples-data/vertex-ai/llm/prompts/landmark1.png\"\n",
        ")\n",
        "landmark2 = load_image_from_url(\n",
        "    \"https://storage.googleapis.com/cloud-samples-data/vertex-ai/llm/prompts/landmark2.png\"\n",
        ")\n",
        "landmark3 = load_image_from_url(\n",
        "    \"https://storage.googleapis.com/cloud-samples-data/vertex-ai/llm/prompts/landmark3.png\"\n",
        ")"
      ],
      "metadata": {
        "id": "TXM72tWEtW_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pass multimodal prompt\n",
        "model = GenerativeModel(\"gemini-1.0-pro-vision\")\n",
        "response = model.generate_content(\n",
        "    [\n",
        "        landmark1,\n",
        "        \"city: Rome, Landmark: the Colosseum\",\n",
        "        landmark2,\n",
        "        \"city: Beijing, Landmark: Forbidden City\",\n",
        "        landmark3,\n",
        "    ]\n",
        ")\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "CHjN8tDz7q9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function calling\n",
        "\n",
        "Create a FC prompt for API calling\n",
        "- The model doesn't actually call the API\n",
        "- The model only parses text to return parameters to call an external API"
      ],
      "metadata": {
        "id": "Ss8WMxRsByM2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"What is the distance between Warsaw and Krakow\""
      ],
      "metadata": {
        "id": "Zb0sJNYWFV13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Gemini model\n",
        "model = GenerativeModel(\"gemini-1.0-pro\")\n",
        "\n",
        "# Specify a function declaration and parameters for an API request\n",
        "get_distance_details_func = FunctionDeclaration(\n",
        "    name=\"get_distance_between_locations\",\n",
        "    description=\"Get the route details from Google Maps and then calculate distance\",\n",
        "    # Function parameters are specified in OpenAPI JSON schema format\n",
        "    parameters={\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "                        \"src_location\": {\"type\": \"string\", \"description\": \"Source Location\"},\n",
        "                        \"tgt_location\": {\"type\": \"string\", \"description\": \"Target Location\"}\n",
        "                      },\n",
        "    },\n",
        ")\n",
        "\n",
        "# Define a tool that includes the above get_current_weather_func\n",
        "distance_tool = Tool(\n",
        "    function_declarations=[get_distance_details_func],\n",
        ")"
      ],
      "metadata": {
        "id": "L9KGywx8B9n0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the user's prompt in a Content object that we can reuse in model calls\n",
        "user_prompt_content = Content(\n",
        "    role=\"user\",\n",
        "    parts=[\n",
        "        Part.from_text(prompt),\n",
        "    ],\n",
        ")\n",
        "\n",
        "# Send the prompt and instruct the model to generate content using the Tool that you just created\n",
        "response = model.generate_content(\n",
        "    user_prompt_content,\n",
        "    generation_config={\"temperature\": 0},\n",
        "    tools=[distance_tool],\n",
        ")\n",
        "response_function_call_content = response.candidates[0].content"
      ],
      "metadata": {
        "id": "EqogzU9cDETK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parse response to get parameters parsed by model from the prompt\n",
        "src_location = response_function_call_content.parts[0].function_call.args[\"src_location\"]\n",
        "tgt_location = response_function_call_content.parts[0].function_call.args[\"tgt_location\"]\n",
        "\n",
        "src_location, tgt_location"
      ],
      "metadata": {
        "id": "tnlX2ZBiErXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Langchain integration\n",
        "\n",
        "Text: QnA over texts with Refine chain"
      ],
      "metadata": {
        "id": "pccFU4zicjyP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Gemini model\n",
        "model = VertexAI( max_output_tokens=2048, model=\"gemini-1.0-pro\", top_p = 1, temperature = 0)\n",
        "embeddings = VertexAIEmbeddings()\n",
        "\n",
        "def chunk_text(input_texts, separator=\"\", chunk_size=100, overlap=20):\n",
        "  ## Create split of texts on a chunk\n",
        "  text_splitter = CharacterTextSplitter(separator=\"\", chunk_size=chunk_size, chunk_overlap=overlap)\n",
        "  chunks = text_splitter.create_documents(input_texts)\n",
        "\n",
        "  return chunks\n",
        "\n",
        "def create_vector_store(chunks):\n",
        "  ## Create vector store from embeddings\n",
        "  db = FAISS.from_documents(chunks, embeddings)\n",
        "\n",
        "  return db\n",
        "\n",
        "# def query_vector_store(query, db, top_n_docs=5):\n",
        "#   docs = db.similarity_search(query, k=top_n_docs)\n",
        "\n",
        "#   return docs\n",
        "\n",
        "def query_vector_store(query, db, top_n_docs, multiquery):\n",
        "  if multiquery:\n",
        "    retriever_from_llm = MultiQueryRetriever.from_llm(\n",
        "      retriever=db.as_retriever(search_kwargs={\"k\": top_n_docs}), llm=model\n",
        "    )\n",
        "    docs = retriever_from_llm.get_relevant_documents(query=query)\n",
        "  else:\n",
        "    retriever = db.as_retriever(search_kwargs={\"k\": top_n_docs})\n",
        "    docs = retriever.get_relevant_documents(query)\n",
        "\n",
        "  return docs\n",
        "\n",
        "def create_with_refine(input_chunks, title):\n",
        "  prompt_template = \"\"\"Write a content with the following:\n",
        "  {text}\n",
        "  CONCISE SUMMARY:\"\"\"\n",
        "  prompt = PromptTemplate.from_template(prompt_template)\n",
        "\n",
        "  refine_template = (\n",
        "      \"\"\"\n",
        "      You are a QnA bot meant to answer questions ONLY from the contexts provided below and NO PRIOR knowledge\n",
        "\n",
        "      Question:\n",
        "      -----------\n",
        "      {query}\n",
        "      -----------\n",
        "\n",
        "      We have provided a response version of the response up to a certain point: {existing_answer}\n",
        "      You have the opportunity to refine the existing response response with below contexts\n",
        "      (only if needed) with some more context as specified below.\n",
        "\n",
        "      Rules:\n",
        "      ------------\n",
        "      Given the new context and the query, refine the response further as necessary for answering the query but\n",
        "      never include the context as is in the response, you should ONLY and ONLY use the knowledge provided in contexts.\n",
        "      DONT add any information which is not present in contexts.\n",
        "      Make sure that the content is always relevant to the original query.\n",
        "      If the context provided isn't useful, dont make any change to the response, just return the current response.\n",
        "      ------------\n",
        "\n",
        "      Context:\n",
        "      ------------\n",
        "      {text}\n",
        "      ------------\n",
        "      \"\"\"\n",
        "  ).replace('{query}', title)\n",
        "\n",
        "  refine_prompt = PromptTemplate.from_template(refine_template)\n",
        "  chain = load_summarize_chain(\n",
        "      llm=model,\n",
        "      chain_type=\"refine\",\n",
        "      question_prompt=prompt,\n",
        "      refine_prompt=refine_prompt,\n",
        "      return_intermediate_steps=True,\n",
        "      input_key=\"input_documents\",\n",
        "      output_key=\"output_text\"\n",
        "  )\n",
        "  result = chain({\"input_documents\": input_chunks}, return_only_outputs=True)\n",
        "\n",
        "  return result['intermediate_steps'], result['output_text']\n",
        "\n",
        "def run_query(query, db, top_n_docs=5, multiquery=False):\n",
        "  docs = query_vector_store(query, db, top_n_docs, multiquery)\n",
        "\n",
        "  ## Create article using top N docs\n",
        "  intermediate_steps, final_text = create_with_refine(docs, query)\n",
        "\n",
        "  return intermediate_steps, final_text"
      ],
      "metadata": {
        "id": "UE7d0ksuwNMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_n_docs = 15 # @param {type:\"integer\"} ## Number of similar chunks used to create content\n",
        "\n",
        "message = \"What are some of the pros and cons of Python as a programming language?\"\n",
        "model.invoke(message)"
      ],
      "metadata": {
        "id": "letWl0Ycc6uX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document = [\"\"\"\n",
        "Information retrieval using AI and LLMs\n",
        "Vertex AI Search brings together the power of deep information retrieval, state-of-the-art natural language processing, and the latest in large language model (LLM) processing to understand user intent and return the most relevant results for the user.\n",
        "\n",
        "With Vertex AI Search, you can build a Google-quality search app on your own data and embed a search bar in your web pages or app.\n",
        "\n",
        "With Recommendations, you can build a recommendations app on your own data that will suggest content similar to the content that the user is currently viewing.\n",
        "\n",
        "Note: The generic recommendations feature is a Preview offering, subject to the \"Pre-GA Offerings Terms\" of the GCP Service Specific Terms. Pre-GA products and features may have limited support, and changes to pre-GA products and features may not be compatible with other pre-GA versions. For more information, see the launch stage descriptions. Further, by using this feature, you agree to the Generative AI Preview terms and conditions (\"Preview Terms\"). For this feature, you can process personal data as outlined in the Cloud Data Processing Addendum, subject to applicable restrictions and obligations in the Agreement (as defined in the Preview Terms).\n",
        "An easy experience to get started\n",
        "Vertex AI Search makes it easy to get started with high-quality search or recommendations based on data that you provide. As part of the setup experience, you can:\n",
        "\n",
        "Use your existing Google Account or sign up for one.\n",
        "Use your existing Google Cloud project or create one.\n",
        "Create an app and attach a data store to it. Provide data to search or recommend by entering the URLs for your website content, importing your data from BigQuery or Cloud Storage, or importing FHIR R4 data from Cloud Healthcare API, or uploading through RESTful CRUD APIs. Syncing data from Jira, Salesforce, or Confluence is available in Preview with allowlist.\n",
        "Embed JavaScript widgets and API samples to integrate search or recommendations into your website or applications.\n",
        "Data stores and apps\n",
        "With Vertex AI Search, you create a search or recommendations app and attach it to a data store. You import your data into a data store and index your data. Apps and data stores have a one-to-one relationship.\n",
        "\n",
        "There are various kinds of data stores that you can create, based on the type of data you use. Each data store can contain one type of data:\n",
        "\n",
        "Website data: You can provide domains such as yourexamplewebsite.com/faq and yourexamplewebsite.com/events and enable search or recommendations over the content at those domains.\n",
        "Structured data: A data store with structured data enables semantic search or recommendations over structured data such as a BigQuery table or NDJSON files. For example, you can enable search or recommendations over a product catalog for your ecommerce experience, a movie catalog for movie search or recommendations, or a directory of doctors for provider search or recommendations.\n",
        "Unstructured data: An unstructured data store enables semantic search or recommendations over data such as documents and images. For example, a financial institution can enable search or recommendations over their private corpus of financial research publications, or a biotech company can enable search or recommendations over their private repository of medical research.\n",
        "Healthcare data: A healthcare data store enables semantic search over healthcare FHIR R4 data imported from Cloud Healthcare API. For example, a healthcare provider can search over a patient's clinical history using exploratory queries.\n",
        "\"\"\"]"
      ],
      "metadata": {
        "id": "xvex1MYGdiaq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Create chunks from array of texts\n",
        "separator = \" \"\n",
        "chunks = chunk_text(document, separator, chunk_size=150, overlap=20)\n",
        "len(chunks)"
      ],
      "metadata": {
        "id": "CvSesAClyQPl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Create vector store from chunks\n",
        "db = create_vector_store(chunks)"
      ],
      "metadata": {
        "id": "I2gnA1rezvET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What type of data can data stores contain in Vertex AI Search ? Give an elaborated answer\" # @param {type:\"string\"} ## Query\n",
        "\n",
        "## Create response using top N docs\n",
        "intermediate_steps, final_text = run_query(query, db, top_n_docs, multiquery=False)\n",
        "\n",
        "print(final_text)"
      ],
      "metadata": {
        "id": "y0x8bClU18hk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# query = \"What type of data can data stores contain in Vertex AI Search ? Give an elaborated answer\" # @param {type:\"string\"} ## Query\n",
        "\n",
        "# ## Create response using top N docs\n",
        "# intermediate_steps, final_text = run_query(query, db, top_n_docs, multiquery=True)\n",
        "\n",
        "# print(final_text)"
      ],
      "metadata": {
        "id": "QWrKWQNSfGpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What does Vertex search support in terms of Healthcare data ?\" # @param {type:\"string\"} ## Query\n",
        "\n",
        "## Create response using top N docs\n",
        "intermediate_steps, final_text = run_query(query, db, top_n_docs)\n",
        "\n",
        "print(final_text)"
      ],
      "metadata": {
        "id": "3hopZZBS7w3_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Which all services are currently in preview in Vertex Search ?\" # @param {type:\"string\"} ## Query\n",
        "\n",
        "## Create response using top N docs\n",
        "intermediate_steps, final_text = run_query(query, db, top_n_docs)\n",
        "\n",
        "print(final_text)"
      ],
      "metadata": {
        "id": "rnmlDm-2BQGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Langchain integration\n",
        "\n",
        "Text: **Summarize** texts with Refine chain"
      ],
      "metadata": {
        "id": "xFohwmlNuwUZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Gemini model\n",
        "model = VertexAI( max_output_tokens=2048, model=\"gemini-1.0-pro\", top_p = 1, temperature = 0)\n",
        "embeddings = VertexAIEmbeddings()\n",
        "\n",
        "def chunk_text(input_texts, separator=\"\", chunk_size=100, overlap=20):\n",
        "  ## Create split of texts on a chunk\n",
        "  text_splitter = CharacterTextSplitter(separator=\"\", chunk_size=chunk_size, chunk_overlap=overlap)\n",
        "  chunks = text_splitter.create_documents(input_texts)\n",
        "\n",
        "  return chunks\n",
        "\n",
        "def summarize_with_refine(input_chunks):\n",
        "  prompt_template = \"\"\"Write a content with the following:\n",
        "  {text}\n",
        "  CONCISE SUMMARY:\"\"\"\n",
        "  prompt = PromptTemplate.from_template(prompt_template)\n",
        "\n",
        "  refine_template = \"\"\"\n",
        "  You are a Summarization bot meant to summarize the contexts provided below and NO PRIOR knowledge\n",
        "\n",
        "  We have provided a version of the summary up to a certain point: {existing_answer}\n",
        "  You have the opportunity to refine the existing summary with below contexts\n",
        "  with some more context as specified below.\n",
        "\n",
        "  Rules:\n",
        "  ------------\n",
        "  1. Given the new context, refine the summary further BUT never include the context as is in the response,\n",
        "  you should ONLY and ONLY use the knowledge provided in contexts.\n",
        "  2. DONT add any information which is not present in contexts.\n",
        "  3. Make sure that the content is always inline with the contexts and DONT ADD any information from your prior knowledge.\n",
        "  ------------\n",
        "\n",
        "  Context:\n",
        "  ------------\n",
        "  {text}\n",
        "  ------------\n",
        "  \"\"\"\n",
        "\n",
        "  refine_prompt = PromptTemplate.from_template(refine_template)\n",
        "  chain = load_summarize_chain(\n",
        "      llm=model,\n",
        "      chain_type=\"refine\",\n",
        "      question_prompt=prompt,\n",
        "      refine_prompt=refine_prompt,\n",
        "      return_intermediate_steps=True,\n",
        "      input_key=\"input_documents\",\n",
        "      output_key=\"output_text\"\n",
        "  )\n",
        "  result = chain({\"input_documents\": input_chunks}, return_only_outputs=True)\n",
        "\n",
        "  return result['intermediate_steps'], result['output_text']"
      ],
      "metadata": {
        "id": "wiIe1G8gwsZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document = [\"\"\"\n",
        "Information retrieval using AI and LLMs\n",
        "Vertex AI Search brings together the power of deep information retrieval, state-of-the-art natural language processing, and the latest in large language model (LLM) processing to understand user intent and return the most relevant results for the user.\n",
        "\n",
        "With Vertex AI Search, you can build a Google-quality search app on your own data and embed a search bar in your web pages or app.\n",
        "\n",
        "With Recommendations, you can build a recommendations app on your own data that will suggest content similar to the content that the user is currently viewing.\n",
        "\n",
        "Note: The generic recommendations feature is a Preview offering, subject to the \"Pre-GA Offerings Terms\" of the GCP Service Specific Terms. Pre-GA products and features may have limited support, and changes to pre-GA products and features may not be compatible with other pre-GA versions. For more information, see the launch stage descriptions. Further, by using this feature, you agree to the Generative AI Preview terms and conditions (\"Preview Terms\"). For this feature, you can process personal data as outlined in the Cloud Data Processing Addendum, subject to applicable restrictions and obligations in the Agreement (as defined in the Preview Terms).\n",
        "An easy experience to get started\n",
        "Vertex AI Search makes it easy to get started with high-quality search or recommendations based on data that you provide. As part of the setup experience, you can:\n",
        "\n",
        "Use your existing Google Account or sign up for one.\n",
        "Use your existing Google Cloud project or create one.\n",
        "Create an app and attach a data store to it. Provide data to search or recommend by entering the URLs for your website content, importing your data from BigQuery or Cloud Storage, or importing FHIR R4 data from Cloud Healthcare API, or uploading through RESTful CRUD APIs. Syncing data from Jira, Salesforce, or Confluence is available in Preview with allowlist.\n",
        "Embed JavaScript widgets and API samples to integrate search or recommendations into your website or applications.\n",
        "Data stores and apps\n",
        "With Vertex AI Search, you create a search or recommendations app and attach it to a data store. You import your data into a data store and index your data. Apps and data stores have a one-to-one relationship.\n",
        "\n",
        "There are various kinds of data stores that you can create, based on the type of data you use. Each data store can contain one type of data:\n",
        "\n",
        "Website data: You can provide domains such as yourexamplewebsite.com/faq and yourexamplewebsite.com/events and enable search or recommendations over the content at those domains.\n",
        "Structured data: A data store with structured data enables semantic search or recommendations over structured data such as a BigQuery table or NDJSON files. For example, you can enable search or recommendations over a product catalog for your ecommerce experience, a movie catalog for movie search or recommendations, or a directory of doctors for provider search or recommendations.\n",
        "Unstructured data: An unstructured data store enables semantic search or recommendations over data such as documents and images. For example, a financial institution can enable search or recommendations over their private corpus of financial research publications, or a biotech company can enable search or recommendations over their private repository of medical research.\n",
        "Healthcare data: A healthcare data store enables semantic search over healthcare FHIR R4 data imported from Cloud Healthcare API. For example, a healthcare provider can search over a patient's clinical history using exploratory queries.\n",
        "\"\"\"]"
      ],
      "metadata": {
        "id": "1i5qlDY_z3MA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Create chunks from array of texts\n",
        "separator = \" \"\n",
        "chunks = chunk_text(document, separator, chunk_size=1000, overlap=20)\n",
        "len(chunks)"
      ],
      "metadata": {
        "id": "rRibKlE2z7Gq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "intermediate_steps, summary = summarize_with_refine(chunks)"
      ],
      "metadata": {
        "id": "I-CY-sLD4aoh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary"
      ],
      "metadata": {
        "id": "G2b0tXiL4o_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X3yrVCZE5F7t"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}