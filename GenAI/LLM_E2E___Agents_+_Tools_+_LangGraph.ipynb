{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Goal:\n",
        "\n",
        "- Build notebook to do RAG + Tools\n",
        "- Try further with LangGraph\n",
        "\n",
        "By: Hasan Rafiq"
      ],
      "metadata": {
        "id": "QWJtdgwJ39wk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installing the package"
      ],
      "metadata": {
        "id": "T_pLQeNp36mA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-cloud-aiplatform --upgrade --user\n",
        "!pip install langchain langchain-core langchain-google-vertexai faiss-cpu ragas"
      ],
      "metadata": {
        "id": "XOPSCwGu38W7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e22227c2-412d-482a-a0cb-de15f8f34e79"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-cloud-aiplatform in /usr/local/lib/python3.10/dist-packages (1.46.0)\n",
            "Requirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.18.0)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.27.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (1.23.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (3.20.3)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (23.2)\n",
            "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.16.0)\n",
            "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (3.12.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (1.12.3)\n",
            "Requirement already satisfied: shapely<3.0.0dev in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.0.3)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.6.4)\n",
            "Requirement already satisfied: docstring-parser<1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (0.16)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.63.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2.31.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.62.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.48.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (4.9)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.3.3)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.7.0)\n",
            "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.8.2)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform) (0.13.0)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.5.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3->google-cloud-aiplatform) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3->google-cloud-aiplatform) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3->google-cloud-aiplatform) (4.10.0)\n",
            "Requirement already satisfied: numpy<2,>=1.14 in /usr/local/lib/python3.10/dist-packages (from shapely<3.0.0dev->google-cloud-aiplatform) (1.25.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0dev,>=2.7.2->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2024.2.2)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.1.14)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.10/dist-packages (0.1.40)\n",
            "Requirement already satisfied: langchain-google-vertexai in /usr/local/lib/python3.10/dist-packages (0.1.2)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (1.8.0)\n",
            "Requirement already satisfied: ragas in /usr/local/lib/python3.10/dist-packages (0.1.6)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.6.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.33)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.30 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.31)\n",
            "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.1)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.40)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.6.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (23.2)\n",
            "Requirement already satisfied: google-cloud-aiplatform<2.0.0,>=1.44.0 in /usr/local/lib/python3.10/dist-packages (from langchain-google-vertexai) (1.46.0)\n",
            "Requirement already satisfied: google-cloud-storage<3.0.0,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from langchain-google-vertexai) (2.16.0)\n",
            "Requirement already satisfied: types-protobuf<5.0.0.0,>=4.24.0.4 in /usr/local/lib/python3.10/dist-packages (from langchain-google-vertexai) (4.24.0.20240408)\n",
            "Requirement already satisfied: types-requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from langchain-google-vertexai) (2.31.0.20240406)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from ragas) (2.18.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from ragas) (0.6.0)\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.10/dist-packages (from ragas) (0.1.1)\n",
            "Requirement already satisfied: openai>1 in /usr/local/lib/python3.10/dist-packages (from ragas) (1.16.2)\n",
            "Requirement already satisfied: pysbd>=0.3.4 in /usr/local/lib/python3.10/dist-packages (from ragas) (0.3.4)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from ragas) (1.6.0)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.10/dist-packages (from ragas) (1.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.44.0->langchain-google-vertexai) (2.18.0)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.44.0->langchain-google-vertexai) (2.27.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.44.0->langchain-google-vertexai) (1.23.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.44.0->langchain-google-vertexai) (3.20.3)\n",
            "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.44.0->langchain-google-vertexai) (3.12.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.44.0->langchain-google-vertexai) (1.12.3)\n",
            "Requirement already satisfied: shapely<3.0.0dev in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.44.0->langchain-google-vertexai) (2.0.3)\n",
            "Requirement already satisfied: docstring-parser<1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.44.0->langchain-google-vertexai) (0.16)\n",
            "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage<3.0.0,>=2.14.0->langchain-google-vertexai) (2.3.3)\n",
            "Requirement already satisfied: google-resumable-media>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage<3.0.0,>=2.14.0->langchain-google-vertexai) (2.7.0)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage<3.0.0,>=2.14.0->langchain-google-vertexai) (1.5.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>1->ragas) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>1->ragas) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai>1->ragas) (0.27.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>1->ragas) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai>1->ragas) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai>1->ragas) (4.10.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.16.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets->ragas) (3.13.3)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->ragas) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->ragas) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->ragas) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->ragas) (2.0.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->ragas) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->ragas) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets->ragas) (2023.6.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets->ragas) (0.20.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->ragas) (2023.12.25)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>1->ragas) (1.2.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.44.0->langchain-google-vertexai) (1.63.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.44.0->langchain-google-vertexai) (1.62.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.44.0->langchain-google-vertexai) (1.48.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.44.0->langchain-google-vertexai) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.44.0->langchain-google-vertexai) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.44.0->langchain-google-vertexai) (4.9)\n",
            "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.44.0->langchain-google-vertexai) (2.8.2)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform<2.0.0,>=1.44.0->langchain-google-vertexai) (0.13.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai>1->ragas) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>1->ragas) (0.14.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->ragas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->ragas) (2024.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.44.0->langchain-google-vertexai) (0.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0dev,>=2.7.2->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.44.0->langchain-google-vertexai) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Authenticate again"
      ],
      "metadata": {
        "id": "SEg9gRnl4iz7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth as google_auth\n",
        "google_auth.authenticate_user()"
      ],
      "metadata": {
        "id": "xTOySbcM4gFp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PROJECT_ID = \"hasanrafiq-test-331814\"  # @param {type:\"string\"}\n",
        "LOCATION = \"us-central1\"  # @param {type:\"string\"}"
      ],
      "metadata": {
        "id": "cKcun6Kf4z2K"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import aiplatform\n",
        "# from vertexai.preview.language_models import TextGenerationModel, ChatModel\n",
        "from vertexai.generative_models import GenerativeModel, Part, ChatSession, Image, FunctionDeclaration, Tool, Content\n",
        "from langchain_google_vertexai import VertexAI\n",
        "import http.client\n",
        "import typing\n",
        "import urllib.request\n",
        "import pandas as pd\n",
        "\n",
        "from google.cloud import aiplatform, storage\n",
        "from vertexai.preview.language_models import TextGenerationModel, ChatModel, TextEmbeddingModel\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "import pprint\n",
        "import re\n",
        "import io\n",
        "\n",
        "from langchain.llms import VertexAI\n",
        "from langchain import hub\n",
        "from langchain.text_splitter import TextSplitter, CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
        "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.document_loaders import TextLoader, GCSFileLoader\n",
        "from langchain.embeddings import VertexAIEmbeddings\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "from langchain.chains.mapreduce import MapReduceChain\n",
        "from langchain.chains import ReduceDocumentsChain, MapReduceDocumentsChain\n",
        "from langchain.chains.llm import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.tools import tool\n",
        "\n",
        "from ragas.metrics import (\n",
        "    answer_relevancy,\n",
        "    faithfulness,\n",
        "    context_recall,\n",
        "    context_precision,\n",
        "    context_entity_recall,\n",
        "    answer_correctness\n",
        ")\n",
        "from datasets import Dataset\n",
        "from ragas import evaluate\n",
        "\n",
        "aiplatform.init(project=PROJECT_ID, location=LOCATION)"
      ],
      "metadata": {
        "id": "aJjzXsFY45oe"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implement a RAG"
      ],
      "metadata": {
        "id": "vnDIpgHX48ZH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Source text"
      ],
      "metadata": {
        "id": "w891IFzU4_Yt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "document = [\"\"\"\n",
        "Information retrieval using AI and LLMs\n",
        "Vertex AI Search brings together the power of deep information retrieval, state-of-the-art natural language processing, and the latest in large language model (LLM) processing to understand user intent and return the most relevant results for the user.\n",
        "\n",
        "With Vertex AI Search, you can build a Google-quality search app on your own data and embed a search bar in your web pages or app.\n",
        "\n",
        "With Recommendations, you can build a recommendations app on your own data that will suggest content similar to the content that the user is currently viewing.\n",
        "\n",
        "Note: The generic recommendations feature is a Preview offering, subject to the \"Pre-GA Offerings Terms\" of the GCP Service Specific Terms. Pre-GA products and features may have limited support, and changes to pre-GA products and features may not be compatible with other pre-GA versions. For more information, see the launch stage descriptions. Further, by using this feature, you agree to the Generative AI Preview terms and conditions (\"Preview Terms\"). For this feature, you can process personal data as outlined in the Cloud Data Processing Addendum, subject to applicable restrictions and obligations in the Agreement (as defined in the Preview Terms).\n",
        "An easy experience to get started\n",
        "Vertex AI Search makes it easy to get started with high-quality search or recommendations based on data that you provide. As part of the setup experience, you can:\n",
        "\n",
        "Use your existing Google Account or sign up for one.\n",
        "Use your existing Google Cloud project or create one.\n",
        "Create an app and attach a data store to it. Provide data to search or recommend by entering the URLs for your website content, importing your data from BigQuery or Cloud Storage, or importing FHIR R4 data from Cloud Healthcare API, or uploading through RESTful CRUD APIs. Syncing data from Jira, Salesforce, or Confluence is available in Preview with allowlist.\n",
        "Embed JavaScript widgets and API samples to integrate search or recommendations into your website or applications.\n",
        "Data stores and apps\n",
        "With Vertex AI Search, you create a search or recommendations app and attach it to a data store. You import your data into a data store and index your data. Apps and data stores have a one-to-one relationship.\n",
        "\n",
        "There are various kinds of data stores that you can create, based on the type of data you use. Each data store can contain one type of data:\n",
        "\n",
        "Website data: You can provide domains such as yourexamplewebsite.com/faq and yourexamplewebsite.com/events and enable search or recommendations over the content at those domains.\n",
        "Structured data: A data store with structured data enables semantic search or recommendations over structured data such as a BigQuery table or NDJSON files. For example, you can enable search or recommendations over a product catalog for your ecommerce experience, a movie catalog for movie search or recommendations, or a directory of doctors for provider search or recommendations.\n",
        "Unstructured data: An unstructured data store enables semantic search or recommendations over data such as documents and images. For example, a financial institution can enable search or recommendations over their private corpus of financial research publications, or a biotech company can enable search or recommendations over their private repository of medical research.\n",
        "Healthcare data: A healthcare data store enables semantic search over healthcare FHIR R4 data imported from Cloud Healthcare API. For example, a healthcare provider can search over a patient's clinical history using exploratory queries.\n",
        "\"\"\"]"
      ],
      "metadata": {
        "id": "1K5nNCjc47UQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create helper functions"
      ],
      "metadata": {
        "id": "z1itUHeG5Ibv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Gemini model\n",
        "model = VertexAI( max_output_tokens=2048, model=\"gemini-1.0-pro\", top_p = 1, temperature = 0)\n",
        "llm_embeddings = VertexAIEmbeddings()\n",
        "\n",
        "def chunk_text(input_texts, separator=\"\", chunk_size=100, overlap=20):\n",
        "  ## Create split of texts on a chunk\n",
        "  text_splitter = CharacterTextSplitter(separator=\"\", chunk_size=chunk_size, chunk_overlap=overlap)\n",
        "  chunks = text_splitter.create_documents(input_texts)\n",
        "\n",
        "  return chunks\n",
        "\n",
        "def create_vector_store(chunks):\n",
        "  ## Create vector store from embeddings\n",
        "  db = FAISS.from_documents(chunks, llm_embeddings)\n",
        "\n",
        "  return db\n",
        "\n",
        "# def query_vector_store(query, db, top_n_docs=5):\n",
        "#   docs = db.similarity_search(query, k=top_n_docs)\n",
        "\n",
        "#   return docs\n",
        "\n",
        "def query_vector_store(query, db, top_n_docs, multiquery):\n",
        "  if multiquery:\n",
        "    retriever_from_llm = MultiQueryRetriever.from_llm(\n",
        "      retriever=db.as_retriever(search_kwargs={\"k\": top_n_docs}), llm=model\n",
        "    )\n",
        "    docs = retriever_from_llm.get_relevant_documents(query=query)\n",
        "  else:\n",
        "    retriever = db.as_retriever(search_kwargs={\"k\": top_n_docs})\n",
        "    docs = retriever.get_relevant_documents(query)\n",
        "\n",
        "  return docs\n",
        "\n",
        "def create_with_refine(input_chunks, title):\n",
        "  prompt_template = \"\"\"Respond as per following instructions:\n",
        "  {text}\n",
        "  CONCISE SUMMARY:\"\"\"\n",
        "  prompt = PromptTemplate.from_template(prompt_template)\n",
        "\n",
        "  refine_template = (\n",
        "      \"\"\"\n",
        "      You are a QnA bot meant to answer questions ONLY from the contexts provided below and NO PRIOR knowledge\n",
        "\n",
        "      Question:\n",
        "      -----------\n",
        "      {query}\n",
        "      -----------\n",
        "\n",
        "      We have provided a response version of the response up to a certain point: {existing_answer}\n",
        "      You have the opportunity to refine the existing response response with below contexts\n",
        "      (only if needed) with some more context as specified below.\n",
        "\n",
        "      Rules:\n",
        "      ------------\n",
        "      Given the new context and the query, refine the response further as necessary for answering the query but\n",
        "      never include the context as is in the response, you should ONLY and ONLY use the knowledge provided in contexts.\n",
        "      DONT add any information which is not present in contexts.\n",
        "      Make sure that the content is always relevant to the original query.\n",
        "      If the context provided isn't useful, dont make any change to the response, just return the current response.\n",
        "      ------------\n",
        "\n",
        "      Context:\n",
        "      ------------\n",
        "      {text}\n",
        "      ------------\n",
        "      \"\"\"\n",
        "  ).replace('{query}', title)\n",
        "\n",
        "  refine_prompt = PromptTemplate.from_template(refine_template)\n",
        "  chain = load_summarize_chain(\n",
        "      llm=model,\n",
        "      chain_type=\"refine\",\n",
        "      question_prompt=prompt,\n",
        "      refine_prompt=refine_prompt,\n",
        "      return_intermediate_steps=True,\n",
        "      input_key=\"input_documents\",\n",
        "      output_key=\"output_text\"\n",
        "  )\n",
        "  result = chain({\"input_documents\": input_chunks}, return_only_outputs=True)\n",
        "\n",
        "  context = []\n",
        "  for ic in input_chunks:\n",
        "    context.append( ic.page_content )\n",
        "\n",
        "  return result['intermediate_steps'], result['output_text'], context\n",
        "\n",
        "def run_query(query, db, top_n_docs=5, multiquery=False):\n",
        "  docs = query_vector_store(query, db, top_n_docs, multiquery)\n",
        "\n",
        "  ## Create article using top N docs\n",
        "  intermediate_steps, final_text, contexts = create_with_refine(docs, query)\n",
        "\n",
        "  return intermediate_steps, final_text, contexts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trr7g_cw5E15",
        "outputId": "3772f0d2-47bc-4fb6-cb97-c3600d20f38f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.vertexai.VertexAI` was deprecated in langchain-community 0.0.12 and will be removed in 0.2.0. An updated version of the class exists in the langchain-google-vertexai package and should be used instead. To use it run `pip install -U langchain-google-vertexai` and import as `from langchain_google_vertexai import VertexAI`.\n",
            "  warn_deprecated(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.vertexai.VertexAIEmbeddings` was deprecated in langchain-community 0.0.12 and will be removed in 0.2.0. An updated version of the class exists in the langchain-google-vertexai package and should be used instead. To use it run `pip install -U langchain-google-vertexai` and import as `from langchain_google_vertexai import VertexAIEmbeddings`.\n",
            "  warn_deprecated(\n",
            "WARNING:langchain_community.embeddings.vertexai:Model_name will become a required arg for VertexAIEmbeddings starting from Feb-01-2024. Currently the default is set to textembedding-gecko@001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_n_docs = 6 # @param {type:\"integer\"} ## Number of similar chunks used to create content\n",
        "\n",
        "## Create chunks from array of texts\n",
        "separator = \" \"\n",
        "chunks = chunk_text(document, separator, chunk_size=250, overlap=20)\n",
        "len(chunks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fN-KTGM5WK6",
        "outputId": "968837af-0eae-46f1-c922-9c106453940a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Create vector store from chunks\n",
        "db = create_vector_store(chunks)"
      ],
      "metadata": {
        "id": "THn3QOYl5X7S"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test RAG"
      ],
      "metadata": {
        "id": "DUvXEo3g8MK2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_answers = []\n",
        "retrieved_contexts = []"
      ],
      "metadata": {
        "id": "u9YSTq3I-yMn"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What type of data can data stores contain in Vertex AI Search ? Give an elaborated answer\" # @param {type:\"string\"} ## Query\n",
        "\n",
        "## Create response using top N docs\n",
        "intermediate_steps, final_text, contexts = run_query(query, db, top_n_docs, multiquery=False)\n",
        "\n",
        "model_answers.append( final_text )\n",
        "retrieved_contexts.append( contexts )\n",
        "\n",
        "final_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "ez6pDnL55dFm",
        "outputId": "240ff0de-ec6a-4ff2-ea6c-1c62bf7f4f2b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Vertex AI Search can store various types of data, including:\\n\\n- **Text:** This includes unstructured text data such as documents, articles, emails, and web pages. Vertex AI Search uses natural language processing (NLP) to understand the meaning of text data and extract relevant information.\\n\\n\\n- **Structured data:** This includes data that is organized in a tabular format, such as spreadsheets, databases, and CSV files. Vertex AI Search can index structured data and make it searchable by specific fields or columns. This enables semantic search or recommendations over structured data such as a BigQuery table or NDJSON files.\\n\\n\\n- **Images:** Vertex AI Search can index and search images based on their visual content. It uses computer vision technology to extract features from images and match them to relevant queries.\\n\\n\\n- **Audio:** Vertex AI Search can index and search audio files, such as podcasts, music, and voice recordings. It uses speech recognition technology to transcribe audio files into text and make them searchable.\\n\\n\\n- **Video:** Vertex AI Search can index and search videos based on their visual and audio content. It uses computer vision and speech recognition technology to extract information from videos and make them searchable.\\n\\n\\n- **Website data:** Vertex AI Search can index and search website content, such as web pages, blog posts, and product descriptions. It can also crawl websites to discover new content and update its index.\\n\\n\\n- **Unstructured data:** Vertex AI Search can also store and search unstructured data, such as documents, images, and videos. This type of data is not organized in a tabular format and can be difficult to search. Vertex AI Search uses machine learning algorithms to understand the meaning of unstructured data and make it searchable.\\n\\nIn addition to these data types, Vertex AI Search can also store and search data from external sources, such as Google Cloud Storage, BigQuery, and Cloud SQL. This allows you to combine data from different sources and create a unified search experience for your users.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What does Vertex search support in terms of Healthcare data ?\" # @param {type:\"string\"} ## Query\n",
        "\n",
        "## Create response using top N docs\n",
        "intermediate_steps, final_text, contexts = run_query(query, db, top_n_docs, multiquery=False)\n",
        "\n",
        "model_answers.append( final_text )\n",
        "retrieved_contexts.append( contexts )\n",
        "\n",
        "final_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "DQlKWT7V-6_m",
        "outputId": "ec9d16d8-d2bb-4cd1-9e94-adb64b51f8f3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" **Healthcare Data:**\\n- Semantic search over healthcare FHIR R4 data from Cloud Healthcare API.\\n- Suitable for healthcare organizations, research institutions, or biotech companies.\\n- For example, a healthcare provider can search over a patient's clinical history using exploratory queries.\\n- Vertex AI Search can also be used to search over other types of healthcare data, such as medical images, genomic data, and electronic health records.\\n- It leverages the power of deep information retrieval, state-of-the-art natural language processing, and the latest in large language model (LLM) processing to understand user intent and retrieve relevant information from healthcare data sources.\\n- Vertex AI Search supports structured data, which enables semantic search or recommendations over structured data such as a BigQuery table or NDJSON files.\\n- You can import FHIR R4 data from Cloud Healthcare API to enable semantic search over healthcare data.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Which all services are currently in preview in Vertex Search ?\" # @param {type:\"string\"} ## Query\n",
        "\n",
        "## Create response using top N docs\n",
        "intermediate_steps, final_text, contexts = run_query(query, db, top_n_docs, multiquery=False)\n",
        "\n",
        "model_answers.append( final_text )\n",
        "retrieved_contexts.append( contexts )\n",
        "\n",
        "final_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "Upl5WhRJ--2d",
        "outputId": "275444bf-2207-45a7-ae22-767dc170c6c1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Vertex AI Search is currently in preview and offers the following services:\\n\\n- Search: Build a Google-quality search app on your own data and embed a search bar in your web pages or app.\\n- Recommendations: Build a recommendations user intent and return the most relevant results for the user.\\n- Data sources: Create search indexes from various data sources, including Salesforce, Jira, Confluence, healthcare FHIR R4 data imported from Cloud Healthcare API, and private repositories of medical research.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tools\n",
        "\n",
        "Tools can be just about anything â€” APIs, functions, databases, etc. Tools allow us to extend the capabilities of a model beyond just outputting text/messages. The key to using models with tools is correctly prompting a model and parsing its response so that it chooses the right tools and provides the right inputs for them.\n",
        "\n",
        "https://python.langchain.com/docs/use_cases/tool_use/prompting/"
      ],
      "metadata": {
        "id": "yh3VDL488O4M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.auth\n",
        "\n",
        "from langchain.chat_models import ChatVertexAI\n",
        "from langchain.embeddings import VertexAIEmbeddings\n",
        "from ragas.llms.base import LangchainLLMWrapper\n",
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "from langchain.tools.render import render_text_description\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from operator import itemgetter\n",
        "from langchain_community.utilities import GoogleSearchAPIWrapper\n",
        "from langchain_core.tools import Tool\n",
        "\n",
        "import os\n",
        "\n",
        "config = {\n",
        "    \"project_id\": \"hasanrafiq-test-331814\",\n",
        "}\n",
        "\n",
        "# authenticate to GCP\n",
        "creds, _ = google.auth.default(quota_project_id=config['project_id'])\n",
        "\n",
        "model = ChatVertexAI(top_k=40, top_p=1, temperature=0, credentials=creds)\n",
        "ragas_vertexai_llm = wrapper = LangchainLLMWrapper(model)\n",
        "vertexai_embeddings = VertexAIEmbeddings(credentials=creds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCK_jOYYIoP-",
        "outputId": "eb259c26-0c29-419a-f0b3-fb6d8b5e7ab5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.vertexai.ChatVertexAI` was deprecated in langchain-community 0.0.12 and will be removed in 0.2.0. An updated version of the class exists in the langchain-google-vertexai package and should be used instead. To use it run `pip install -U langchain-google-vertexai` and import as `from langchain_google_vertexai import ChatVertexAI`.\n",
            "  warn_deprecated(\n",
            "WARNING:langchain_community.embeddings.vertexai:Model_name will become a required arg for VertexAIEmbeddings starting from Feb-01-2024. Currently the default is set to textembedding-gecko@001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Create Google search engine - instructions to make your keys are here - https://python.langchain.com/docs/use_cases/tool_use/quickstart/\n",
        "\n",
        "os.environ[\"GOOGLE_CSE_ID\"] = \"13a84e8cdbaf14622\"\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyAX6QqHZIYXi9-pdckEGAHEjQCYRXOB1TM\"\n",
        "\n",
        "search = GoogleSearchAPIWrapper()\n",
        "\n",
        "search_tool = Tool(\n",
        "    name=\"google_search\",\n",
        "    description=\"Search Google for recent results.\",\n",
        "    func=search.run,\n",
        ")\n",
        "\n",
        "search_tool.run(\"Obama's first name?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "p5UYpGkYU_9P",
        "outputId": "340fba80-f57f-4c5d-a711-c0dd73f02dbf"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Is Residence on a Farm or Plantation? 8. Full Name of Father. BARACK. HUSSEIN. 10. Barack Hussein Obama II. (1961-08-04) August 4, 1961 (age 62) Honolulu, Hawaii, U.S. Â· Democratic Â· Michelle Robinson. \\u200b. ( m. Â· 1992)\\u200b. At the first-ever Global AI Summit last year, I laid out our vision for a future where AI advances the public interest. To help build that future, I am\\xa0... Apr 2, 2018 ... BARACK : Barkat and Mubarak both are derived from it in Hindi and Urdu. Roughly meaning blessing, abundance etc. Husen or Hussein from which\\xa0... Apr 7, 2021 ... No, Obama is secretly his last name, his first name is obviously Joe, though. Joe Obama. Joebama. Dec 19, 2018 ... His full name is Barack Hussein Obama II. Since the â€œIIâ€ is simply because he was named for his father, his last name is Obama. First Lady Michelle LaVaughn Robinson Obama is a lawyer, writer, and the wife of the 44th President, Barack Obama. She is the first African-American First\\xa0... Apr 12, 2017 ... His full name is Barack Hussein Obama II. Since the â€œIIâ€ is simply because he was named for his father, his last name is Obama. Jan 19, 2017 ... Hopeful parents named their sons for the first Black president, whose name is a variation of the Hebrew name Baruch, which means â€œblessedâ€\\xa0... Feb 28, 2008 ... Republicans decry use of 'Hussein' in Obama's name ... WASHINGTON (CNN) -- Republican National Committee Chairman Mike Duncan formally denounced\\xa0...\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@tool\n",
        "def multiply(first_int: int, second_int: int) -> int:\n",
        "    \"\"\"Multiply two integers together.\"\"\"\n",
        "    return first_int * second_int\n",
        "\n",
        "@tool\n",
        "def add(first_int: int, second_int: int) -> int:\n",
        "    \"Add two integers.\"\n",
        "    return first_int + second_int\n",
        "\n",
        "\n",
        "@tool\n",
        "def exponentiate(base: int, exponent: int) -> int:\n",
        "    \"Exponentiate the base to the exponent power.\"\n",
        "    return base**exponent\n",
        "\n",
        "@tool\n",
        "def rag_vertex(question: str) -> str:\n",
        "    \"Answer question related to Vertex AI search and conversation\"\n",
        "\n",
        "    ## Create response using top N docs\n",
        "    intermediate_steps, final_text, contexts = run_query(question, db, top_n_docs, multiquery=False)\n",
        "\n",
        "    return final_text\n",
        "\n",
        "@tool\n",
        "def google_search(question: str) -> str:\n",
        "    \"Answer questions related to facts, non-mathematics, not related to Vertex AI search and Conversation\"\n",
        "\n",
        "    ## Create response using top N docs\n",
        "    res = search_tool.run(question)\n",
        "\n",
        "    return str(res)"
      ],
      "metadata": {
        "id": "YzlTcUe9Idpm"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Tool chooser - Function which helps the model choose in case of multiple functions/\n",
        "\n",
        "def tool_chooser(model_output):\n",
        "    tool_map = {tool.name: tool for tool in tools}\n",
        "    chosen_tool = tool_map[model_output[\"name\"]]\n",
        "    return itemgetter(\"arguments\") | chosen_tool"
      ],
      "metadata": {
        "id": "kbhHeZYRKeHJ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Render the text description of the tools\n",
        "## These are used internally by the LLM when deciding which tool to chose\n",
        "\n",
        "tools = [multiply, add, exponentiate, rag_vertex, google_search]\n",
        "rendered_tools = render_text_description(tools)\n",
        "rendered_tools\n",
        "\n",
        "system_prompt = f\"\"\"You are an assistant that has access to the following set of tools. Here are the names and descriptions for each tool:\n",
        "\n",
        "{rendered_tools}\n",
        "\n",
        "Given the user input, return the name and input of the tool to use. Return your response as a JSON blob with 'name' and 'arguments' keys.\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [(\"system\", system_prompt), (\"user\", \"{input}\")]\n",
        ")\n",
        "\n",
        "print(rendered_tools)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9tQVByQ2Jann",
        "outputId": "25d78935-d3e3-4a44-85da-541793ad4fa3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "multiply: multiply(first_int: int, second_int: int) -> int - Multiply two integers together.\n",
            "add: add(first_int: int, second_int: int) -> int - Add two integers.\n",
            "exponentiate: exponentiate(base: int, exponent: int) -> int - Exponentiate the base to the exponent power.\n",
            "rag_vertex: rag_vertex(question: str) -> str - Answer question related to Vertex AI search and conversation\n",
            "google_search: google_search(question: str) -> str - Answer questions related to facts, non-mathematics, not related to Vertex AI search and Conversation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Chain to parse parameters from the function call, returning name of the function to call and its arguments\n",
        "\n",
        "chain = prompt | model | JsonOutputParser()\n",
        "chain.invoke({\"input\": \"what's thirteen times 4\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lf0iKxmyJiJ4",
        "outputId": "5ce9f826-de57-4e12-f107-88265ebd180a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': 'multiply', 'arguments': {'first_int': 13, 'second_int': 4}}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Call the function selected above\n",
        "\n",
        "chain = prompt | model | JsonOutputParser() | itemgetter(\"arguments\") | multiply\n",
        "chain.invoke({\"input\": \"what's thirteen times 4\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjT19nRFKxxC",
        "outputId": "21a1af58-f454-4284-8c54-57e0d9ba6673"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "52"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rendered_tools = render_text_description(tools)\n",
        "system_prompt = f\"\"\"You are an assistant that has access to the following set of tools. Here are the names and descriptions for each tool:\n",
        "\n",
        "{rendered_tools}\n",
        "\n",
        "Given the user input, return the name and input of the tool to use. Return your response as a JSON blob with 'name' and 'arguments' keys.\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [(\"system\", system_prompt), (\"user\", \"{input}\")]\n",
        ")\n",
        "\n",
        "chain = prompt | model | JsonOutputParser() | tool_chooser\n",
        "chain.invoke(\"what's 3 plus 1132\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k673UXPDK4qB",
        "outputId": "2d76ae62-b73c-4332-b861-6fa92e21c6b8"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1135"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke(\"what's 4.233 power 5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rEVHqLuK705",
        "outputId": "b2d9dfa4-5f7c-4cca-8e36-ad0cc981e2f1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1024"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke(\"cube of ninety nine\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hfB7jmgbIxNA",
        "outputId": "786db645-e790-4ddd-affc-f82cf8d69735"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "970299"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke(\"What is the distance between Warsaw and Krakow ?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "1L9zWJs8ZJ-Q",
        "outputId": "58d6a430-6988-4de0-f0ba-449e275715b3"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Questions & Answers Â· Distance: 289 km Â· Duration: 2h 14m\\xa0... Distance between Krakow and Warsaw is 252 kilometers (157 miles) in Poland. Also calculate the driving distance and how far is it the travel time. Questions & Answers Â· Distance: 289 km Â· Duration: 2h 22m\\xa0... What's the distance between Warsaw and Krakow Central by train? Trains travelling from Warsaw to Krakow Central cover a distance of around 155 miles (250 km)\\xa0... Travelers usually depart from Warsaw Chopin, or Warsaw Modlin when they travel from Warsaw to KrakÃ³w. The distance between Warsaw and KrakÃ³w is 246 km. The\\xa0... Feb 22, 2021 ... I've checked it on Naviki and the example distance is 373 km. The intermediate route (according Naviki best for â€œeverydayâ€ trip) is about 317 km\\xa0... The distance between Warsaw and KrakÃ³w is 180 miles, which takes a minimum of 3 hours 35 minutes. FlixBus has a large nationwide network, so you can travel\\xa0... Looking how to get from Warsaw to Krakow? Check trip schedule and travel distance. Compare prices for trains, buses, ferries and âœˆï¸ flights. Distance from KrakÃ³w to Warsaw (KrakÃ³w John Paul II International Airport â€“ Warsaw Chopin Airport) is 153 miles / 247 kilometers / 133 nautical miles. Fastest flight, 50 min, The fastest nonstop flight from Warsaw to KrakÃ³w takes 50 min. Nonstop flights, Every day, There are direct flights on this route\\xa0...\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke(\"Which all services are currently in preview in Vertex AI Search ?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "qeJZvkj4MZA9",
        "outputId": "da7d0f5e-0a66-44f5-acb0-0bc06f5679a8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The generic recommendations feature and the healthcare data store are currently in preview in Vertex AI Search.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    }
  ]
}