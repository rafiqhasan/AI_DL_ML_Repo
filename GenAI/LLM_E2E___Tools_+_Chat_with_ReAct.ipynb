{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Goal:\n",
        "\n",
        "- Build notebook to do RAG + Tools\n",
        "- Try further with LangGraph\n",
        "\n",
        "By: Hasan Rafiq"
      ],
      "metadata": {
        "id": "QWJtdgwJ39wk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installing the package"
      ],
      "metadata": {
        "id": "T_pLQeNp36mA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-cloud-aiplatform langchain langchain-core langchain-google-vertexai faiss-cpu ragas langchainhub --upgrade --user"
      ],
      "metadata": {
        "id": "XOPSCwGu38W7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "78b0ab96-dd84-45ca-95aa-12f181160da4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-cloud-aiplatform in /usr/local/lib/python3.10/dist-packages (1.48.0)\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.1.16-py3-none-any.whl (817 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m817.7/817.7 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core\n",
            "  Downloading langchain_core-0.1.45-py3-none-any.whl (291 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m291.3/291.3 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-google-vertexai\n",
            "  Downloading langchain_google_vertexai-1.0.1-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.3/53.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ragas\n",
            "  Downloading ragas-0.1.7-py3-none-any.whl (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.2/81.2 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchainhub\n",
            "  Downloading langchainhub-0.1.15-py3-none-any.whl (4.6 kB)\n",
            "Requirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.11.1)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.27.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (1.23.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (3.20.3)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (24.0)\n",
            "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.8.0)\n",
            "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (3.12.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (1.12.3)\n",
            "Requirement already satisfied: shapely<3.0.0dev in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.0.4)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.7.0)\n",
            "Requirement already satisfied: docstring-parser<1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (0.16)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.32 (from langchain)\n",
            "  Downloading langchain_community-0.0.34-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.49-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.2/115.2 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Collecting packaging>=14.3 (from google-cloud-aiplatform)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting google-cloud-storage<3.0.0dev,>=1.32.0 (from google-cloud-aiplatform)\n",
            "  Downloading google_cloud_storage-2.16.0-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.6/125.6 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting types-protobuf<5.0.0.0,>=4.24.0.4 (from langchain-google-vertexai)\n",
            "  Downloading types_protobuf-4.25.0.20240417-py3-none-any.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.9/67.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting types-requests<3.0.0,>=2.31.0 (from langchain-google-vertexai)\n",
            "  Downloading types_requests-2.31.0.20240406-py3-none-any.whl (15 kB)\n",
            "Collecting datasets (from ragas)\n",
            "  Downloading datasets-2.19.0-py3-none-any.whl (542 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tiktoken (from ragas)\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-openai (from ragas)\n",
            "  Downloading langchain_openai-0.1.3-py3-none-any.whl (33 kB)\n",
            "Collecting openai>1 (from ragas)\n",
            "  Downloading openai-1.23.2-py3-none-any.whl (311 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pysbd>=0.3.4 (from ragas)\n",
            "  Downloading pysbd-0.3.4-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from ragas) (1.6.0)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.10/dist-packages (from ragas) (1.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.63.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.62.2)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.48.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (4.9)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.3.3)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.7.0)\n",
            "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.8.2)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform) (0.13.0)\n",
            "INFO: pip is looking at multiple versions of google-cloud-storage to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting google-cloud-storage<3.0.0dev,>=1.32.0 (from google-cloud-aiplatform)\n",
            "  Downloading google_cloud_storage-2.15.0-py2.py3-none-any.whl (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.5/123.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading google_cloud_storage-2.14.0-py2.py3-none-any.whl (121 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.5.0)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>1->ragas) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>1->ragas) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai>1->ragas)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>1->ragas) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai>1->ragas) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai>1->ragas) (4.11.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3->google-cloud-aiplatform) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3->google-cloud-aiplatform) (2.18.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets->ragas) (3.13.4)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->ragas) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->ragas) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets->ragas)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->ragas) (2.0.3)\n",
            "Collecting xxhash (from datasets->ragas)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets->ragas)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets->ragas) (2023.6.0)\n",
            "Collecting huggingface-hub>=0.21.2 (from datasets->ragas)\n",
            "  Downloading huggingface_hub-0.22.2-py3-none-any.whl (388 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.9/388.9 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->ragas) (2023.12.25)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>1->ragas) (1.2.1)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai>1->ragas)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai>1->ragas)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0dev,>=2.7.2->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.16.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->ragas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->ragas) (2024.1)\n",
            "Installing collected packages: xxhash, types-requests, types-protobuf, pysbd, packaging, orjson, mypy-extensions, jsonpointer, h11, faiss-cpu, dill, typing-inspect, tiktoken, multiprocess, marshmallow, langchainhub, jsonpatch, huggingface-hub, httpcore, langsmith, httpx, dataclasses-json, openai, langchain-core, datasets, langchain-text-splitters, langchain-openai, langchain-community, google-cloud-storage, langchain, ragas, langchain-google-vertexai\n",
            "\u001b[33m  WARNING: The script huggingface-cli is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The script langsmith is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The script httpx is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The script openai is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The script datasets-cli is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The script langchain-server is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.4 datasets-2.19.0 dill-0.3.8 faiss-cpu-1.8.0 google-cloud-storage-2.14.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 huggingface-hub-0.22.2 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.16 langchain-community-0.0.34 langchain-core-0.1.45 langchain-google-vertexai-1.0.1 langchain-openai-0.1.3 langchain-text-splitters-0.0.1 langchainhub-0.1.15 langsmith-0.1.49 marshmallow-3.21.1 multiprocess-0.70.16 mypy-extensions-1.0.0 openai-1.23.2 orjson-3.10.1 packaging-23.2 pysbd-0.3.4 ragas-0.1.7 tiktoken-0.6.0 types-protobuf-4.25.0.20240417 types-requests-2.31.0.20240406 typing-inspect-0.9.0 xxhash-3.4.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "2c6d75ef8d7a41c99654c0ee5b185ed7"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Authenticate again"
      ],
      "metadata": {
        "id": "SEg9gRnl4iz7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth as google_auth\n",
        "google_auth.authenticate_user()"
      ],
      "metadata": {
        "id": "xTOySbcM4gFp"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PROJECT_ID = \"hasanrafiq-test-331814\"  # @param {type:\"string\"}\n",
        "LOCATION = \"us-central1\"  # @param {type:\"string\"}"
      ],
      "metadata": {
        "id": "cKcun6Kf4z2K"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import aiplatform\n",
        "# from vertexai.preview.language_models import TextGenerationModel, ChatModel\n",
        "from vertexai.generative_models import GenerativeModel, Part, ChatSession, Image, FunctionDeclaration, Tool, Content\n",
        "from langchain_google_vertexai import VertexAI\n",
        "import http.client\n",
        "import typing\n",
        "import urllib.request\n",
        "import pandas as pd\n",
        "\n",
        "from google.cloud import aiplatform, storage\n",
        "from vertexai.preview.language_models import TextGenerationModel, ChatModel, TextEmbeddingModel\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "import pprint\n",
        "import re\n",
        "import io\n",
        "\n",
        "from langchain.llms import VertexAI\n",
        "from langchain import hub\n",
        "from langchain.text_splitter import TextSplitter, CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
        "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.document_loaders import TextLoader, GCSFileLoader\n",
        "from langchain.embeddings import VertexAIEmbeddings\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "from langchain.chains.mapreduce import MapReduceChain\n",
        "from langchain.chains import ReduceDocumentsChain, MapReduceDocumentsChain\n",
        "from langchain.chains.llm import LLMChain\n",
        "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
        "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.tools import tool\n",
        "from langchain.agents import AgentExecutor, create_react_agent, create_tool_calling_agent\n",
        "from langchain import hub\n",
        "\n",
        "from ragas.metrics import (\n",
        "    answer_relevancy,\n",
        "    faithfulness,\n",
        "    context_recall,\n",
        "    context_precision,\n",
        "    context_entity_recall,\n",
        "    answer_correctness\n",
        ")\n",
        "from datasets import Dataset\n",
        "from ragas import evaluate\n",
        "\n",
        "aiplatform.init(project=PROJECT_ID, location=LOCATION)"
      ],
      "metadata": {
        "id": "aJjzXsFY45oe"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implement a RAG"
      ],
      "metadata": {
        "id": "vnDIpgHX48ZH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Source text"
      ],
      "metadata": {
        "id": "w891IFzU4_Yt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "document = [\"\"\"\n",
        "Information retrieval using AI and LLMs\n",
        "Vertex AI Search brings together the power of deep information retrieval, state-of-the-art natural language processing, and the latest in large language model (LLM) processing to understand user intent and return the most relevant results for the user.\n",
        "\n",
        "With Vertex AI Search, you can build a Google-quality search app on your own data and embed a search bar in your web pages or app.\n",
        "\n",
        "With Recommendations, you can build a recommendations app on your own data that will suggest content similar to the content that the user is currently viewing.\n",
        "\n",
        "Note: The generic recommendations feature is a Preview offering, subject to the \"Pre-GA Offerings Terms\" of the GCP Service Specific Terms. Pre-GA products and features may have limited support, and changes to pre-GA products and features may not be compatible with other pre-GA versions. For more information, see the launch stage descriptions. Further, by using this feature, you agree to the Generative AI Preview terms and conditions (\"Preview Terms\"). For this feature, you can process personal data as outlined in the Cloud Data Processing Addendum, subject to applicable restrictions and obligations in the Agreement (as defined in the Preview Terms).\n",
        "An easy experience to get started\n",
        "Vertex AI Search makes it easy to get started with high-quality search or recommendations based on data that you provide. As part of the setup experience, you can:\n",
        "\n",
        "Use your existing Google Account or sign up for one.\n",
        "Use your existing Google Cloud project or create one.\n",
        "Create an app and attach a data store to it. Provide data to search or recommend by entering the URLs for your website content, importing your data from BigQuery or Cloud Storage, or importing FHIR R4 data from Cloud Healthcare API, or uploading through RESTful CRUD APIs. Syncing data from Jira, Salesforce, or Confluence is available in Preview with allowlist.\n",
        "Embed JavaScript widgets and API samples to integrate search or recommendations into your website or applications.\n",
        "Data stores and apps\n",
        "With Vertex AI Search, you create a search or recommendations app and attach it to a data store. You import your data into a data store and index your data. Apps and data stores have a one-to-one relationship.\n",
        "\n",
        "There are various kinds of data stores that you can create, based on the type of data you use. Each data store can contain one type of data:\n",
        "\n",
        "Website data: You can provide domains such as yourexamplewebsite.com/faq and yourexamplewebsite.com/events and enable search or recommendations over the content at those domains.\n",
        "Structured data: A data store with structured data enables semantic search or recommendations over structured data such as a BigQuery table or NDJSON files. For example, you can enable search or recommendations over a product catalog for your ecommerce experience, a movie catalog for movie search or recommendations, or a directory of doctors for provider search or recommendations.\n",
        "Unstructured data: An unstructured data store enables semantic search or recommendations over data such as documents and images. For example, a financial institution can enable search or recommendations over their private corpus of financial research publications, or a biotech company can enable search or recommendations over their private repository of medical research.\n",
        "Healthcare data: A healthcare data store enables semantic search over healthcare FHIR R4 data imported from Cloud Healthcare API. For example, a healthcare provider can search over a patient's clinical history using exploratory queries.\n",
        "\"\"\"]"
      ],
      "metadata": {
        "id": "1K5nNCjc47UQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create helper functions"
      ],
      "metadata": {
        "id": "z1itUHeG5Ibv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Gemini model\n",
        "model = VertexAI( max_output_tokens=2048, model=\"gemini-1.0-pro\", top_p = 1, temperature = 0)\n",
        "llm_embeddings = VertexAIEmbeddings()\n",
        "\n",
        "def chunk_text(input_texts, separator=\"\", chunk_size=100, overlap=20):\n",
        "  ## Create split of texts on a chunk\n",
        "  text_splitter = CharacterTextSplitter(separator=\"\", chunk_size=chunk_size, chunk_overlap=overlap)\n",
        "  chunks = text_splitter.create_documents(input_texts)\n",
        "\n",
        "  return chunks\n",
        "\n",
        "def create_vector_store(chunks):\n",
        "  ## Create vector store from embeddings\n",
        "  db = FAISS.from_documents(chunks, llm_embeddings)\n",
        "\n",
        "  return db\n",
        "\n",
        "# def query_vector_store(query, db, top_n_docs=5):\n",
        "#   docs = db.similarity_search(query, k=top_n_docs)\n",
        "\n",
        "#   return docs\n",
        "\n",
        "def query_vector_store(query, db, top_n_docs, multiquery):\n",
        "  if multiquery:\n",
        "    retriever_from_llm = MultiQueryRetriever.from_llm(\n",
        "      retriever=db.as_retriever(search_kwargs={\"k\": top_n_docs}), llm=model\n",
        "    )\n",
        "    docs = retriever_from_llm.get_relevant_documents(query=query)\n",
        "  else:\n",
        "    retriever = db.as_retriever(search_kwargs={\"k\": top_n_docs})\n",
        "    docs = retriever.get_relevant_documents(query)\n",
        "\n",
        "  return docs\n",
        "\n",
        "def create_with_refine(input_chunks, title):\n",
        "  prompt_template = \"\"\"Respond as per following instructions:\n",
        "  {text}\n",
        "  CONCISE SUMMARY:\"\"\"\n",
        "  prompt = PromptTemplate.from_template(prompt_template)\n",
        "\n",
        "  refine_template = (\n",
        "      \"\"\"\n",
        "      You are a QnA bot meant to answer questions ONLY from the contexts provided below and NO PRIOR knowledge\n",
        "\n",
        "      Question:\n",
        "      -----------\n",
        "      {query}\n",
        "      -----------\n",
        "\n",
        "      We have provided a response version of the response up to a certain point: {existing_answer}\n",
        "      You have the opportunity to refine the existing response response with below contexts\n",
        "      (only if needed) with some more context as specified below.\n",
        "\n",
        "      Rules:\n",
        "      ------------\n",
        "      Given the new context and the query, refine the response further as necessary for answering the query but\n",
        "      never include the context as is in the response, you should ONLY and ONLY use the knowledge provided in contexts.\n",
        "      DONT add any information which is not present in contexts.\n",
        "      Make sure that the content is always relevant to the original query.\n",
        "      If the context provided isn't useful, dont make any change to the response, just return the current response.\n",
        "      ------------\n",
        "\n",
        "      Context:\n",
        "      ------------\n",
        "      {text}\n",
        "      ------------\n",
        "      \"\"\"\n",
        "  ).replace('{query}', title)\n",
        "\n",
        "  refine_prompt = PromptTemplate.from_template(refine_template)\n",
        "  chain = load_summarize_chain(\n",
        "      llm=model,\n",
        "      chain_type=\"refine\",\n",
        "      question_prompt=prompt,\n",
        "      refine_prompt=refine_prompt,\n",
        "      return_intermediate_steps=True,\n",
        "      input_key=\"input_documents\",\n",
        "      output_key=\"output_text\"\n",
        "  )\n",
        "  result = chain({\"input_documents\": input_chunks}, return_only_outputs=True)\n",
        "\n",
        "  context = []\n",
        "  for ic in input_chunks:\n",
        "    context.append( ic.page_content )\n",
        "\n",
        "  return result['intermediate_steps'], result['output_text'], context\n",
        "\n",
        "def run_query(query, db, top_n_docs=5, multiquery=False):\n",
        "  docs = query_vector_store(query, db, top_n_docs, multiquery)\n",
        "\n",
        "  ## Create article using top N docs\n",
        "  intermediate_steps, final_text, contexts = create_with_refine(docs, query)\n",
        "\n",
        "  return intermediate_steps, final_text, contexts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trr7g_cw5E15",
        "outputId": "c63de849-a9ae-4f1b-d3bd-3a2b3d333aa7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/root/.local/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `VertexAI` was deprecated in LangChain 0.0.12 and will be removed in 0.2.0. An updated version of the class exists in the langchain-google-vertexai package and should be used instead. To use it run `pip install -U langchain-google-vertexai` and import as `from langchain_google_vertexai import VertexAI`.\n",
            "  warn_deprecated(\n",
            "/root/.local/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `VertexAIEmbeddings` was deprecated in LangChain 0.0.12 and will be removed in 0.2.0. An updated version of the class exists in the langchain-google-vertexai package and should be used instead. To use it run `pip install -U langchain-google-vertexai` and import as `from langchain_google_vertexai import VertexAIEmbeddings`.\n",
            "  warn_deprecated(\n",
            "WARNING:langchain_community.embeddings.vertexai:Model_name will become a required arg for VertexAIEmbeddings starting from Feb-01-2024. Currently the default is set to textembedding-gecko@001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_n_docs = 6 # @param {type:\"integer\"} ## Number of similar chunks used to create content\n",
        "\n",
        "## Create chunks from array of texts\n",
        "separator = \" \"\n",
        "chunks = chunk_text(document, separator, chunk_size=250, overlap=20)\n",
        "len(chunks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fN-KTGM5WK6",
        "outputId": "30ac07cc-2cde-4764-8583-084e08271a72"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Create vector store from chunks\n",
        "db = create_vector_store(chunks)"
      ],
      "metadata": {
        "id": "THn3QOYl5X7S"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test RAG"
      ],
      "metadata": {
        "id": "DUvXEo3g8MK2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_answers = []\n",
        "retrieved_contexts = []"
      ],
      "metadata": {
        "id": "u9YSTq3I-yMn"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What type of data can data stores contain in Vertex AI Search ? Give an elaborated answer\" # @param {type:\"string\"} ## Query\n",
        "\n",
        "## Create response using top N docs\n",
        "intermediate_steps, final_text, contexts = run_query(query, db, top_n_docs, multiquery=False)\n",
        "\n",
        "model_answers.append( final_text )\n",
        "retrieved_contexts.append( contexts )\n",
        "\n",
        "final_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 152
        },
        "id": "ez6pDnL55dFm",
        "outputId": "f05e95a5-8139-4225-e821-e371876e373a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/root/.local/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Vertex AI Search can store various types of data, including:\\n\\n- **Text:** This includes unstructured text data such as documents, articles, emails, and web pages. Vertex AI Search uses natural language processing (NLP) to understand the meaning of text data and extract relevant information.\\n\\n\\n- **Structured data:** This includes data that is organized in a tabular format, such as spreadsheets, databases, and CSV files. Vertex AI Search can index structured data and make it searchable by specific fields or columns. This enables semantic search or recommendations over structured data such as a BigQuery table or NDJSON files.\\n\\n\\n- **Images:** Vertex AI Search can index and search images based on their visual content. It uses computer vision technology to extract features from images and match them to relevant queries.\\n\\n\\n- **Audio:** Vertex AI Search can index and search audio files, such as podcasts, music, and voice recordings. It uses speech recognition technology to transcribe audio files into text and make them searchable.\\n\\n\\n- **Video:** Vertex AI Search can index and search videos based on their visual and audio content. It uses computer vision and speech recognition technology to extract information from videos and make them searchable.\\n\\n\\n- **Website data:** Vertex AI Search can index and search website content, such as web pages, blog posts, and product descriptions. It can also crawl websites to discover new content and update its index.\\n\\n\\n- **Unstructured data:** Vertex AI Search can also store and search unstructured data, such as documents, images, and videos. This type of data is not organized in a tabular format and can be difficult to search. Vertex AI Search uses machine learning algorithms to understand the meaning of unstructured data and make it searchable.\\n\\nIn addition to these data types, Vertex AI Search can also store and search data from external sources, such as Google Cloud Storage, BigQuery, and Cloud SQL. This allows you to combine data from different sources and create a unified search experience for your users.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What does Vertex search support in terms of Healthcare data ?\" # @param {type:\"string\"} ## Query\n",
        "\n",
        "## Create response using top N docs\n",
        "intermediate_steps, final_text, contexts = run_query(query, db, top_n_docs, multiquery=False)\n",
        "\n",
        "model_answers.append( final_text )\n",
        "retrieved_contexts.append( contexts )\n",
        "\n",
        "final_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113
        },
        "id": "DQlKWT7V-6_m",
        "outputId": "15e1c241-e705-49ce-e317-0dfffa5e1811"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" **Healthcare Data:**\\n- Semantic search over healthcare FHIR R4 data from Cloud Healthcare API.\\n- Suitable for healthcare organizations, research institutions, or biotech companies.\\n- For example, a healthcare provider can search over a patient's clinical history using exploratory queries.\\n- Vertex AI Search can also be used to search over other types of healthcare data, such as medical images, genomic data, and electronic health records.\\n- It leverages the power of deep information retrieval, state-of-the-art natural language processing, and the latest in large language model (LLM) processing to understand user intent and retrieve relevant information from healthcare data sources.\\n- Vertex AI Search supports structured data, which enables semantic search or recommendations over structured data such as a BigQuery table or NDJSON files.\\n- You can import FHIR R4 data from Cloud Healthcare API to enable semantic search over healthcare data.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Which all services are currently in preview in Vertex Search ?\" # @param {type:\"string\"} ## Query\n",
        "\n",
        "## Create response using top N docs\n",
        "intermediate_steps, final_text, contexts = run_query(query, db, top_n_docs, multiquery=False)\n",
        "\n",
        "model_answers.append( final_text )\n",
        "retrieved_contexts.append( contexts )\n",
        "\n",
        "final_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "Upl5WhRJ--2d",
        "outputId": "61c86a7d-79f3-42b3-8fd6-fbb6091eaba6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Vertex AI Search is currently in preview and offers the following services:\\n\\n- Search: Build a Google-quality search app on your own data and embed a search bar in your web pages or app.\\n- Recommendations: Build a recommendations user intent and return the most relevant results for the user.\\n- Data sources: Create search indexes from various data sources, including Salesforce, Jira, Confluence, healthcare FHIR R4 data imported from Cloud Healthcare API, and private repositories of medical research.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tools\n",
        "\n",
        "Tools can be just about anything — APIs, functions, databases, etc. Tools allow us to extend the capabilities of a model beyond just outputting text/messages. The key to using models with tools is correctly prompting a model and parsing its response so that it chooses the right tools and provides the right inputs for them.\n",
        "\n",
        "https://python.langchain.com/docs/use_cases/tool_use/prompting/"
      ],
      "metadata": {
        "id": "yh3VDL488O4M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.auth\n",
        "\n",
        "from langchain.chat_models import ChatVertexAI\n",
        "from langchain.embeddings import VertexAIEmbeddings\n",
        "from ragas.llms.base import LangchainLLMWrapper\n",
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "from langchain.tools.render import render_text_description\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from operator import itemgetter\n",
        "from langchain_community.utilities import GoogleSearchAPIWrapper\n",
        "from langchain_core.tools import Tool\n",
        "\n",
        "import os\n",
        "\n",
        "config = {\n",
        "    \"project_id\": \"hasanrafiq-test-331814\",\n",
        "}\n",
        "\n",
        "# authenticate to GCP\n",
        "creds, _ = google.auth.default(quota_project_id=config['project_id'])\n",
        "\n",
        "model = ChatVertexAI(top_k=40, top_p=1, temperature=0, credentials=creds)\n",
        "ragas_vertexai_llm = wrapper = LangchainLLMWrapper(model)\n",
        "vertexai_embeddings = VertexAIEmbeddings(credentials=creds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCK_jOYYIoP-",
        "outputId": "b02f200c-9be3-46e8-d295-845ab0818507"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/root/.local/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `ChatVertexAI` was deprecated in LangChain 0.0.12 and will be removed in 0.2.0. An updated version of the class exists in the langchain-google-vertexai package and should be used instead. To use it run `pip install -U langchain-google-vertexai` and import as `from langchain_google_vertexai import ChatVertexAI`.\n",
            "  warn_deprecated(\n",
            "WARNING:langchain_community.embeddings.vertexai:Model_name will become a required arg for VertexAIEmbeddings starting from Feb-01-2024. Currently the default is set to textembedding-gecko@001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Create Google search engine - instructions to make your keys are here - https://python.langchain.com/docs/integrations/tools/google_search/\n",
        "\n",
        "os.environ[\"GOOGLE_CSE_ID\"] = \"\"\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"\"\n",
        "\n",
        "search = GoogleSearchAPIWrapper()\n",
        "\n",
        "search_tool = Tool(\n",
        "    name=\"google_search\",\n",
        "    description=\"Search Google for recent results.\",\n",
        "    func=search.run,\n",
        ")\n",
        "\n",
        "search_tool.run(\"Obama's first name?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "id": "p5UYpGkYU_9P",
        "outputId": "3d2c2881-82e5-4711-ee1f-1f0d108a5a1c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/root/.local/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `GoogleSearchAPIWrapper` was deprecated in LangChain 0.0.33 and will be removed in 0.2.0. An updated version of the class exists in the langchain-google-community package and should be used instead. To use it run `pip install -U langchain-google-community` and import as `from langchain_google_community import GoogleSearchAPIWrapper`.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Full Maiden Name of Mother. STANLEY. 15. Age of Mother 16. 18. Yes. No. 9. Race of Father. OBAMA. African. Usual Occupation. 12b. Student. DUNHAM. Kind of\\xa0... Barack Hussein Obama II. (1961-08-04) August 4, 1961 (age 62) Honolulu, Hawaii, U.S. · Democratic · Michelle Robinson. \\u200b. ( m. · 1992)\\u200b. Apr 2, 2018 ... BARACK : Barkat and Mubarak both are derived from it in Hindi and Urdu. Roughly meaning blessing, abundance etc. Husen or Hussein from which\\xa0... At the first-ever Global AI Summit last year, I laid out our vision for a future where AI advances the public interest. To help build that future, I am\\xa0... First Lady Michelle LaVaughn Robinson Obama is a lawyer, writer, and the wife of the 44th President, Barack Obama. She is the first African-American First\\xa0... Apr 7, 2021 ... No, Obama is secretly his last name, his first name is obviously Joe, though. Joe Obama. Joebama. Jan 19, 2017 ... Hopeful parents named their sons for the first Black president, whose name is a variation of the Hebrew name Baruch, which means “blessed”\\xa0... Nov 13, 2023 ... 70. Downvote Reply reply. Share. u/Slugger322 avatar · Slugger322. • 5mo ago. Kinda like how Obama's first name is Mr. Upvote 37. Downvote Reply\\xa0... May 19, 2010 ... President Barack Obama greets a boy, whose first name is also Barack, following the President's remarks on health care at the University of\\xa0... Jan 16, 2024 ... ... Obama was not born in the US and ineligible to be president. Trump also regularly emphasizes Obama's middle name, Hussein, at campaign rallies.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@tool\n",
        "def multiply(first_int: int, second_int: int) -> int:\n",
        "    \"\"\"Multiply two integers together.\"\"\"\n",
        "    return first_int * second_int\n",
        "\n",
        "@tool\n",
        "def add(first_int: int, second_int: int) -> int:\n",
        "    \"Add two integers.\"\n",
        "    return first_int + second_int\n",
        "\n",
        "\n",
        "@tool\n",
        "def exponentiate(base: int, exponent: float) -> float:\n",
        "    \"Exponentiate the base to the exponent power.\"\n",
        "    return base**exponent\n",
        "\n",
        "@tool\n",
        "def rag_vertex(question: str) -> str:\n",
        "    \"Answer question related to Vertex AI search and conversation ONLY\"\n",
        "\n",
        "    ## Create response using top N docs\n",
        "    intermediate_steps, final_text, contexts = run_query(question, db, top_n_docs, multiquery=False)\n",
        "\n",
        "    return final_text\n",
        "\n",
        "@tool\n",
        "def google_search(question: str) -> str:\n",
        "    \"Answer questions related to facts, non-mathematics, but NOT related to Vertex AI search and Conversation\"\n",
        "\n",
        "    ## Create response using top N docs\n",
        "    res = search_tool.run(question)\n",
        "\n",
        "    return str(res)"
      ],
      "metadata": {
        "id": "YzlTcUe9Idpm"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Tool chooser - Function which helps the model choose in case of multiple functions/\n",
        "\n",
        "def tool_chooser(model_output):\n",
        "    tool_map = {tool.name: tool for tool in tools}\n",
        "    chosen_tool = tool_map[model_output[\"name\"]]\n",
        "    return itemgetter(\"arguments\") | chosen_tool"
      ],
      "metadata": {
        "id": "kbhHeZYRKeHJ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Render the text description of the tools\n",
        "## These are used internally by the LLM when deciding which tool to chose\n",
        "\n",
        "tools = [multiply, add, exponentiate, rag_vertex, google_search]\n",
        "rendered_tools = render_text_description(tools)\n",
        "rendered_tools\n",
        "\n",
        "system_prompt = f\"\"\"You are an assistant that has access to the following set of tools. Here are the names and descriptions for each tool:\n",
        "\n",
        "{rendered_tools}\n",
        "\n",
        "Given the user input, return the name and input of the tool to use. Return your response as a JSON blob with 'name' and 'arguments' keys.\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [(\"system\", system_prompt), (\"user\", \"{input}\")]\n",
        ")\n",
        "\n",
        "print(rendered_tools)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9tQVByQ2Jann",
        "outputId": "77592bc1-038b-4740-bbbc-2fd042e3bc54"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "multiply: multiply(first_int: int, second_int: int) -> int - Multiply two integers together.\n",
            "add: add(first_int: int, second_int: int) -> int - Add two integers.\n",
            "exponentiate: exponentiate(base: int, exponent: float) -> float - Exponentiate the base to the exponent power.\n",
            "rag_vertex: rag_vertex(question: str) -> str - Answer question related to Vertex AI search and conversation ONLY\n",
            "google_search: google_search(question: str) -> str - Answer questions related to facts, non-mathematics, but NOT related to Vertex AI search and Conversation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Chain to parse parameters from the function call, returning name of the function to call and its arguments\n",
        "\n",
        "chain = prompt | model | JsonOutputParser()\n",
        "chain.invoke({\"input\": \"what's thirteen times 4\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lf0iKxmyJiJ4",
        "outputId": "c4318f05-b92c-4355-a372-e7097d342d20"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': 'multiply', 'arguments': {'first_int': 13, 'second_int': 4}}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Call the function selected above ( using Multiply function specifically )\n",
        "\n",
        "chain = prompt | model | JsonOutputParser() | itemgetter(\"arguments\") | multiply\n",
        "chain.invoke({\"input\": \"what's thirteen times 4\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjT19nRFKxxC",
        "outputId": "289c1deb-e04d-471b-98f8-1e6b8ae9bcd5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "52"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rendered_tools = render_text_description(tools)\n",
        "system_prompt = f\"\"\"You are an assistant that has access to the following set of tools. Here are the names and descriptions for each tool:\n",
        "\n",
        "{rendered_tools}\n",
        "\n",
        "Given the user input, return the name and input of the tool to use. Return your response as a JSON blob with 'name' and 'arguments' keys.\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [(\"system\", system_prompt), (\"user\", \"{input}\")]\n",
        ")\n",
        "\n",
        "chain = prompt | model | JsonOutputParser() | tool_chooser\n",
        "chain.invoke(\"what's 3 plus 1132\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k673UXPDK4qB",
        "outputId": "cae50337-0e2c-4052-c34e-d0b331bcd6c1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1135"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke(\"what's 4.233 power 5 power 3\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rEVHqLuK705",
        "outputId": "95e687c9-91a9-41bd-9eaa-572519340e01"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1073741824.0"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke(\"cube of ninety nine\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hfB7jmgbIxNA",
        "outputId": "68cbcb5b-a0f7-4a0b-f327-e38286ddcea4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "970299.0"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke(\"cube of ninety nine\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvG6BqG8Wfoo",
        "outputId": "a244b153-03c5-4621-b161-462179214ade"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "970299.0"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke(\"What is the distance between Warsaw and Krakow ?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113
        },
        "id": "1L9zWJs8ZJ-Q",
        "outputId": "23a10c5d-dbff-4b25-edd7-a0fae8efadd4"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Questions & Answers · Distance: 289 km · Duration: 2h 14m\\xa0... You'll usually find 18 trains per day traveling the 250 km between these two destinations. Direct trains are usually available every day on the route to Krakow\\xa0... Questions & Answers · Distance: 289 km · Duration: 2h 22m\\xa0... Distance between Krakow and Warsaw is 252 kilometers (157 miles) in Poland. Also calculate the driving distance and how far is it the travel time. The distance between Warsaw and Kraków is 180 miles, which takes a minimum of 3 hours 35 minutes. FlixBus has a large nationwide network, so you can travel\\xa0... Distance between Warsaw and Krakow is 252 kilometers (157 miles) in Poland. Also calculate the driving distance and how far is it the travel time. Looking how to get from Warsaw to Krakow? Check trip schedule and travel distance. Compare prices for trains, buses, ferries and ✈️ flights. Jun 9, 2023 ... According to Google Maps (Kraków to Warsaw ) it's 283kms. But it's the closest walkable path and might not be too entertaining. More restaurants in Cracow. Tourist AttractionsThings to see and do Cracow. Wawel Cathedral. The Green Guide. 507 m - Ul. Grodzka, 31-006 Kraków. Distance from Kraków to Warsaw (Kraków John Paul II International Airport – Warsaw Chopin Airport) is 153 miles / 247 kilometers / 133 nautical miles.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke(\"Which all services are currently in preview in Vertex AI Search ?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "qeJZvkj4MZA9",
        "outputId": "ae3f19f2-bd3a-4ab5-b0df-d7233dd3a4fd"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The generic recommendations feature and the healthcare data store are currently in preview in Vertex AI Search.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ReAct Agent for Chat based QnA\n",
        "\n",
        "- RAG + ReAct based Chatbot\n",
        "- Uses tools created above for selection"
      ],
      "metadata": {
        "id": "7_xoq02UYpGO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tool\n",
        "def rag_vertex(question) -> str:\n",
        "    \"Answer question related to Vertex AI search and conversation ONLY\"\n",
        "\n",
        "    ## Create response using top N docs\n",
        "    intermediate_steps, final_text, contexts = run_query(question, db, top_n_docs, multiquery=False)\n",
        "\n",
        "    return final_text\n",
        "\n",
        "@tool\n",
        "def google_search(question) -> str:\n",
        "    \"Answer questions related to facts, non-mathematics, but NOT related to Vertex AI search and Conversation\"\n",
        "\n",
        "    ## Create response using top N docs\n",
        "    res = search_tool.run(question)\n",
        "\n",
        "    return str(res)"
      ],
      "metadata": {
        "id": "CbFzblrGPJpx"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the prompt to use - you can modify this!\n",
        "prompt = hub.pull(\"hwchase17/react\")\n",
        "prompt.pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QPdGbZLlYqiL",
        "outputId": "9272b799-0aff-499a-a2f9-e222e0b9d8cf"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer the following questions as best you can. You have access to the following tools:\n",
            "\n",
            "\u001b[33;1m\u001b[1;3m{tools}\u001b[0m\n",
            "\n",
            "Use the following format:\n",
            "\n",
            "Question: the input question you must answer\n",
            "Thought: you should always think about what to do\n",
            "Action: the action to take, should be one of [\u001b[33;1m\u001b[1;3m{tool_names}\u001b[0m]\n",
            "Action Input: the input to the action\n",
            "Observation: the result of the action\n",
            "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
            "Thought: I now know the final answer\n",
            "Final Answer: the final answer to the original input question\n",
            "\n",
            "Begin!\n",
            "\n",
            "Question: \u001b[33;1m\u001b[1;3m{input}\u001b[0m\n",
            "Thought:\u001b[33;1m\u001b[1;3m{agent_scratchpad}\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_new = \"\"\"You are a chat bot ! Answer the following questions as best you can.\n",
        "You have access to the following tools:\n",
        "\n",
        "{tools}\n",
        "\n",
        "and your conversation so far( which might have the answer to the question )\n",
        "\n",
        "Use the following format:\n",
        "\n",
        "To use a tool, please use the following format:\n",
        "\n",
        "Question: the input question you must answer\n",
        "Thought: Do I need to use a tool ? YES\n",
        "Action: the action to take, should be one of the tools: [{tool_names}]\n",
        "Action Input: the input to the action\n",
        "Observation: the result of the action\n",
        "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
        "Thought: I now know the final answer\n",
        "Final Answer: the final answer to the original input question\n",
        "\n",
        "When you have a response to say to the Human, or if you do not need to use a tool, you MUST use the format:\n",
        "\n",
        "```\n",
        "Thought: Do I need to use a tool? NO\n",
        "Final Answer: [your response here]\n",
        "```\n",
        "\n",
        "Rules:\n",
        "1. If tool = 'rag_vertex', then feel free to change the question to only be specific to Vertex AI Search and Conversation\n",
        "2. Use 'scratch pad' to store intermediate results\n",
        "3. In every iteration of Thought/Action/Action Input/Observation, refine the 'current response' to improve the response and evaluate if next thought ieration is needed or not ?\n",
        "4. If the question is completely answered in \"current response\" then DON'T iterate further\n",
        "\n",
        "Begin!\n",
        "\n",
        "Conversation:\n",
        "{chat_history}\n",
        "\n",
        "Question: {input}\n",
        "Thought:{agent_scratchpad}\"\"\"\n",
        "\n",
        "prompt_new = PromptTemplate(\n",
        "    template=prompt_new,\n",
        "    input_variables=[\"tools\", \"tool_names\", \"input\", \"agent_scratchpad\", \"chat_history\"],\n",
        ")"
      ],
      "metadata": {
        "id": "xJtXpaUwnrXO"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_new.pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npcGVs3zu00p",
        "outputId": "ec0143cf-6f87-4a7a-88fb-cbc923be270b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are a chat bot ! Answer the following questions as best you can. \n",
            "You have access to the following tools:\n",
            "\n",
            "\u001b[33;1m\u001b[1;3m{tools}\u001b[0m\n",
            "\n",
            "and your conversation so far( which might have the answer to the question )\n",
            "\n",
            "Use the following format:\n",
            "\n",
            "To use a tool, please use the following format:\n",
            "\n",
            "Question: the input question you must answer\n",
            "Thought: Do I need to use a tool ? YES\n",
            "Action: the action to take, should be one of the tools: [\u001b[33;1m\u001b[1;3m{tool_names}\u001b[0m]\n",
            "Action Input: the input to the action\n",
            "Observation: the result of the action\n",
            "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
            "Thought: I now know the final answer\n",
            "Final Answer: the final answer to the original input question\n",
            "\n",
            "When you have a response to say to the Human, or if you do not need to use a tool, you MUST use the format:\n",
            "\n",
            "```\n",
            "Thought: Do I need to use a tool? NO\n",
            "Final Answer: [your response here]\n",
            "```\n",
            "\n",
            "Rules:\n",
            "1. If tool = 'rag_vertex', then feel free to change the question to only be specific to Vertex AI Search and Conversation\n",
            "2. Use 'scratch pad' to store intermediate results\n",
            "3. In every iteration of Thought/Action/Action Input/Observation, refine the 'current response' to improve the response and evaluate if next thought ieration is needed or not ?\n",
            "4. If the question is completely answered in \"current response\" then DON'T iterate further\n",
            "\n",
            "Begin!\n",
            "\n",
            "Conversation:\n",
            "\u001b[33;1m\u001b[1;3m{chat_history}\u001b[0m\n",
            "\n",
            "Question: \u001b[33;1m\u001b[1;3m{input}\u001b[0m\n",
            "Thought:\u001b[33;1m\u001b[1;3m{agent_scratchpad}\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_history = \"\""
      ],
      "metadata": {
        "id": "l1lgytWQZSQG"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = VertexAI( max_output_tokens=2048, model=\"gemini-1.0-pro\", top_p = 1, temperature = 0)\n",
        "\n",
        "tools_react = [rag_vertex, google_search]\n",
        "# tools_react = [multiply, add, exponentiate, rag_vertex, google_search]"
      ],
      "metadata": {
        "id": "uAllVkjBbKp9"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Construct the ReAct agent\n",
        "agent = create_react_agent(llm, tools_react, prompt_new)"
      ],
      "metadata": {
        "id": "tmv172pgad8c"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an agent executor by passing in the agent and tools\n",
        "agent_executor = AgentExecutor(agent=agent, tools = tools_react, verbose=True)\n",
        "\n",
        "resp = agent_executor.invoke({\n",
        "    \"input\": \"Hi how are you ? How can you help me ?\",\n",
        "    \"chat_history\": chat_history\n",
        "})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5hxa-qaUc5L",
        "outputId": "e79e8629-09f4-4d83-9198-88bf15693395"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m Do I need to use a tool? NO\n",
            "Final Answer: I am doing great! I am a chatbot assistant designed to help you with questions related to Vertex AI Search and Conversation. I can also provide general information and answer questions on a wide range of topics. How can I help you today?\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_history = f\"\"\"\n",
        "{resp[\"chat_history\"]}\n",
        "(Human) {resp[\"input\"]}\n",
        "(Bot) {resp[\"output\"]}\n",
        "\"\"\"\n",
        "\n",
        "print(chat_history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5NGrZOzUeO2",
        "outputId": "f9ccd5d7-27dd-492f-8474-3601fae3ec96"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "(Human) Hi how are you ? How can you help me ?\n",
            "(Bot) I am doing great! I am a chatbot assistant designed to help you with questions related to Vertex AI Search and Conversation. I can also provide general information and answer questions on a wide range of topics. How can I help you today?\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resp = agent_executor.invoke({\n",
        "    \"input\": \"Which all services are currently in preview in Vertex AI Search ? Secondly what is the age of Earth ?\",\n",
        "    \"chat_history\": chat_history\n",
        "})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWM2xX3abEQY",
        "outputId": "3e2e0322-e639-4031-b5da-e73bdbbbd50c"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m Do I need to use a tool? YES\n",
            "Action: rag_vertex\n",
            "Action Input: Which all services are currently in preview in Vertex AI Search ?\u001b[0m\u001b[36;1m\u001b[1;3m The generic recommendations feature and the healthcare data store are currently in preview in Vertex AI Search.\u001b[0m\u001b[32;1m\u001b[1;3m Do I need to use a tool? YES\n",
            "Action: google_search\n",
            "Action Input: what is the age of Earth ?\u001b[0m\u001b[33;1m\u001b[1;3mEarth is estimated to be 4.54 billion years old, plus or minus about 50 million years. Scientists have scoured the Earth searching for the oldest rocks to ... Age of Earth · The age of Earth is estimated to be 4.54 ± 0.05 billion years (4.54 × 109 years ± 1%). · Following the development of radiometric age-dating in ... Oct 19, 2023 ... The examination and analysis of rocks on Earth's surface, and of extraterrestrial rocks, have enabled scientists to determine the ... Jul 9, 2007 ... The results show that the meteorites, and therefore the Solar System, formed between 4.53 and 4.58 billion years ago. ... These calculations ... Today, we know from radiometric dating that Earth is about 4.5 billion years old. ... Had naturalists in the 1700s and 1800s known Earth's true age, early ideas ... Feb 18, 2021 ... An ice age is a period of colder-than-usual global temperatures and bigger-than-usual glaciers and ice sheets. Ice ages don't bring unrelenting ... Indeed, the age of the Earth may be the catchy title of this book, but the real issue is the role of science in influencing our faith, a nonscientific realm. It ... The Planets ; Mercury. Your Mercurian Age ; Venus. Your Venusian Age ; Earth. Your Earth Age ; Mars. Your Martian Age ; Jupiter. Your Jovian Age. Feb 24, 2023 ... The 4.5-billion-year record contained in Earth's continental crust reveals a seven-phase evolution, from an initial magma ocean to the ... Mar 22, 2020 ... Age of Our Earth: 6,000 or 4.5 billion years old? ... One of AIG's most important arguments is that the Earth and the universe are both only 6,000 ...\u001b[0m\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: The generic recommendations feature and the healthcare data store are currently in preview in Vertex AI Search. Additionally, Earth is estimated to be 4.54 billion years old, with a margin of error of approximately 50 million years.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_history = f\"\"\"\n",
        "{resp[\"chat_history\"]}\n",
        "(Human) {resp[\"input\"]}\n",
        "(Bot) {resp[\"output\"]}\n",
        "\"\"\"\n",
        "\n",
        "print(chat_history)"
      ],
      "metadata": {
        "id": "Jhgyimk3YCuJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e79e3135-f6ea-47e1-8d58-cb45251713f1"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "(Human) Hi how are you ? How can you help me ?\n",
            "(Bot) I am doing great! I am a chatbot assistant designed to help you with questions related to Vertex AI Search and Conversation. I can also provide general information and answer questions on a wide range of topics. How can I help you today?\n",
            "\n",
            "(Human) Which all services are currently in preview in Vertex AI Search ? Secondly what is the age of Earth ?\n",
            "(Bot) The generic recommendations feature and the healthcare data store are currently in preview in Vertex AI Search. Additionally, Earth is estimated to be 4.54 billion years old, with a margin of error of approximately 50 million years.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resp = agent_executor.invoke({\n",
        "    \"input\": \"What is the age of Earth ?\",\n",
        "    \"chat_history\": chat_history\n",
        "})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVrL_kbXjmkz",
        "outputId": "7311b648-b428-4c6e-c09a-d68453661220"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m Do I need to use a tool? NO\n",
            "Final Answer: Earth is estimated to be 4.54 billion years old, with a margin of error of approximately 50 million years.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_history = f\"\"\"\n",
        "{resp[\"chat_history\"]}\n",
        "(Human) {resp[\"input\"]}\n",
        "(Bot) {resp[\"output\"]}\n",
        "\"\"\"\n",
        "\n",
        "print(chat_history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlOGLeoJmWUV",
        "outputId": "6fb94a85-286c-4905-97fe-5d5e29597216"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "(Human) Hi how are you ? How can you help me ?\n",
            "(Bot) I am doing great! I am a chatbot assistant designed to help you with questions related to Vertex AI Search and Conversation. I can also provide general information and answer questions on a wide range of topics. How can I help you today?\n",
            "\n",
            "(Human) Which all services are currently in preview in Vertex AI Search ? Secondly what is the age of Earth ?\n",
            "(Bot) The generic recommendations feature and the healthcare data store are currently in preview in Vertex AI Search. Additionally, Earth is estimated to be 4.54 billion years old, with a margin of error of approximately 50 million years.\n",
            "\n",
            "(Human) What is the age of Earth ?\n",
            "(Bot) Earth is estimated to be 4.54 billion years old, with a margin of error of approximately 50 million years.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resp = agent_executor.invoke({\n",
        "    \"input\": \"Which all services are currently in preview in Vertex AI Search ?\",\n",
        "    \"chat_history\": chat_history\n",
        "})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TlHSW-Hij6HF",
        "outputId": "7c2cb30d-7714-4973-c36d-6ea9b5c07465"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m Do I need to use a tool? YES\n",
            "Action: rag_vertex\n",
            "Action Input: Which all services are currently in preview in Vertex AI Search ?\u001b[0m\u001b[36;1m\u001b[1;3m The generic recommendations feature and the healthcare data store are currently in preview in Vertex AI Search.\u001b[0m\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: The generic recommendations feature and the healthcare data store are currently in preview in Vertex AI Search.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_history = f\"\"\"\n",
        "{resp[\"chat_history\"]}\n",
        "(Human) {resp[\"input\"]}\n",
        "(Bot) {resp[\"output\"]}\n",
        "\"\"\"\n",
        "\n",
        "print(chat_history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Toj_9BmkmNrz",
        "outputId": "e5d7edcb-6e4c-4610-bdbc-74b67ab4ce64"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "(Human) Hi how are you ? How can you help me ?\n",
            "(Bot) I am doing great! I am a chatbot assistant designed to help you with questions related to Vertex AI Search and Conversation. I can also provide general information and answer questions on a wide range of topics. How can I help you today?\n",
            "\n",
            "(Human) Which all services are currently in preview in Vertex AI Search ? Secondly what is the age of Earth ?\n",
            "(Bot) The generic recommendations feature and the healthcare data store are currently in preview in Vertex AI Search. Additionally, Earth is estimated to be 4.54 billion years old, with a margin of error of approximately 50 million years.\n",
            "\n",
            "(Human) What is the age of Earth ?\n",
            "(Bot) Earth is estimated to be 4.54 billion years old, with a margin of error of approximately 50 million years.\n",
            "\n",
            "(Human) Which all services are currently in preview in Vertex AI Search ?\n",
            "(Bot) The generic recommendations feature and the healthcare data store are currently in preview in Vertex AI Search.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resp = agent_executor.invoke({\n",
        "    \"input\": \"What is the distance between Krakow and Vienna ?\",\n",
        "    \"chat_history\": chat_history\n",
        "})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSqHvH_nm273",
        "outputId": "3da4f283-d69c-4178-cba2-6cee0756e59e"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m Do I need to use a tool ? YES\n",
            "Action: google_search\n",
            "Action Input: distance between Krakow and Vienna\u001b[0m\u001b[33;1m\u001b[1;3mThe cheapest way to get from Kraków to Vienna costs only €17, and the quickest way takes just 2½ hours. Find the travel option that best suits you. The average journey time by train between Krakow Central and Vienna is 6 hours and 26 minutes, with around 7 trains per day. The journey time may be longer on ... The cheapest way to get from Vienna to Kraków costs only 83 zł, and the quickest way takes just 3 hours. Find the travel option that best suits you. Distance between Krakow and Vienna is 331 kilometers (206 miles). Driving distance from Krakow to Vienna is 464 kilometers (288 miles). Jan 21, 2023 ... This route will take you through the Czech Republic, at a distance of around 465 kilometers, the Krakow to Vienna distance takes around 5–6 ... Getting from Kraków to Vienna is cheap and easy when you travel with FlixBus. The two cities are 291 miles apart and traveling between the two takes as fast as ... How long does it take to travel from Krakow to Vienna? The Krakow to Vienna train travel takes about 5 hours and 12 minutes, no matter when you leave. Travel from Krakow to Vienna by comfortable high-speed train. Check schedule, map, stations, and prices. Book train tickets with Poland trains! Cheap train tickets from Kraków to Vienna can start from as little as $27 (€23) when you book in advance. The average train ticket price for Kraków to Vienna is ... Fastest flight, 50 min, The fastest nonstop flight from Kraków to Vienna takes 50 min. Nonstop flights, Every day, There are direct flights on this route ...\u001b[0m\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: The distance between Krakow and Vienna is approximately 331 kilometers (206 miles) by road and 291 miles by air. The travel time by train can vary between 5 to 6 hours, depending on the train service.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_history = f\"\"\"\n",
        "{resp[\"chat_history\"]}\n",
        "(Human) {resp[\"input\"]}\n",
        "(Bot) {resp[\"output\"]}\n",
        "\"\"\"\n",
        "\n",
        "print(chat_history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-72EqACZm6Xy",
        "outputId": "ef98aee0-422d-443b-e880-c780934f1404"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "(Human) Hi how are you ? How can you help me ?\n",
            "(Bot) I am doing great! I am a chatbot assistant designed to help you with questions related to Vertex AI Search and Conversation. I can also provide general information and answer questions on a wide range of topics. How can I help you today?\n",
            "\n",
            "(Human) Which all services are currently in preview in Vertex AI Search ? Secondly what is the age of Earth ?\n",
            "(Bot) The generic recommendations feature and the healthcare data store are currently in preview in Vertex AI Search. Additionally, Earth is estimated to be 4.54 billion years old, with a margin of error of approximately 50 million years.\n",
            "\n",
            "(Human) What is the age of Earth ?\n",
            "(Bot) Earth is estimated to be 4.54 billion years old, with a margin of error of approximately 50 million years.\n",
            "\n",
            "(Human) Which all services are currently in preview in Vertex AI Search ?\n",
            "(Bot) The generic recommendations feature and the healthcare data store are currently in preview in Vertex AI Search.\n",
            "\n",
            "(Human) What is the distance between Krakow and Vienna ?\n",
            "(Bot) The distance between Krakow and Vienna is approximately 331 kilometers (206 miles) by road and 291 miles by air. The travel time by train can vary between 5 to 6 hours, depending on the train service.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MTc4NiU6oODb"
      },
      "execution_count": 75,
      "outputs": []
    }
  ]
}