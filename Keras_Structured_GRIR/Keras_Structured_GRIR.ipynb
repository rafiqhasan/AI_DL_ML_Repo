{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"GRIR_GCP_Data.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WERKS</th>\n",
       "      <th>SCENARIO</th>\n",
       "      <th>KTOKK</th>\n",
       "      <th>VSTATU</th>\n",
       "      <th>VPATD</th>\n",
       "      <th>EKORG</th>\n",
       "      <th>EKGRP</th>\n",
       "      <th>TOTGRQTY</th>\n",
       "      <th>TOTIRQTY</th>\n",
       "      <th>NODLGR</th>\n",
       "      <th>NODLIR</th>\n",
       "      <th>DIFGRIRD</th>\n",
       "      <th>DIFGRIRV</th>\n",
       "      <th>STATUS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ML01</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>-80</td>\n",
       "      <td>-38100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ML01</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>177</td>\n",
       "      <td>-107</td>\n",
       "      <td>-41600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ML01</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>152</td>\n",
       "      <td>-107</td>\n",
       "      <td>-27600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ML01</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>-96</td>\n",
       "      <td>-13800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ML01</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>192</td>\n",
       "      <td>-146</td>\n",
       "      <td>-73500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  WERKS  SCENARIO  KTOKK  VSTATU  VPATD  EKORG EKGRP  TOTGRQTY  TOTIRQTY  \\\n",
       "0  ML01         3      1       1     30      1     A         0        80   \n",
       "1  ML01         3      1       1     30      1     A         0       107   \n",
       "2  ML01         3      1       1     30      1     A         0       107   \n",
       "3  ML01         3      1       1     30      1     A         0        96   \n",
       "4  ML01         3      1       1     30      1     A         0       146   \n",
       "\n",
       "   NODLGR  NODLIR  DIFGRIRD  DIFGRIRV  STATUS  \n",
       "0       0      90       -80    -38100       1  \n",
       "1       0     177      -107    -41600       0  \n",
       "2       0     152      -107    -27600       1  \n",
       "3       0      79       -96    -13800       1  \n",
       "4       0     192      -146    -73500       0  "
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8279 entries, 0 to 8278\n",
      "Data columns (total 14 columns):\n",
      "WERKS       8279 non-null object\n",
      "SCENARIO    8279 non-null int64\n",
      "KTOKK       8279 non-null int64\n",
      "VSTATU      8279 non-null int64\n",
      "VPATD       8279 non-null int64\n",
      "EKORG       8279 non-null int64\n",
      "EKGRP       8279 non-null object\n",
      "TOTGRQTY    8279 non-null int64\n",
      "TOTIRQTY    8279 non-null int64\n",
      "NODLGR      8279 non-null int64\n",
      "NODLIR      8279 non-null int64\n",
      "DIFGRIRD    8279 non-null int64\n",
      "DIFGRIRV    8279 non-null int64\n",
      "STATUS      8279 non-null int64\n",
      "dtypes: int64(12), object(2)\n",
      "memory usage: 905.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8279 entries, 0 to 8278\n",
      "Data columns (total 14 columns):\n",
      "WERKS       8279 non-null object\n",
      "SCENARIO    8279 non-null category\n",
      "KTOKK       8279 non-null category\n",
      "VSTATU      8279 non-null category\n",
      "VPATD       8279 non-null int64\n",
      "EKORG       8279 non-null category\n",
      "EKGRP       8279 non-null object\n",
      "TOTGRQTY    8279 non-null int64\n",
      "TOTIRQTY    8279 non-null int64\n",
      "NODLGR      8279 non-null int64\n",
      "NODLIR      8279 non-null int64\n",
      "DIFGRIRD    8279 non-null int64\n",
      "DIFGRIRV    8279 non-null int64\n",
      "STATUS      8279 non-null int64\n",
      "dtypes: category(4), int64(8), object(2)\n",
      "memory usage: 679.7+ KB\n"
     ]
    }
   ],
   "source": [
    "#Mark some columns as categorical\n",
    "for col_cat in ['SCENARIO','KTOKK','VSTATU','EKORG']:\n",
    "    df[col_cat] = df[col_cat].astype('category')\n",
    "    \n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare train and output columns\n",
    "df_x = df.drop(['STATUS'],axis=1)\n",
    "df_y = df['STATUS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DIFGRIRD</th>\n",
       "      <th>DIFGRIRV</th>\n",
       "      <th>EKORG</th>\n",
       "      <th>KTOKK</th>\n",
       "      <th>NODLGR</th>\n",
       "      <th>NODLIR</th>\n",
       "      <th>Random</th>\n",
       "      <th>SCENARIO</th>\n",
       "      <th>TOTGRQTY</th>\n",
       "      <th>TOTIRQTY</th>\n",
       "      <th>VPATD</th>\n",
       "      <th>VSTATU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.865186</td>\n",
       "      <td>0.850320</td>\n",
       "      <td>0.996530</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997738</td>\n",
       "      <td>0.485958</td>\n",
       "      <td>0</td>\n",
       "      <td>0.879783</td>\n",
       "      <td>0.194014</td>\n",
       "      <td>0.338620</td>\n",
       "      <td>0.990500</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.987979</td>\n",
       "      <td>0.835343</td>\n",
       "      <td>0.996530</td>\n",
       "      <td>0.787057</td>\n",
       "      <td>0.830635</td>\n",
       "      <td>0.727003</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.596619</td>\n",
       "      <td>0.107376</td>\n",
       "      <td>0.989171</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.614764</td>\n",
       "      <td>0.205466</td>\n",
       "      <td>0.999289</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.093186</td>\n",
       "      <td>0.209803</td>\n",
       "      <td>2</td>\n",
       "      <td>0.711002</td>\n",
       "      <td>0.312491</td>\n",
       "      <td>0.797120</td>\n",
       "      <td>0.665292</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.287316</td>\n",
       "      <td>0.358338</td>\n",
       "      <td>0.774537</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.038072</td>\n",
       "      <td>0.248484</td>\n",
       "      <td>3</td>\n",
       "      <td>0.709403</td>\n",
       "      <td>0.027086</td>\n",
       "      <td>0.894614</td>\n",
       "      <td>0.999331</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.061270</td>\n",
       "      <td>0.108989</td>\n",
       "      <td>0.922054</td>\n",
       "      <td>0.959982</td>\n",
       "      <td>0.549862</td>\n",
       "      <td>0.205517</td>\n",
       "      <td>4</td>\n",
       "      <td>0.205517</td>\n",
       "      <td>0.544833</td>\n",
       "      <td>0.205517</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.640502</td>\n",
       "      <td>0.501720</td>\n",
       "      <td>0.414625</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.776710</td>\n",
       "      <td>0.514906</td>\n",
       "      <td>5</td>\n",
       "      <td>0.975722</td>\n",
       "      <td>0.791521</td>\n",
       "      <td>0.587118</td>\n",
       "      <td>0.997557</td>\n",
       "      <td>0.982422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.286878</td>\n",
       "      <td>0.179726</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999825</td>\n",
       "      <td>0.957352</td>\n",
       "      <td>0.895561</td>\n",
       "      <td>6</td>\n",
       "      <td>0.881185</td>\n",
       "      <td>0.739157</td>\n",
       "      <td>0.430504</td>\n",
       "      <td>0.881883</td>\n",
       "      <td>0.998032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.922265</td>\n",
       "      <td>0.890104</td>\n",
       "      <td>0.275618</td>\n",
       "      <td>0.980325</td>\n",
       "      <td>0.810987</td>\n",
       "      <td>0.996811</td>\n",
       "      <td>7</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.562305</td>\n",
       "      <td>0.287610</td>\n",
       "      <td>0.698262</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.549601</td>\n",
       "      <td>0.666214</td>\n",
       "      <td>0.714640</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.941271</td>\n",
       "      <td>0.227629</td>\n",
       "      <td>8</td>\n",
       "      <td>0.825911</td>\n",
       "      <td>0.769461</td>\n",
       "      <td>0.882082</td>\n",
       "      <td>0.708470</td>\n",
       "      <td>0.998032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.499860</td>\n",
       "      <td>0.953603</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.109492</td>\n",
       "      <td>0.504285</td>\n",
       "      <td>0.447540</td>\n",
       "      <td>9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.869874</td>\n",
       "      <td>0.665397</td>\n",
       "      <td>0.987354</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DIFGRIRD  DIFGRIRV     EKORG     KTOKK    NODLGR    NODLIR  Random  \\\n",
       "0  0.865186  0.850320  0.996530  1.000000  0.997738  0.485958       0   \n",
       "1  0.987979  0.835343  0.996530  0.787057  0.830635  0.727003       1   \n",
       "2  0.614764  0.205466  0.999289  1.000000  0.093186  0.209803       2   \n",
       "3  0.287316  0.358338  0.774537  0.999998  0.038072  0.248484       3   \n",
       "4  0.061270  0.108989  0.922054  0.959982  0.549862  0.205517       4   \n",
       "5  0.640502  0.501720  0.414625  1.000000  0.776710  0.514906       5   \n",
       "6  0.286878  0.179726  1.000000  0.999825  0.957352  0.895561       6   \n",
       "7  0.922265  0.890104  0.275618  0.980325  0.810987  0.996811       7   \n",
       "8  0.549601  0.666214  0.714640  0.999998  0.941271  0.227629       8   \n",
       "9  0.499860  0.953603  1.000000  0.109492  0.504285  0.447540       9   \n",
       "\n",
       "   SCENARIO  TOTGRQTY  TOTIRQTY     VPATD    VSTATU  \n",
       "0  0.879783  0.194014  0.338620  0.990500  1.000000  \n",
       "1  0.999995  0.596619  0.107376  0.989171  1.000000  \n",
       "2  0.711002  0.312491  0.797120  0.665292  1.000000  \n",
       "3  0.709403  0.027086  0.894614  0.999331  1.000000  \n",
       "4  0.205517  0.544833  0.205517  1.000000  0.998587  \n",
       "5  0.975722  0.791521  0.587118  0.997557  0.982422  \n",
       "6  0.881185  0.739157  0.430504  0.881883  0.998032  \n",
       "7  0.999995  0.562305  0.287610  0.698262  0.999999  \n",
       "8  0.825911  0.769461  0.882082  0.708470  0.998032  \n",
       "9  1.000000  0.869874  0.665397  0.987354  1.000000  "
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Split dataset -> Split 10 times and choose the one with best P values( Significance test )\n",
    "p_res = {}\n",
    "t_res = []\n",
    "for i in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_x, df_y, test_size=0.1, random_state=i,stratify=df_y)\n",
    "\n",
    "    #Run Significance Tests on both the distributions( Train and Test ) for all numerical attributes\n",
    "    p_res = {}\n",
    "    for c_ in X_train.columns:\n",
    "        if not X_train[c_].dtype == 'object':\n",
    "            try:\n",
    "                _, a = scipy.stats.ks_2samp(X_train[c_].values,X_test[c_].values)\n",
    "                #print('P-value for column {} is {}'.format(c_.upper(), a))\n",
    "                p_res['Random'] = i\n",
    "                p_res[c_] = a\n",
    "            except:\n",
    "                p_res['Random'] = i\n",
    "                p_res[c_] = 'Error'\n",
    "    t_res.append(p_res)\n",
    "\n",
    "p_df = pd.DataFrame(t_res)\n",
    "p_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7451 entries, 692 to 315\n",
      "Data columns (total 13 columns):\n",
      "WERKS       7451 non-null object\n",
      "SCENARIO    7451 non-null category\n",
      "KTOKK       7451 non-null category\n",
      "VSTATU      7451 non-null category\n",
      "VPATD       7451 non-null int64\n",
      "EKORG       7451 non-null category\n",
      "EKGRP       7451 non-null object\n",
      "TOTGRQTY    7451 non-null int64\n",
      "TOTIRQTY    7451 non-null int64\n",
      "NODLGR      7451 non-null int64\n",
      "NODLIR      7451 non-null int64\n",
      "DIFGRIRD    7451 non-null int64\n",
      "DIFGRIRV    7451 non-null int64\n",
      "dtypes: category(4), int64(7), object(2)\n",
      "memory usage: 611.7+ KB\n"
     ]
    }
   ],
   "source": [
    "#Split Train and Validation\n",
    "\n",
    "#Use the best split value from above after manual inspection\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_x, df_y, test_size=0.1, random_state=8,stratify=df_y)\n",
    "x_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "268"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train['NODLGR'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hrafiq\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "c:\\users\\hrafiq\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "c:\\users\\hrafiq\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "c:\\users\\hrafiq\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VPATD</th>\n",
       "      <th>TOTGRQTY</th>\n",
       "      <th>TOTIRQTY</th>\n",
       "      <th>NODLGR</th>\n",
       "      <th>NODLIR</th>\n",
       "      <th>DIFGRIRD</th>\n",
       "      <th>DIFGRIRV</th>\n",
       "      <th>grminusirbyvpatd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7451.000000</td>\n",
       "      <td>7451.000000</td>\n",
       "      <td>7451.000000</td>\n",
       "      <td>7451.000000</td>\n",
       "      <td>7451.000000</td>\n",
       "      <td>7451.000000</td>\n",
       "      <td>7451.000000</td>\n",
       "      <td>7451.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.506039</td>\n",
       "      <td>0.329276</td>\n",
       "      <td>0.470508</td>\n",
       "      <td>0.384943</td>\n",
       "      <td>0.370619</td>\n",
       "      <td>0.626838</td>\n",
       "      <td>0.509348</td>\n",
       "      <td>-0.578462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.405868</td>\n",
       "      <td>0.314870</td>\n",
       "      <td>0.312830</td>\n",
       "      <td>0.306502</td>\n",
       "      <td>0.311038</td>\n",
       "      <td>0.231224</td>\n",
       "      <td>0.169547</td>\n",
       "      <td>1.439549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-6.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043388</td>\n",
       "      <td>0.525547</td>\n",
       "      <td>0.488085</td>\n",
       "      <td>-0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>0.495000</td>\n",
       "      <td>0.417910</td>\n",
       "      <td>0.338843</td>\n",
       "      <td>0.722628</td>\n",
       "      <td>0.554560</td>\n",
       "      <td>-0.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.605000</td>\n",
       "      <td>0.735000</td>\n",
       "      <td>0.641791</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.770073</td>\n",
       "      <td>0.599851</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             VPATD     TOTGRQTY     TOTIRQTY       NODLGR       NODLIR  \\\n",
       "count  7451.000000  7451.000000  7451.000000  7451.000000  7451.000000   \n",
       "mean      0.506039     0.329276     0.470508     0.384943     0.370619   \n",
       "std       0.405868     0.314870     0.312830     0.306502     0.311038   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.270000     0.000000     0.043388   \n",
       "50%       0.500000     0.275000     0.495000     0.417910     0.338843   \n",
       "75%       1.000000     0.605000     0.735000     0.641791     0.636364   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "          DIFGRIRD     DIFGRIRV  grminusirbyvpatd  \n",
       "count  7451.000000  7451.000000       7451.000000  \n",
       "mean      0.626838     0.509348         -0.578462  \n",
       "std       0.231224     0.169547          1.439549  \n",
       "min       0.000000     0.000000         -6.666667  \n",
       "25%       0.525547     0.488085         -0.833333  \n",
       "50%       0.722628     0.554560         -0.033333  \n",
       "75%       0.770073     0.599851          0.200000  \n",
       "max       1.000000     1.000000          1.666667  "
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Feature engineering steps\n",
    "x_train['grminusirbyvpatd'] = ( x_train['TOTGRQTY'] - x_train['TOTIRQTY'] ) / x_train['VPATD']\n",
    "x_test['grminusirbyvpatd'] = ( x_test['TOTGRQTY'] - x_test['TOTIRQTY'] ) / x_test['VPATD']\n",
    "\n",
    "#min max scaling\n",
    "for c_ in ['VPATD','TOTGRQTY','TOTIRQTY','NODLGR','NODLIR','DIFGRIRD','DIFGRIRV']:\n",
    "    mini = x_train[c_].min()\n",
    "    maxi = x_train[c_].max()\n",
    "    \n",
    "    x_train[c_] = (x_train[c_] - mini) / (maxi - mini)\n",
    "    x_test[c_] = (x_test[c_] - mini) / (maxi - mini)\n",
    "    \n",
    "x_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7451, 14)"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7451, 24)\n",
      "(828, 24)\n"
     ]
    }
   ],
   "source": [
    "#One hot encoders\n",
    "x_train = pd.get_dummies(x_train)\n",
    "x_test = pd.get_dummies(x_test)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "###Create keras Model\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=x_train.shape[1], activation='relu',kernel_initializer='he_uniform'))\n",
    "model.add(Dense(32, activation='relu',kernel_initializer='he_uniform'))\n",
    "model.add(Dense(128, activation='relu',kernel_initializer='he_uniform'))\n",
    "# model.add(Dense(32, activation='relu',kernel_initializer='he_uniform'))\n",
    "model.add(Dense(1,   activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',  optimizer=Adam(lr= 0.01), metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_254 (Dense)            (None, 32)                800       \n",
      "_________________________________________________________________\n",
      "dense_255 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_256 (Dense)            (None, 128)               4224      \n",
      "_________________________________________________________________\n",
      "dense_257 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 6,209\n",
      "Trainable params: 6,209\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7451 samples, validate on 828 samples\n",
      "Epoch 1/100\n",
      "7451/7451 [==============================] - 2s 295us/step - loss: 0.6548 - acc: 0.6363 - val_loss: 0.5966 - val_acc: 0.6775\n",
      "Epoch 2/100\n",
      "7451/7451 [==============================] - 0s 11us/step - loss: 0.5306 - acc: 0.7261 - val_loss: 0.5378 - val_acc: 0.7234\n",
      "Epoch 3/100\n",
      "7451/7451 [==============================] - 0s 11us/step - loss: 0.4782 - acc: 0.7568 - val_loss: 0.4808 - val_acc: 0.7440\n",
      "Epoch 4/100\n",
      "7451/7451 [==============================] - 0s 11us/step - loss: 0.4065 - acc: 0.8054 - val_loss: 0.4604 - val_acc: 0.7645\n",
      "Epoch 5/100\n",
      "7451/7451 [==============================] - 0s 12us/step - loss: 0.3485 - acc: 0.8412 - val_loss: 0.3581 - val_acc: 0.8321\n",
      "Epoch 6/100\n",
      "7451/7451 [==============================] - 0s 12us/step - loss: 0.2983 - acc: 0.8700 - val_loss: 0.3327 - val_acc: 0.8478\n",
      "Epoch 7/100\n",
      "7451/7451 [==============================] - 0s 12us/step - loss: 0.2903 - acc: 0.8755 - val_loss: 0.3071 - val_acc: 0.8720\n",
      "Epoch 8/100\n",
      "7451/7451 [==============================] - 0s 14us/step - loss: 0.2622 - acc: 0.8847 - val_loss: 0.3332 - val_acc: 0.8539\n",
      "Epoch 9/100\n",
      "7451/7451 [==============================] - 0s 24us/step - loss: 0.2580 - acc: 0.8875 - val_loss: 0.2942 - val_acc: 0.8623\n",
      "Epoch 10/100\n",
      "7451/7451 [==============================] - 0s 17us/step - loss: 0.2519 - acc: 0.8883 - val_loss: 0.2979 - val_acc: 0.8611\n",
      "Epoch 11/100\n",
      "7451/7451 [==============================] - 0s 13us/step - loss: 0.2521 - acc: 0.8909 - val_loss: 0.3039 - val_acc: 0.8732\n",
      "Epoch 12/100\n",
      "7451/7451 [==============================] - 0s 13us/step - loss: 0.2332 - acc: 0.8967 - val_loss: 0.2907 - val_acc: 0.8659\n",
      "Epoch 13/100\n",
      "7451/7451 [==============================] - 0s 12us/step - loss: 0.2283 - acc: 0.9020 - val_loss: 0.2665 - val_acc: 0.8877\n",
      "Epoch 14/100\n",
      "7451/7451 [==============================] - 0s 12us/step - loss: 0.2074 - acc: 0.9106 - val_loss: 0.2639 - val_acc: 0.8804\n",
      "Epoch 15/100\n",
      "7451/7451 [==============================] - 0s 15us/step - loss: 0.2055 - acc: 0.9103 - val_loss: 0.2667 - val_acc: 0.8829\n",
      "Epoch 16/100\n",
      "7451/7451 [==============================] - 0s 23us/step - loss: 0.2026 - acc: 0.9106 - val_loss: 0.2417 - val_acc: 0.8998\n",
      "Epoch 17/100\n",
      "7451/7451 [==============================] - 0s 13us/step - loss: 0.2023 - acc: 0.9095 - val_loss: 0.3018 - val_acc: 0.8780\n",
      "Epoch 18/100\n",
      "7451/7451 [==============================] - 0s 15us/step - loss: 0.2198 - acc: 0.9048 - val_loss: 0.2399 - val_acc: 0.8913\n",
      "Epoch 19/100\n",
      "7451/7451 [==============================] - 0s 19us/step - loss: 0.2046 - acc: 0.9094 - val_loss: 0.2444 - val_acc: 0.8877\n",
      "Epoch 20/100\n",
      "7451/7451 [==============================] - 0s 22us/step - loss: 0.1853 - acc: 0.9205 - val_loss: 0.2273 - val_acc: 0.9046\n",
      "Epoch 21/100\n",
      "7451/7451 [==============================] - 0s 22us/step - loss: 0.1813 - acc: 0.9244 - val_loss: 0.2177 - val_acc: 0.9034\n",
      "Epoch 22/100\n",
      "7451/7451 [==============================] - 0s 16us/step - loss: 0.1908 - acc: 0.9150 - val_loss: 0.2410 - val_acc: 0.8986\n",
      "Epoch 23/100\n",
      "7451/7451 [==============================] - 0s 15us/step - loss: 0.1863 - acc: 0.9184 - val_loss: 0.2437 - val_acc: 0.8889\n",
      "Epoch 24/100\n",
      "7451/7451 [==============================] - 0s 13us/step - loss: 0.1833 - acc: 0.9239 - val_loss: 0.2178 - val_acc: 0.9046\n",
      "Epoch 25/100\n",
      "7451/7451 [==============================] - 0s 14us/step - loss: 0.1792 - acc: 0.9207 - val_loss: 0.2168 - val_acc: 0.8986\n",
      "Epoch 26/100\n",
      "7451/7451 [==============================] - 0s 13us/step - loss: 0.1807 - acc: 0.9222 - val_loss: 0.2536 - val_acc: 0.8925\n",
      "Epoch 27/100\n",
      "7451/7451 [==============================] - 0s 21us/step - loss: 0.1786 - acc: 0.9228 - val_loss: 0.2001 - val_acc: 0.9070\n",
      "Epoch 28/100\n",
      "7451/7451 [==============================] - 0s 16us/step - loss: 0.1587 - acc: 0.9321 - val_loss: 0.2065 - val_acc: 0.9130\n",
      "Epoch 29/100\n",
      "7451/7451 [==============================] - 0s 14us/step - loss: 0.1689 - acc: 0.9262 - val_loss: 0.2328 - val_acc: 0.8961\n",
      "Epoch 30/100\n",
      "7451/7451 [==============================] - 0s 16us/step - loss: 0.1732 - acc: 0.9261 - val_loss: 0.2080 - val_acc: 0.9082\n",
      "Epoch 31/100\n",
      "7451/7451 [==============================] - 0s 17us/step - loss: 0.1523 - acc: 0.9318 - val_loss: 0.1874 - val_acc: 0.9167\n",
      "Epoch 32/100\n",
      "7451/7451 [==============================] - 0s 20us/step - loss: 0.1558 - acc: 0.9324 - val_loss: 0.2055 - val_acc: 0.9070\n",
      "Epoch 33/100\n",
      "7451/7451 [==============================] - 0s 23us/step - loss: 0.1540 - acc: 0.9321 - val_loss: 0.2094 - val_acc: 0.8998\n",
      "Epoch 34/100\n",
      "7451/7451 [==============================] - 0s 19us/step - loss: 0.1548 - acc: 0.9328 - val_loss: 0.2015 - val_acc: 0.9034\n",
      "Epoch 35/100\n",
      "7451/7451 [==============================] - 0s 17us/step - loss: 0.1492 - acc: 0.9358 - val_loss: 0.2122 - val_acc: 0.9094\n",
      "Epoch 36/100\n",
      "7451/7451 [==============================] - 0s 16us/step - loss: 0.1626 - acc: 0.9291 - val_loss: 0.2140 - val_acc: 0.9106\n",
      "Epoch 37/100\n",
      "7451/7451 [==============================] - 0s 15us/step - loss: 0.1469 - acc: 0.9373 - val_loss: 0.1782 - val_acc: 0.9215\n",
      "Epoch 38/100\n",
      "7451/7451 [==============================] - 0s 14us/step - loss: 0.1411 - acc: 0.9391 - val_loss: 0.1889 - val_acc: 0.9167\n",
      "Epoch 39/100\n",
      "7451/7451 [==============================] - 0s 23us/step - loss: 0.1399 - acc: 0.9363 - val_loss: 0.1892 - val_acc: 0.9215\n",
      "Epoch 40/100\n",
      "7451/7451 [==============================] - 0s 19us/step - loss: 0.1326 - acc: 0.9416 - val_loss: 0.1598 - val_acc: 0.9167\n",
      "Epoch 41/100\n",
      "7451/7451 [==============================] - 0s 14us/step - loss: 0.1278 - acc: 0.9439 - val_loss: 0.1863 - val_acc: 0.9167\n",
      "Epoch 42/100\n",
      "7451/7451 [==============================] - 0s 14us/step - loss: 0.1239 - acc: 0.9450 - val_loss: 0.1752 - val_acc: 0.9239\n",
      "Epoch 43/100\n",
      "7451/7451 [==============================] - 0s 14us/step - loss: 0.1288 - acc: 0.9442 - val_loss: 0.1672 - val_acc: 0.9167\n",
      "Epoch 44/100\n",
      "7451/7451 [==============================] - 0s 13us/step - loss: 0.1385 - acc: 0.9385 - val_loss: 0.1873 - val_acc: 0.9118\n",
      "Epoch 45/100\n",
      "7451/7451 [==============================] - 0s 22us/step - loss: 0.1324 - acc: 0.9403 - val_loss: 0.1752 - val_acc: 0.9191\n",
      "Epoch 46/100\n",
      "7451/7451 [==============================] - 0s 20us/step - loss: 0.1243 - acc: 0.9462 - val_loss: 0.1706 - val_acc: 0.9191\n",
      "Epoch 47/100\n",
      "7451/7451 [==============================] - 0s 13us/step - loss: 0.1230 - acc: 0.9447 - val_loss: 0.1679 - val_acc: 0.9215\n",
      "Epoch 48/100\n",
      "7451/7451 [==============================] - 0s 13us/step - loss: 0.1135 - acc: 0.9538 - val_loss: 0.1779 - val_acc: 0.9227\n",
      "Epoch 49/100\n",
      "7451/7451 [==============================] - 0s 14us/step - loss: 0.1114 - acc: 0.9514 - val_loss: 0.1773 - val_acc: 0.9130\n",
      "Epoch 50/100\n",
      "7451/7451 [==============================] - 0s 15us/step - loss: 0.1216 - acc: 0.9483 - val_loss: 0.1532 - val_acc: 0.9275\n",
      "Epoch 51/100\n",
      "7451/7451 [==============================] - 0s 20us/step - loss: 0.1134 - acc: 0.9509 - val_loss: 0.1732 - val_acc: 0.9263\n",
      "Epoch 52/100\n",
      "7451/7451 [==============================] - 0s 15us/step - loss: 0.1132 - acc: 0.9485 - val_loss: 0.1504 - val_acc: 0.9324\n",
      "Epoch 53/100\n",
      "7451/7451 [==============================] - 0s 13us/step - loss: 0.1070 - acc: 0.9562 - val_loss: 0.1601 - val_acc: 0.9239\n",
      "Epoch 54/100\n",
      "7451/7451 [==============================] - 0s 13us/step - loss: 0.1061 - acc: 0.9552 - val_loss: 0.1613 - val_acc: 0.9312\n",
      "Epoch 55/100\n",
      "7451/7451 [==============================] - 0s 14us/step - loss: 0.1207 - acc: 0.9499 - val_loss: 0.1777 - val_acc: 0.9143\n",
      "Epoch 56/100\n",
      "7451/7451 [==============================] - 0s 13us/step - loss: 0.1280 - acc: 0.9458 - val_loss: 0.2331 - val_acc: 0.9022\n",
      "Epoch 57/100\n",
      "7451/7451 [==============================] - 0s 12us/step - loss: 0.1171 - acc: 0.9478 - val_loss: 0.2022 - val_acc: 0.9118\n",
      "Epoch 58/100\n",
      "7451/7451 [==============================] - 0s 14us/step - loss: 0.1317 - acc: 0.9426 - val_loss: 0.1857 - val_acc: 0.9191\n",
      "Epoch 59/100\n",
      "7451/7451 [==============================] - 0s 13us/step - loss: 0.1118 - acc: 0.9516 - val_loss: 0.1737 - val_acc: 0.9191\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7451/7451 [==============================] - 0s 14us/step - loss: 0.0994 - acc: 0.9562 - val_loss: 0.2014 - val_acc: 0.9070\n",
      "Epoch 61/100\n",
      "7451/7451 [==============================] - 0s 14us/step - loss: 0.1002 - acc: 0.9567 - val_loss: 0.1509 - val_acc: 0.9384\n",
      "Epoch 62/100\n",
      "7451/7451 [==============================] - 0s 13us/step - loss: 0.1218 - acc: 0.9458 - val_loss: 0.2038 - val_acc: 0.8998\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21eaf1f6a20>"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=100, batch_size=512, \n",
    "          callbacks=[keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
