{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d91a2ce483074838a077d2481f038385": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_70a1b00825ca47a1a9d403164ef38420",
              "IPY_MODEL_57af0b9dc81b42429ac29430672c553b",
              "IPY_MODEL_962a2be6393b48258f7fa7694593e80d"
            ],
            "layout": "IPY_MODEL_5ccde1c5b3bf479ca5bd842f8c326d1c"
          }
        },
        "70a1b00825ca47a1a9d403164ef38420": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1390490d09c345b89683a0ee2a320723",
            "placeholder": "​",
            "style": "IPY_MODEL_052df76f0cca407f9835fb6051c346f3",
            "value": "Evaluating: 100%"
          }
        },
        "57af0b9dc81b42429ac29430672c553b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53120f2f334e4b3d8b53950828052e68",
            "max": 12,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dfcbc471858e430ea009462e779f15eb",
            "value": 12
          }
        },
        "962a2be6393b48258f7fa7694593e80d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9019ef41db24a2b9fe36a8a2cb91757",
            "placeholder": "​",
            "style": "IPY_MODEL_9d2026d84ec84e15910238825302b9bc",
            "value": " 12/12 [00:21&lt;00:00,  3.01s/it]"
          }
        },
        "5ccde1c5b3bf479ca5bd842f8c326d1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1390490d09c345b89683a0ee2a320723": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "052df76f0cca407f9835fb6051c346f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "53120f2f334e4b3d8b53950828052e68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfcbc471858e430ea009462e779f15eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b9019ef41db24a2b9fe36a8a2cb91757": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d2026d84ec84e15910238825302b9bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# RAG - Implementation and Evaluation\n",
        "\n",
        "## Goal:\n",
        "\n",
        "- Build notebook to do RAG wth LangChain\n",
        "- Evaluation\n",
        "\n",
        "By: Hasan Rafiq"
      ],
      "metadata": {
        "id": "QWJtdgwJ39wk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installing the package"
      ],
      "metadata": {
        "id": "T_pLQeNp36mA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-cloud-aiplatform --upgrade --user\n",
        "!pip install langchain langchain-core langchain-google-vertexai faiss-cpu ragas"
      ],
      "metadata": {
        "id": "XOPSCwGu38W7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Authenticate again"
      ],
      "metadata": {
        "id": "SEg9gRnl4iz7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth as google_auth\n",
        "google_auth.authenticate_user()"
      ],
      "metadata": {
        "id": "xTOySbcM4gFp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PROJECT_ID = \"<YOUR PROJECT ID>\"  # @param {type:\"string\"}\n",
        "LOCATION = \"us-central1\"  # @param {type:\"string\"}"
      ],
      "metadata": {
        "id": "cKcun6Kf4z2K"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import aiplatform\n",
        "# from vertexai.preview.language_models import TextGenerationModel, ChatModel\n",
        "from vertexai.generative_models import GenerativeModel, Part, ChatSession, Image, FunctionDeclaration, Tool, Content\n",
        "from langchain_google_vertexai import VertexAI\n",
        "import http.client\n",
        "import typing\n",
        "import urllib.request\n",
        "import pandas as pd\n",
        "\n",
        "from google.cloud import aiplatform, storage\n",
        "from vertexai.preview.language_models import TextGenerationModel, ChatModel, TextEmbeddingModel\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "import pprint\n",
        "import re\n",
        "import io\n",
        "\n",
        "from langchain.llms import VertexAI\n",
        "from langchain import hub\n",
        "from langchain.text_splitter import TextSplitter, CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
        "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.document_loaders import TextLoader, GCSFileLoader\n",
        "from langchain.embeddings import VertexAIEmbeddings\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "from langchain.chains.mapreduce import MapReduceChain\n",
        "from langchain.chains import ReduceDocumentsChain, MapReduceDocumentsChain\n",
        "from langchain.chains.llm import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "from ragas.metrics import (\n",
        "    answer_relevancy,\n",
        "    faithfulness,\n",
        "    context_recall,\n",
        "    context_precision,\n",
        "    context_entity_recall,\n",
        "    answer_correctness\n",
        ")\n",
        "from datasets import Dataset\n",
        "from ragas import evaluate\n",
        "\n",
        "aiplatform.init(project=PROJECT_ID, location=LOCATION)"
      ],
      "metadata": {
        "id": "aJjzXsFY45oe"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implement a RAG"
      ],
      "metadata": {
        "id": "vnDIpgHX48ZH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Source text"
      ],
      "metadata": {
        "id": "w891IFzU4_Yt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "document = [\"\"\"\n",
        "Information retrieval using AI and LLMs\n",
        "Vertex AI Search brings together the power of deep information retrieval, state-of-the-art natural language processing, and the latest in large language model (LLM) processing to understand user intent and return the most relevant results for the user.\n",
        "\n",
        "With Vertex AI Search, you can build a Google-quality search app on your own data and embed a search bar in your web pages or app.\n",
        "\n",
        "With Recommendations, you can build a recommendations app on your own data that will suggest content similar to the content that the user is currently viewing.\n",
        "\n",
        "Note: The generic recommendations feature is a Preview offering, subject to the \"Pre-GA Offerings Terms\" of the GCP Service Specific Terms. Pre-GA products and features may have limited support, and changes to pre-GA products and features may not be compatible with other pre-GA versions. For more information, see the launch stage descriptions. Further, by using this feature, you agree to the Generative AI Preview terms and conditions (\"Preview Terms\"). For this feature, you can process personal data as outlined in the Cloud Data Processing Addendum, subject to applicable restrictions and obligations in the Agreement (as defined in the Preview Terms).\n",
        "An easy experience to get started\n",
        "Vertex AI Search makes it easy to get started with high-quality search or recommendations based on data that you provide. As part of the setup experience, you can:\n",
        "\n",
        "Use your existing Google Account or sign up for one.\n",
        "Use your existing Google Cloud project or create one.\n",
        "Create an app and attach a data store to it. Provide data to search or recommend by entering the URLs for your website content, importing your data from BigQuery or Cloud Storage, or importing FHIR R4 data from Cloud Healthcare API, or uploading through RESTful CRUD APIs. Syncing data from Jira, Salesforce, or Confluence is available in Preview with allowlist.\n",
        "Embed JavaScript widgets and API samples to integrate search or recommendations into your website or applications.\n",
        "Data stores and apps\n",
        "With Vertex AI Search, you create a search or recommendations app and attach it to a data store. You import your data into a data store and index your data. Apps and data stores have a one-to-one relationship.\n",
        "\n",
        "There are various kinds of data stores that you can create, based on the type of data you use. Each data store can contain one type of data:\n",
        "\n",
        "Website data: You can provide domains such as yourexamplewebsite.com/faq and yourexamplewebsite.com/events and enable search or recommendations over the content at those domains.\n",
        "Structured data: A data store with structured data enables semantic search or recommendations over structured data such as a BigQuery table or NDJSON files. For example, you can enable search or recommendations over a product catalog for your ecommerce experience, a movie catalog for movie search or recommendations, or a directory of doctors for provider search or recommendations.\n",
        "Unstructured data: An unstructured data store enables semantic search or recommendations over data such as documents and images. For example, a financial institution can enable search or recommendations over their private corpus of financial research publications, or a biotech company can enable search or recommendations over their private repository of medical research.\n",
        "Healthcare data: A healthcare data store enables semantic search over healthcare FHIR R4 data imported from Cloud Healthcare API. For example, a healthcare provider can search over a patient's clinical history using exploratory queries.\n",
        "\"\"\"]"
      ],
      "metadata": {
        "id": "1K5nNCjc47UQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create helper functions"
      ],
      "metadata": {
        "id": "z1itUHeG5Ibv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Gemini model\n",
        "model = VertexAI( max_output_tokens=2048, model=\"gemini-1.0-pro\", top_p = 1, temperature = 0)\n",
        "llm_embeddings = VertexAIEmbeddings()\n",
        "\n",
        "def chunk_text(input_texts, separator=\"\", chunk_size=100, overlap=20):\n",
        "  ## Create split of texts on a chunk\n",
        "  text_splitter = CharacterTextSplitter(separator=\"\", chunk_size=chunk_size, chunk_overlap=overlap)\n",
        "  chunks = text_splitter.create_documents(input_texts)\n",
        "\n",
        "  return chunks\n",
        "\n",
        "def create_vector_store(chunks):\n",
        "  ## Create vector store from embeddings\n",
        "  db = FAISS.from_documents(chunks, llm_embeddings)\n",
        "\n",
        "  return db\n",
        "\n",
        "# def query_vector_store(query, db, top_n_docs=5):\n",
        "#   docs = db.similarity_search(query, k=top_n_docs)\n",
        "\n",
        "#   return docs\n",
        "\n",
        "def query_vector_store(query, db, top_n_docs, multiquery):\n",
        "  if multiquery:\n",
        "    retriever_from_llm = MultiQueryRetriever.from_llm(\n",
        "      retriever=db.as_retriever(search_kwargs={\"k\": top_n_docs}), llm=model\n",
        "    )\n",
        "    docs = retriever_from_llm.get_relevant_documents(query=query)\n",
        "  else:\n",
        "    retriever = db.as_retriever(search_kwargs={\"k\": top_n_docs})\n",
        "    docs = retriever.get_relevant_documents(query)\n",
        "\n",
        "  return docs\n",
        "\n",
        "def create_with_refine(input_chunks, title):\n",
        "  prompt_template = \"\"\"Respond as per following instructions:\n",
        "  {text}\n",
        "  CONCISE SUMMARY:\"\"\"\n",
        "  prompt = PromptTemplate.from_template(prompt_template)\n",
        "\n",
        "  refine_template = (\n",
        "      \"\"\"\n",
        "      You are a QnA bot meant to answer questions ONLY from the contexts provided below and NO PRIOR knowledge\n",
        "\n",
        "      Question:\n",
        "      -----------\n",
        "      {query}\n",
        "      -----------\n",
        "\n",
        "      We have provided a response version of the response up to a certain point: {existing_answer}\n",
        "      You have the opportunity to refine the existing response response with below contexts\n",
        "      (only if needed) with some more context as specified below.\n",
        "\n",
        "      Rules:\n",
        "      ------------\n",
        "      Given the new context and the query, refine the response further as necessary for answering the query but\n",
        "      never include the context as is in the response, you should ONLY and ONLY use the knowledge provided in contexts.\n",
        "      DONT add any information which is not present in contexts.\n",
        "      Make sure that the content is always relevant to the original query.\n",
        "      If the context provided isn't useful, dont make any change to the response, just return the current response.\n",
        "      ------------\n",
        "\n",
        "      Context:\n",
        "      ------------\n",
        "      {text}\n",
        "      ------------\n",
        "      \"\"\"\n",
        "  ).replace('{query}', title)\n",
        "\n",
        "  refine_prompt = PromptTemplate.from_template(refine_template)\n",
        "  chain = load_summarize_chain(\n",
        "      llm=model,\n",
        "      chain_type=\"refine\",\n",
        "      question_prompt=prompt,\n",
        "      refine_prompt=refine_prompt,\n",
        "      return_intermediate_steps=True,\n",
        "      input_key=\"input_documents\",\n",
        "      output_key=\"output_text\"\n",
        "  )\n",
        "  result = chain({\"input_documents\": input_chunks}, return_only_outputs=True)\n",
        "\n",
        "  context = []\n",
        "  for ic in input_chunks:\n",
        "    context.append( ic.page_content )\n",
        "\n",
        "  return result['intermediate_steps'], result['output_text'], context\n",
        "\n",
        "def run_query(query, db, top_n_docs=5, multiquery=False):\n",
        "  docs = query_vector_store(query, db, top_n_docs, multiquery)\n",
        "\n",
        "  ## Create article using top N docs\n",
        "  intermediate_steps, final_text, contexts = create_with_refine(docs, query)\n",
        "\n",
        "  return intermediate_steps, final_text, contexts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trr7g_cw5E15",
        "outputId": "cfa871d6-6863-490c-f9d0-1bdc950132b8"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.embeddings.vertexai:Model_name will become a required arg for VertexAIEmbeddings starting from Feb-01-2024. Currently the default is set to textembedding-gecko@001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_n_docs = 6 # @param {type:\"integer\"} ## Number of similar chunks used to create content\n",
        "\n",
        "## Create chunks from array of texts\n",
        "separator = \" \"\n",
        "chunks = chunk_text(document, separator, chunk_size=250, overlap=20)\n",
        "len(chunks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fN-KTGM5WK6",
        "outputId": "5231643c-823e-47fc-f13f-4cc2041e8bec"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Create vector store from chunks\n",
        "db = create_vector_store(chunks)"
      ],
      "metadata": {
        "id": "THn3QOYl5X7S"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test RAG"
      ],
      "metadata": {
        "id": "DUvXEo3g8MK2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_answers = []\n",
        "retrieved_contexts = []"
      ],
      "metadata": {
        "id": "u9YSTq3I-yMn"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What type of data can data stores contain in Vertex AI Search ? Give an elaborated answer\" # @param {type:\"string\"} ## Query\n",
        "\n",
        "## Create response using top N docs\n",
        "intermediate_steps, final_text, contexts = run_query(query, db, top_n_docs, multiquery=False)\n",
        "\n",
        "model_answers.append( final_text )\n",
        "retrieved_contexts.append( contexts )\n",
        "\n",
        "final_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113
        },
        "id": "ez6pDnL55dFm",
        "outputId": "da92776d-30f4-43f6-a318-a21fab7eb261"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Vertex AI Search can store various types of data, including:\\n\\n- **Text:** This includes unstructured text data such as documents, articles, emails, and web pages. Vertex AI Search uses natural language processing (NLP) to understand the meaning of text data and extract relevant information.\\n\\n\\n- **Structured data:** This includes data that is organized in a tabular format, such as spreadsheets, databases, and CSV files. Vertex AI Search can index structured data and make it searchable by specific fields or columns. This enables semantic search or recommendations over structured data such as a BigQuery table or NDJSON files.\\n\\n\\n- **Images:** Vertex AI Search can index and search images based on their visual content. It uses computer vision technology to extract features from images and match them to relevant queries.\\n\\n\\n- **Audio:** Vertex AI Search can index and search audio files, such as podcasts, music, and voice recordings. It uses speech recognition technology to transcribe audio files into text and make them searchable.\\n\\n\\n- **Video:** Vertex AI Search can index and search videos based on their visual and audio content. It uses computer vision and speech recognition technology to extract information from videos and make them searchable.\\n\\n\\n- **Website data:** Vertex AI Search can index and search website content, such as web pages, blog posts, and product descriptions. It can also crawl websites to discover new content and update its index.\\n\\n\\n- **Unstructured data:** Vertex AI Search can also store and search unstructured data, such as documents, images, and videos. This type of data is not organized in a tabular format and can be difficult to search. Vertex AI Search uses machine learning algorithms to understand the meaning of unstructured data and make it searchable.\\n\\nIn addition to these data types, Vertex AI Search can also store and search data from external sources, such as Google Cloud Storage, BigQuery, and Cloud SQL. This allows you to combine data from different sources and create a unified search experience for your users.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What does Vertex search support in terms of Healthcare data ?\" # @param {type:\"string\"} ## Query\n",
        "\n",
        "## Create response using top N docs\n",
        "intermediate_steps, final_text, contexts = run_query(query, db, top_n_docs, multiquery=False)\n",
        "\n",
        "model_answers.append( final_text )\n",
        "retrieved_contexts.append( contexts )\n",
        "\n",
        "final_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113
        },
        "id": "DQlKWT7V-6_m",
        "outputId": "101106c9-2b45-44f0-e197-e9708a4a5ccd"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" **Healthcare Data:**\\n- Semantic search over healthcare FHIR R4 data from Cloud Healthcare API.\\n- Suitable for healthcare organizations, research institutions, or biotech companies.\\n- For example, a healthcare provider can search over a patient's clinical history using exploratory queries.\\n- Vertex AI Search can also be used to search over other types of healthcare data, such as medical images, genomic data, and electronic health records.\\n- It leverages the power of deep information retrieval, state-of-the-art natural language processing, and the latest in large language model (LLM) processing to understand user intent and retrieve relevant information from healthcare data sources.\\n- Vertex AI Search supports structured data, which enables semantic search or recommendations over structured data such as a BigQuery table or NDJSON files.\\n- You can import FHIR R4 data from Cloud Healthcare API to enable semantic search over healthcare data.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Which all services are currently in preview in Vertex Search ?\" # @param {type:\"string\"} ## Query\n",
        "\n",
        "## Create response using top N docs\n",
        "intermediate_steps, final_text, contexts = run_query(query, db, top_n_docs, multiquery=False)\n",
        "\n",
        "model_answers.append( final_text )\n",
        "retrieved_contexts.append( contexts )\n",
        "\n",
        "final_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "Upl5WhRJ--2d",
        "outputId": "dc24e092-db93-41ef-d5e8-50ecee0538ab"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Vertex AI Search is currently in preview and offers the following services:\\n\\n- Search: Build a Google-quality search app on your own data and embed a search bar in your web pages or app.\\n- Recommendations: Build a recommendations user intent and return the most relevant results for the user.\\n- Data sources: Create search indexes from various data sources, including Salesforce, Jira, Confluence, healthcare FHIR R4 data imported from Cloud Healthcare API, and private repositories of medical research.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pprint.pp(model_answers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9-sCAEt_DUe",
        "outputId": "f71b2de4-5c34-4705-f788-a4ac6607e5f9"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[' Vertex AI Search can store various types of data, including:\\n'\n",
            " '\\n'\n",
            " '- **Text:** This includes unstructured text data such as documents, '\n",
            " 'articles, emails, and web pages. Vertex AI Search uses natural language '\n",
            " 'processing (NLP) to understand the meaning of text data and extract relevant '\n",
            " 'information.\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '- **Structured data:** This includes data that is organized in a tabular '\n",
            " 'format, such as spreadsheets, databases, and CSV files. Vertex AI Search can '\n",
            " 'index structured data and make it searchable by specific fields or columns. '\n",
            " 'This enables semantic search or recommendations over structured data such as '\n",
            " 'a BigQuery table or NDJSON files.\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '- **Images:** Vertex AI Search can index and search images based on their '\n",
            " 'visual content. It uses computer vision technology to extract features from '\n",
            " 'images and match them to relevant queries.\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '- **Audio:** Vertex AI Search can index and search audio files, such as '\n",
            " 'podcasts, music, and voice recordings. It uses speech recognition technology '\n",
            " 'to transcribe audio files into text and make them searchable.\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '- **Video:** Vertex AI Search can index and search videos based on their '\n",
            " 'visual and audio content. It uses computer vision and speech recognition '\n",
            " 'technology to extract information from videos and make them searchable.\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '- **Website data:** Vertex AI Search can index and search website content, '\n",
            " 'such as web pages, blog posts, and product descriptions. It can also crawl '\n",
            " 'websites to discover new content and update its index.\\n'\n",
            " '\\n'\n",
            " '\\n'\n",
            " '- **Unstructured data:** Vertex AI Search can also store and search '\n",
            " 'unstructured data, such as documents, images, and videos. This type of data '\n",
            " 'is not organized in a tabular format and can be difficult to search. Vertex '\n",
            " 'AI Search uses machine learning algorithms to understand the meaning of '\n",
            " 'unstructured data and make it searchable.\\n'\n",
            " '\\n'\n",
            " 'In addition to these data types, Vertex AI Search can also store and search '\n",
            " 'data from external sources, such as Google Cloud Storage, BigQuery, and '\n",
            " 'Cloud SQL. This allows you to combine data from different sources and create '\n",
            " 'a unified search experience for your users.',\n",
            " ' **Healthcare Data:**\\n'\n",
            " '- Semantic search over healthcare FHIR R4 data from Cloud Healthcare API.\\n'\n",
            " '- Suitable for healthcare organizations, research institutions, or biotech '\n",
            " 'companies.\\n'\n",
            " \"- For example, a healthcare provider can search over a patient's clinical \"\n",
            " 'history using exploratory queries.\\n'\n",
            " '- Vertex AI Search can also be used to search over other types of healthcare '\n",
            " 'data, such as medical images, genomic data, and electronic health records.\\n'\n",
            " '- It leverages the power of deep information retrieval, state-of-the-art '\n",
            " 'natural language processing, and the latest in large language model (LLM) '\n",
            " 'processing to understand user intent and retrieve relevant information from '\n",
            " 'healthcare data sources.\\n'\n",
            " '- Vertex AI Search supports structured data, which enables semantic search '\n",
            " 'or recommendations over structured data such as a BigQuery table or NDJSON '\n",
            " 'files.\\n'\n",
            " '- You can import FHIR R4 data from Cloud Healthcare API to enable semantic '\n",
            " 'search over healthcare data.',\n",
            " ' Vertex AI Search is currently in preview and offers the following '\n",
            " 'services:\\n'\n",
            " '\\n'\n",
            " '- Search: Build a Google-quality search app on your own data and embed a '\n",
            " 'search bar in your web pages or app.\\n'\n",
            " '- Recommendations: Build a recommendations user intent and return the most '\n",
            " 'relevant results for the user.\\n'\n",
            " '- Data sources: Create search indexes from various data sources, including '\n",
            " 'Salesforce, Jira, Confluence, healthcare FHIR R4 data imported from Cloud '\n",
            " 'Healthcare API, and private repositories of medical research.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate RAG with RAGAs"
      ],
      "metadata": {
        "id": "yh3VDL488O4M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate a test set"
      ],
      "metadata": {
        "id": "IWkj8VpE8TAy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.auth\n",
        "\n",
        "from langchain.chat_models import ChatVertexAI\n",
        "from langchain.embeddings import VertexAIEmbeddings\n",
        "from ragas.llms.base import LangchainLLMWrapper\n",
        "\n",
        "config = {\n",
        "    \"project_id\": \"hasanrafiq-test-331814\",\n",
        "}\n",
        "\n",
        "# authenticate to GCP\n",
        "creds, _ = google.auth.default(quota_project_id=config['project_id'])\n",
        "\n",
        "llm = ChatVertexAI(top_k=40, top_p=1, temperature=0, credentials=creds)\n",
        "ragas_vertexai_llm = wrapper = LangchainLLMWrapper(llm)\n",
        "vertexai_embeddings = VertexAIEmbeddings(credentials=creds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kaht1h2vV_X",
        "outputId": "8913f104-6b5b-4d9b-9609-a72faca0d9cb"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.embeddings.vertexai:Model_name will become a required arg for VertexAIEmbeddings starting from Feb-01-2024. Currently the default is set to textembedding-gecko@001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "questions = [\n",
        "    \"What type of data can data stores contain in Vertex AI Search ?\",\n",
        "    \"What does Vertex search support in terms of Healthcare data ?\",\n",
        "    \"Which all services are currently in preview in Vertex Search ?\"\n",
        "]"
      ],
      "metadata": {
        "id": "2IVdD4lr9mgZ"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct_answers = [\n",
        "    [\"\"\"Website data, structured data, unstructured data, health care data\"\"\"],\n",
        "    [\"\"\"You can do a semantic search over healthcare FHIR R4 data imported from Cloud Healthcare API. For example, a healthcare provider can search over a patient's clinical history using exploratory queries.\"\"\"],\n",
        "    [\"\"\"Currently Syncing data from Jira, Salesforce, or Confluence is available in Preview with allowlist and generic recommendation feature is also in preview\"\"\"]\n",
        "]"
      ],
      "metadata": {
        "id": "-KzuSbMn9y5e"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_set = {\n",
        " 'question': questions,\n",
        " 'ground_truths': correct_answers,\n",
        " 'answer': model_answers,\n",
        " 'contexts': retrieved_contexts\n",
        "}\n",
        "\n",
        "metrics = [\n",
        "        # answer_correctness,\n",
        "        answer_relevancy,\n",
        "        context_precision,\n",
        "        context_recall,\n",
        "        context_entity_recall\n",
        "]\n",
        "\n",
        "## Switch to VertexAI models\n",
        "for m in metrics:\n",
        "    # change LLM for metric\n",
        "    m.__setattr__(\"llm\", ragas_vertexai_llm)\n",
        "\n",
        "    # check if this metric needs embeddings\n",
        "    if hasattr(m, \"embeddings\"):\n",
        "        # if so change with VertexAI Embeddings\n",
        "        m.__setattr__(\"embeddings\", vertexai_embeddings)"
      ],
      "metadata": {
        "id": "Nto0mc3M5pFA"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_eval = Dataset.from_dict(test_set)\n",
        "\n",
        "score = evaluate(df_eval, metrics=metrics)\n",
        "score.to_pandas()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266,
          "referenced_widgets": [
            "d91a2ce483074838a077d2481f038385",
            "70a1b00825ca47a1a9d403164ef38420",
            "57af0b9dc81b42429ac29430672c553b",
            "962a2be6393b48258f7fa7694593e80d",
            "5ccde1c5b3bf479ca5bd842f8c326d1c",
            "1390490d09c345b89683a0ee2a320723",
            "052df76f0cca407f9835fb6051c346f3",
            "53120f2f334e4b3d8b53950828052e68",
            "dfcbc471858e430ea009462e779f15eb",
            "b9019ef41db24a2b9fe36a8a2cb91757",
            "9d2026d84ec84e15910238825302b9bc"
          ]
        },
        "id": "qBqLAWBbq3hk",
        "outputId": "146818ab-2674-4301-d609-22fe57b28ae1"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ragas.validation:passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluating:   0%|          | 0/12 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d91a2ce483074838a077d2481f038385"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            question  \\\n",
              "0  What type of data can data stores contain in V...   \n",
              "1  What does Vertex search support in terms of He...   \n",
              "2  Which all services are currently in preview in...   \n",
              "\n",
              "                                       ground_truths  \\\n",
              "0  [Website data, structured data, unstructured d...   \n",
              "1  [You can do a semantic search over healthcare ...   \n",
              "2  [Currently Syncing data from Jira, Salesforce,...   \n",
              "\n",
              "                                              answer  \\\n",
              "0   Vertex AI Search can store various types of d...   \n",
              "1   **Healthcare Data:**\\n- Semantic search over ...   \n",
              "2   Vertex AI Search is currently in preview and ...   \n",
              "\n",
              "                                            contexts  \\\n",
              "0  [Information retrieval using AI and LLMs\\nVert...   \n",
              "1  [ublications, or a biotech company can enable ...   \n",
              "2  [rom Jira, Salesforce, or Confluence is availa...   \n",
              "\n",
              "                                        ground_truth  answer_relevancy  \\\n",
              "0  Website data, structured data, unstructured da...          0.947733   \n",
              "1  You can do a semantic search over healthcare F...          0.000000   \n",
              "2  Currently Syncing data from Jira, Salesforce, ...          0.814847   \n",
              "\n",
              "   context_precision  context_recall  context_entity_recall  \n",
              "0           0.325000             1.0                    0.5  \n",
              "1           0.876667             1.0                    0.5  \n",
              "2           1.000000             1.0                    1.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-43986b40-b536-4dfa-8436-edd1055c3ba4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>ground_truths</th>\n",
              "      <th>answer</th>\n",
              "      <th>contexts</th>\n",
              "      <th>ground_truth</th>\n",
              "      <th>answer_relevancy</th>\n",
              "      <th>context_precision</th>\n",
              "      <th>context_recall</th>\n",
              "      <th>context_entity_recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What type of data can data stores contain in V...</td>\n",
              "      <td>[Website data, structured data, unstructured d...</td>\n",
              "      <td>Vertex AI Search can store various types of d...</td>\n",
              "      <td>[Information retrieval using AI and LLMs\\nVert...</td>\n",
              "      <td>Website data, structured data, unstructured da...</td>\n",
              "      <td>0.947733</td>\n",
              "      <td>0.325000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What does Vertex search support in terms of He...</td>\n",
              "      <td>[You can do a semantic search over healthcare ...</td>\n",
              "      <td>**Healthcare Data:**\\n- Semantic search over ...</td>\n",
              "      <td>[ublications, or a biotech company can enable ...</td>\n",
              "      <td>You can do a semantic search over healthcare F...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.876667</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Which all services are currently in preview in...</td>\n",
              "      <td>[Currently Syncing data from Jira, Salesforce,...</td>\n",
              "      <td>Vertex AI Search is currently in preview and ...</td>\n",
              "      <td>[rom Jira, Salesforce, or Confluence is availa...</td>\n",
              "      <td>Currently Syncing data from Jira, Salesforce, ...</td>\n",
              "      <td>0.814847</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-43986b40-b536-4dfa-8436-edd1055c3ba4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-43986b40-b536-4dfa-8436-edd1055c3ba4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-43986b40-b536-4dfa-8436-edd1055c3ba4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-479976a1-19c0-44aa-8396-26aa646ac367\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-479976a1-19c0-44aa-8396-26aa646ac367')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-479976a1-19c0-44aa-8396-26aa646ac367 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"score\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"What type of data can data stores contain in Vertex AI Search ?\",\n          \"What does Vertex search support in terms of Healthcare data ?\",\n          \"Which all services are currently in preview in Vertex Search ?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ground_truths\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \" Vertex AI Search can store various types of data, including:\\n\\n- **Text:** This includes unstructured text data such as documents, articles, emails, and web pages. Vertex AI Search uses natural language processing (NLP) to understand the meaning of text data and extract relevant information.\\n\\n\\n- **Structured data:** This includes data that is organized in a tabular format, such as spreadsheets, databases, and CSV files. Vertex AI Search can index structured data and make it searchable by specific fields or columns. This enables semantic search or recommendations over structured data such as a BigQuery table or NDJSON files.\\n\\n\\n- **Images:** Vertex AI Search can index and search images based on their visual content. It uses computer vision technology to extract features from images and match them to relevant queries.\\n\\n\\n- **Audio:** Vertex AI Search can index and search audio files, such as podcasts, music, and voice recordings. It uses speech recognition technology to transcribe audio files into text and make them searchable.\\n\\n\\n- **Video:** Vertex AI Search can index and search videos based on their visual and audio content. It uses computer vision and speech recognition technology to extract information from videos and make them searchable.\\n\\n\\n- **Website data:** Vertex AI Search can index and search website content, such as web pages, blog posts, and product descriptions. It can also crawl websites to discover new content and update its index.\\n\\n\\n- **Unstructured data:** Vertex AI Search can also store and search unstructured data, such as documents, images, and videos. This type of data is not organized in a tabular format and can be difficult to search. Vertex AI Search uses machine learning algorithms to understand the meaning of unstructured data and make it searchable.\\n\\nIn addition to these data types, Vertex AI Search can also store and search data from external sources, such as Google Cloud Storage, BigQuery, and Cloud SQL. This allows you to combine data from different sources and create a unified search experience for your users.\",\n          \" **Healthcare Data:**\\n- Semantic search over healthcare FHIR R4 data from Cloud Healthcare API.\\n- Suitable for healthcare organizations, research institutions, or biotech companies.\\n- For example, a healthcare provider can search over a patient's clinical history using exploratory queries.\\n- Vertex AI Search can also be used to search over other types of healthcare data, such as medical images, genomic data, and electronic health records.\\n- It leverages the power of deep information retrieval, state-of-the-art natural language processing, and the latest in large language model (LLM) processing to understand user intent and retrieve relevant information from healthcare data sources.\\n- Vertex AI Search supports structured data, which enables semantic search or recommendations over structured data such as a BigQuery table or NDJSON files.\\n- You can import FHIR R4 data from Cloud Healthcare API to enable semantic search over healthcare data.\",\n          \" Vertex AI Search is currently in preview and offers the following services:\\n\\n- Search: Build a Google-quality search app on your own data and embed a search bar in your web pages or app.\\n- Recommendations: Build a recommendations user intent and return the most relevant results for the user.\\n- Data sources: Create search indexes from various data sources, including Salesforce, Jira, Confluence, healthcare FHIR R4 data imported from Cloud Healthcare API, and private repositories of medical research.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"contexts\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ground_truth\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Website data, structured data, unstructured data, health care data\",\n          \"You can do a semantic search over healthcare FHIR R4 data imported from Cloud Healthcare API. For example, a healthcare provider can search over a patient's clinical history using exploratory queries.\",\n          \"Currently Syncing data from Jira, Salesforce, or Confluence is available in Preview with allowlist and generic recommendation feature is also in preview\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer_relevancy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5131328137275861,\n        \"min\": 0.0,\n        \"max\": 0.9477325788456074,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.9477325788456074,\n          0.0,\n          0.8148473340835878\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"context_precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.359437575036195,\n        \"min\": 0.32499999998375,\n        \"max\": 0.9999999999,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.32499999998375,\n          0.8766666666491333,\n          0.9999999999\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"context_recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"context_entity_recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.28867513375284376,\n        \"min\": 0.4999999975,\n        \"max\": 0.9999999966666667,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.49999999875\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    }
  ]
}