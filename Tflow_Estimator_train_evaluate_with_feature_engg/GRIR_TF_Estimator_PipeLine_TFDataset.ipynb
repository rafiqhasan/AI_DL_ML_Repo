{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hrafiq\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from tensorflow.python.training import training_util\n",
    "\n",
    "print(tf.__version__)\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = '{:.1f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"GRIR_GCP_Data.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WERKS</th>\n",
       "      <th>SCENARIO</th>\n",
       "      <th>KTOKK</th>\n",
       "      <th>VSTATU</th>\n",
       "      <th>VPATD</th>\n",
       "      <th>EKORG</th>\n",
       "      <th>EKGRP</th>\n",
       "      <th>TOTGRQTY</th>\n",
       "      <th>TOTIRQTY</th>\n",
       "      <th>NODLGR</th>\n",
       "      <th>NODLIR</th>\n",
       "      <th>DIFGRIRD</th>\n",
       "      <th>DIFGRIRV</th>\n",
       "      <th>STATUS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ML01</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>-80</td>\n",
       "      <td>-38100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ML01</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>177</td>\n",
       "      <td>-107</td>\n",
       "      <td>-41600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ML01</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>152</td>\n",
       "      <td>-107</td>\n",
       "      <td>-27600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ML01</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>-96</td>\n",
       "      <td>-13800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ML01</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>192</td>\n",
       "      <td>-146</td>\n",
       "      <td>-73500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ML01</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "      <td>0</td>\n",
       "      <td>139</td>\n",
       "      <td>-189</td>\n",
       "      <td>-26600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ML01</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>183</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>-183</td>\n",
       "      <td>-69200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ML01</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "      <td>195</td>\n",
       "      <td>-159</td>\n",
       "      <td>-73600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ML01</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>185</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>-185</td>\n",
       "      <td>-59500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ML01</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>168</td>\n",
       "      <td>-91</td>\n",
       "      <td>-4700</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  WERKS  SCENARIO  KTOKK  VSTATU  VPATD  EKORG EKGRP  TOTGRQTY  TOTIRQTY  \\\n",
       "0  ML01         3      1       1     30      1     A         0        80   \n",
       "1  ML01         3      1       1     30      1     A         0       107   \n",
       "2  ML01         3      1       1     30      1     A         0       107   \n",
       "3  ML01         3      1       1     30      1     A         0        96   \n",
       "4  ML01         3      1       1     30      1     A         0       146   \n",
       "5  ML01         3      1       1     60      1     A         0       189   \n",
       "6  ML01         3      1       1     60      1     A         0       183   \n",
       "7  ML01         3      1       1     60      1     A         0       159   \n",
       "8  ML01         3      1       1     60      1     A         0       185   \n",
       "9  ML01         3      1       1     60      1     A         0        91   \n",
       "\n",
       "   NODLGR  NODLIR  DIFGRIRD  DIFGRIRV  STATUS  \n",
       "0       0      90       -80    -38100       1  \n",
       "1       0     177      -107    -41600       0  \n",
       "2       0     152      -107    -27600       1  \n",
       "3       0      79       -96    -13800       1  \n",
       "4       0     192      -146    -73500       0  \n",
       "5       0     139      -189    -26600       1  \n",
       "6       0      48      -183    -69200       0  \n",
       "7       0     195      -159    -73600       0  \n",
       "8       0      79      -185    -59500       0  \n",
       "9       0     168       -91     -4700       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SCENARIO</th>\n",
       "      <th>KTOKK</th>\n",
       "      <th>VSTATU</th>\n",
       "      <th>VPATD</th>\n",
       "      <th>EKORG</th>\n",
       "      <th>TOTGRQTY</th>\n",
       "      <th>TOTIRQTY</th>\n",
       "      <th>NODLGR</th>\n",
       "      <th>NODLIR</th>\n",
       "      <th>DIFGRIRD</th>\n",
       "      <th>DIFGRIRV</th>\n",
       "      <th>STATUS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8279.0</td>\n",
       "      <td>8279.0</td>\n",
       "      <td>8279.0</td>\n",
       "      <td>8279.0</td>\n",
       "      <td>8279.0</td>\n",
       "      <td>8279.0</td>\n",
       "      <td>8279.0</td>\n",
       "      <td>8279.0</td>\n",
       "      <td>8279.0</td>\n",
       "      <td>8279.0</td>\n",
       "      <td>8279.0</td>\n",
       "      <td>8279.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.1</td>\n",
       "      <td>60.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>65.9</td>\n",
       "      <td>94.1</td>\n",
       "      <td>103.1</td>\n",
       "      <td>89.5</td>\n",
       "      <td>-28.2</td>\n",
       "      <td>-6716.3</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>24.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>63.0</td>\n",
       "      <td>62.4</td>\n",
       "      <td>82.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>63.2</td>\n",
       "      <td>22797.4</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>-75000.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-56.0</td>\n",
       "      <td>-9600.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-546.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5482.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>59200.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       SCENARIO  KTOKK  VSTATU  VPATD  EKORG  TOTGRQTY  TOTIRQTY  NODLGR  \\\n",
       "count    8279.0 8279.0  8279.0 8279.0 8279.0    8279.0    8279.0  8279.0   \n",
       "mean        2.6    1.5     1.1   60.3    1.3      65.9      94.1   103.1   \n",
       "std         1.1    0.5     0.3   24.4    0.5      63.0      62.4    82.0   \n",
       "min         1.0    1.0     1.0   30.0    1.0       0.0       0.0     0.0   \n",
       "25%         2.0    1.0     1.0   30.0    1.0       0.0      54.0     0.0   \n",
       "50%         3.0    1.0     1.0   60.0    1.0      55.0      99.0   112.0   \n",
       "75%         4.0    2.0     1.0   90.0    2.0     121.0     146.0   172.0   \n",
       "max         4.0    2.0     2.0   90.0    2.0     200.0     200.0   268.0   \n",
       "\n",
       "       NODLIR  DIFGRIRD  DIFGRIRV  STATUS  \n",
       "count  8279.0    8279.0    8279.0  8279.0  \n",
       "mean     89.5     -28.2   -6716.3     0.4  \n",
       "std      75.0      63.2   22797.4     0.5  \n",
       "min       0.0    -200.0  -75000.0     0.0  \n",
       "25%      10.0     -56.0   -9600.0     0.0  \n",
       "50%      82.0      -2.0    -546.0     0.0  \n",
       "75%     154.0      11.0    5482.0     1.0  \n",
       "max     242.0      74.0   59200.0     1.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['WERKS', 'SCENARIO', 'KTOKK', 'VSTATU', 'VPATD', 'EKORG', 'EKGRP',\n",
       "       'TOTGRQTY', 'TOTIRQTY', 'NODLGR', 'NODLIR', 'DIFGRIRD', 'DIFGRIRV',\n",
       "       'STATUS'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1gAAADQCAYAAAAalMCAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEodEpAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2bf85487898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Facet1\n",
    "g = sns.FacetGrid(df, col=\"SCENARIO\")\n",
    "g = g.map(plt.hist, \"TOTGRQTY\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1gAAADQCAYAAAAalMCAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSZIkSWrEgCVJkiRJjRiwJEmSJKmR/w9+gt+/npE5dAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2bf87609e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Facet1\n",
    "g = sns.FacetGrid(df, col=\"SCENARIO\")\n",
    "g = g.map(plt.hist, \"TOTIRQTY\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WERKS</th>\n",
       "      <th>SCENARIO</th>\n",
       "      <th>KTOKK</th>\n",
       "      <th>VSTATU</th>\n",
       "      <th>VPATD</th>\n",
       "      <th>EKORG</th>\n",
       "      <th>EKGRP</th>\n",
       "      <th>TOTGRQTY</th>\n",
       "      <th>TOTIRQTY</th>\n",
       "      <th>NODLGR</th>\n",
       "      <th>NODLIR</th>\n",
       "      <th>DIFGRIRD</th>\n",
       "      <th>DIFGRIRV</th>\n",
       "      <th>STATUS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ML01</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>-80</td>\n",
       "      <td>-38100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ML01</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>177</td>\n",
       "      <td>-107</td>\n",
       "      <td>-41600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ML01</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>152</td>\n",
       "      <td>-107</td>\n",
       "      <td>-27600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ML01</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>-96</td>\n",
       "      <td>-13800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ML01</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>192</td>\n",
       "      <td>-146</td>\n",
       "      <td>-73500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  WERKS  SCENARIO  KTOKK  VSTATU  VPATD  EKORG EKGRP  TOTGRQTY  TOTIRQTY  \\\n",
       "0  ML01         3      1       1     30      1     A         0        80   \n",
       "1  ML01         3      1       1     30      1     A         0       107   \n",
       "2  ML01         3      1       1     30      1     A         0       107   \n",
       "3  ML01         3      1       1     30      1     A         0        96   \n",
       "4  ML01         3      1       1     30      1     A         0       146   \n",
       "\n",
       "   NODLGR  NODLIR  DIFGRIRD  DIFGRIRV  STATUS  \n",
       "0       0      90       -80    -38100       1  \n",
       "1       0     177      -107    -41600       0  \n",
       "2       0     152      -107    -27600       1  \n",
       "3       0      79       -96    -13800       1  \n",
       "4       0     192      -146    -73500       0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Filter out scenario = 3 ( It has TOTGRQTY == 0 )\n",
    "df_s1 = df[df['SCENARIO'].eq(3) & df['TOTGRQTY'].eq(0)]\n",
    "df_s1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8279 entries, 0 to 8278\n",
      "Data columns (total 14 columns):\n",
      "WERKS       8279 non-null object\n",
      "SCENARIO    8279 non-null object\n",
      "KTOKK       8279 non-null object\n",
      "VSTATU      8279 non-null object\n",
      "VPATD       8279 non-null int64\n",
      "EKORG       8279 non-null object\n",
      "EKGRP       8279 non-null object\n",
      "TOTGRQTY    8279 non-null int64\n",
      "TOTIRQTY    8279 non-null int64\n",
      "NODLGR      8279 non-null int64\n",
      "NODLIR      8279 non-null int64\n",
      "DIFGRIRD    8279 non-null int64\n",
      "DIFGRIRV    8279 non-null int64\n",
      "STATUS      8279 non-null int64\n",
      "dtypes: int64(8), object(6)\n",
      "memory usage: 905.6+ KB\n"
     ]
    }
   ],
   "source": [
    "#Mark some columns as categorical so that TF treats them as categorical\n",
    "for col_cat in ['SCENARIO','KTOKK','VSTATU','EKORG']:\n",
    "    df[col_cat] = df[col_cat].astype('str') #Very important to keep this as STR -> Tensorflow treats only STR as categorical\n",
    "    \n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DIFGRIRD</th>\n",
       "      <th>DIFGRIRV</th>\n",
       "      <th>NODLGR</th>\n",
       "      <th>NODLIR</th>\n",
       "      <th>Random</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>TOTGRQTY</th>\n",
       "      <th>TOTIRQTY</th>\n",
       "      <th>VPATD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DIFGRIRD  DIFGRIRV  NODLGR  NODLIR  Random  STATUS  TOTGRQTY  TOTIRQTY  \\\n",
       "0       0.2       0.1     0.3     0.3       0     0.2       0.3       0.6   \n",
       "1       0.1       0.1     0.1     0.3       1     1.0       0.0       0.8   \n",
       "2       1.0       0.9     0.8     1.0       2     1.0       0.9       0.4   \n",
       "3       0.5       0.2     0.1     0.1       3     1.0       0.4       0.9   \n",
       "4       1.0       0.6     0.5     0.5       4     1.0       1.0       0.9   \n",
       "5       0.7       0.4     0.2     0.4       5     0.8       0.7       0.2   \n",
       "6       0.5       0.3     0.4     1.0       6     1.0       0.9       0.7   \n",
       "7       0.8       0.3     0.7     0.6       7     0.7       0.9       0.8   \n",
       "8       0.8       0.6     1.0     1.0       8     1.0       0.0       0.3   \n",
       "9       1.0       0.5     0.4     0.4       9     1.0       0.0       0.1   \n",
       "\n",
       "   VPATD  \n",
       "0    0.9  \n",
       "1    1.0  \n",
       "2    0.8  \n",
       "3    1.0  \n",
       "4    1.0  \n",
       "5    1.0  \n",
       "6    0.3  \n",
       "7    0.6  \n",
       "8    0.4  \n",
       "9    1.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Split dataset -> Split 10 times and choose the one with best P values( Significance test )\n",
    "p_res = {}\n",
    "t_res = []\n",
    "for i in range(10):\n",
    "    np.random.seed(seed=i) #makes result reproducible\n",
    "    msk = np.random.rand(len(df)) < 0.8\n",
    "    X_train = df[msk]\n",
    "    X_test = df[~msk]\n",
    "\n",
    "    #Run Significance Tests on both the distributions( Train and Test ) for all numerical attributes\n",
    "    p_res = {}\n",
    "    for c_ in X_train.columns:\n",
    "        if not X_train[c_].dtype == 'object':\n",
    "            try:\n",
    "                _, a = scipy.stats.ks_2samp(X_train[c_].values,X_test[c_].values)\n",
    "                #print('P-value for column {} is {}'.format(c_.upper(), a))\n",
    "                p_res['Random'] = i\n",
    "                p_res[c_] = a\n",
    "            except:\n",
    "                p_res['Random'] = i\n",
    "                p_res[c_] = 'Error'\n",
    "    t_res.append(p_res)\n",
    "\n",
    "p_df = pd.DataFrame(t_res)\n",
    "p_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare train and test data set\n",
    "np.random.seed(seed=2) #makes result reproducible\n",
    "msk = np.random.rand(len(df)) < 0.8\n",
    "traindf = df[msk]\n",
    "evaldf = df[~msk]\n",
    "#evaldf[evaldf['STATUS'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6629 entries, 0 to 8278\n",
      "Data columns (total 14 columns):\n",
      "WERKS       6629 non-null object\n",
      "SCENARIO    6629 non-null object\n",
      "KTOKK       6629 non-null object\n",
      "VSTATU      6629 non-null object\n",
      "VPATD       6629 non-null int64\n",
      "EKORG       6629 non-null object\n",
      "EKGRP       6629 non-null object\n",
      "TOTGRQTY    6629 non-null int64\n",
      "TOTIRQTY    6629 non-null int64\n",
      "NODLGR      6629 non-null int64\n",
      "NODLIR      6629 non-null int64\n",
      "DIFGRIRD    6629 non-null int64\n",
      "DIFGRIRV    6629 non-null int64\n",
      "STATUS      6629 non-null int64\n",
      "dtypes: int64(8), object(6)\n",
      "memory usage: 776.8+ KB\n"
     ]
    }
   ],
   "source": [
    "traindf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1650 entries, 16 to 8272\n",
      "Data columns (total 14 columns):\n",
      "WERKS       1650 non-null object\n",
      "SCENARIO    1650 non-null object\n",
      "KTOKK       1650 non-null object\n",
      "VSTATU      1650 non-null object\n",
      "VPATD       1650 non-null int64\n",
      "EKORG       1650 non-null object\n",
      "EKGRP       1650 non-null object\n",
      "TOTGRQTY    1650 non-null int64\n",
      "TOTIRQTY    1650 non-null int64\n",
      "NODLGR      1650 non-null int64\n",
      "NODLIR      1650 non-null int64\n",
      "DIFGRIRD    1650 non-null int64\n",
      "DIFGRIRV    1650 non-null int64\n",
      "STATUS      1650 non-null int64\n",
      "dtypes: int64(8), object(6)\n",
      "memory usage: 193.4+ KB\n"
     ]
    }
   ],
   "source": [
    "evaldf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Files To be used in Tensorflow pipeline dataset API\n",
    "traindf.to_csv(\"grir_train.csv\", index=False, header=False)\n",
    "evaldf.to_csv(\"grir_eval.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################## Tensorflow Pipeline building and Modeling ############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tf version of Add_new_features\n",
    "def add_new_features_tf(df_temp):   \n",
    "    #Add any feature engineering or new column here\n",
    "    df_temp['grminusirbyvpatd'] = ( df_temp['TOTGRQTY'] - df_temp['TOTIRQTY'] ) / df_temp['VPATD']\n",
    "    \n",
    "    df_temp['difgrirdbytotgrqty'] = tf.where( tf.not_equal(tf.cast(df_temp['TOTGRQTY'], tf.float32), tf.cast(0, tf.float32)),\n",
    "                                              tf.cast(tf.divide(df_temp['DIFGRIRD'], df_temp['TOTGRQTY']), tf.float32),\n",
    "                                              tf.cast(tf.zeros_like(df_temp['DIFGRIRD']), tf.float32))\n",
    "    return df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Panda version of Add_new_features\n",
    "def add_new_features_panda(df_temp):   \n",
    "    def feat_difgrirdbytotgrqty(row):\n",
    "        if row['TOTGRQTY'] == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return row['DIFGRIRD'] / row['TOTGRQTY']\n",
    "    \n",
    "    #Add any feature engineering or new column here\n",
    "    df_temp['grminusirbyvpatd'] = ( df_temp['TOTGRQTY'] - df_temp['TOTIRQTY'] ) / df_temp['VPATD']\n",
    "    \n",
    "    df_temp['difgrirdbytotgrqty'] = df_temp.apply(feat_difgrirdbytotgrqty, axis=1)\n",
    "    return df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  WERKS SCENARIO KTOKK VSTATU  VPATD EKORG EKGRP  TOTGRQTY  TOTIRQTY  NODLGR  \\\n",
      "0  ML01        3     1      1     30     1     A         0        80       0   \n",
      "1  ML01        3     1      1     30     1     A         0       107       0   \n",
      "2  ML01        3     1      1     30     1     A         0       107       0   \n",
      "3  ML01        3     1      1     30     1     A         0        96       0   \n",
      "4  ML01        3     1      1     30     1     A         0       146       0   \n",
      "\n",
      "   NODLIR  DIFGRIRD  DIFGRIRV  STATUS  grminusirbyvpatd  difgrirdbytotgrqty  \n",
      "0      90       -80    -38100       1              -2.7                 0.0  \n",
      "1     177      -107    -41600       0              -3.6                 0.0  \n",
      "2     152      -107    -27600       1              -3.6                 0.0  \n",
      "3      79       -96    -13800       1              -3.2                 0.0  \n",
      "4     192      -146    -73500       0              -4.9                 0.0  \n",
      "       VPATD  TOTGRQTY  TOTIRQTY  NODLGR  NODLIR  DIFGRIRD  DIFGRIRV  STATUS  \\\n",
      "count 6629.0    6629.0    6629.0  6629.0  6629.0    6629.0    6629.0  6629.0   \n",
      "mean    60.4      65.9      94.2   103.1    89.5     -28.3   -6720.6     0.4   \n",
      "std     24.4      63.0      62.5    81.9    75.0      63.3   22747.0     0.5   \n",
      "min     30.0       0.0       0.0     0.0     0.0    -200.0  -75000.0     0.0   \n",
      "25%     30.0       0.0      54.0     0.0    10.0     -57.0   -9637.0     0.0   \n",
      "50%     60.0      55.0     100.0   112.0    82.0      -2.0    -566.0     0.0   \n",
      "75%     90.0     122.0     146.0   172.0   153.0      11.0    5500.0     1.0   \n",
      "max     90.0     200.0     200.0   268.0   242.0      74.0   59200.0     1.0   \n",
      "\n",
      "       grminusirbyvpatd  difgrirdbytotgrqty  \n",
      "count            6629.0              6629.0  \n",
      "mean               -0.6                 0.2  \n",
      "std                 1.4                 0.4  \n",
      "min                -6.7                -0.2  \n",
      "25%                -0.8                -0.0  \n",
      "50%                -0.0                 0.0  \n",
      "75%                 0.2                 0.1  \n",
      "max                 1.7                 1.0  \n"
     ]
    }
   ],
   "source": [
    "# Test add_new_features for X_train\n",
    "df_dummy = add_new_features_panda(traindf.copy())\n",
    "print(df_dummy.head())\n",
    "print(df_dummy.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RETURNS a pre-processing( New columns + Transformations ) function to be used inside pipeline\n",
    "def create_add_engineered_fn(df):\n",
    "    #Add new features in the set so that it's details can be copied to parameters of fn_add_engineered\n",
    "    df = add_new_features_panda(df)\n",
    "    \n",
    "    #Get min max for each numerical column to use for scaling\n",
    "    cols_mean = {}\n",
    "    cols_std = {}\n",
    "    num_feats = []\n",
    "    for col_norm in list(df.columns):\n",
    "        if not df[col_norm].dtype == 'object' and not col_norm in ['STATUS']:\n",
    "            cols_mean[col_norm] = df[col_norm].mean()\n",
    "            cols_std[col_norm] = df[col_norm].std()\n",
    "            num_feats.append(col_norm)\n",
    "\n",
    "    #Pass all the above calculated values to be used by main function which will be called in Pipeline\n",
    "    def fn_add_engineered(features, cols_mean = cols_mean, cols_std = cols_std, num_feats = num_feats):\n",
    "        #Save value here for 0-1 scaling during training and serving\n",
    "#         print(\"mean\", cols_mean)\n",
    "#         print(\"std\", cols_std)\n",
    "#         print(features)\n",
    "        \n",
    "        #Add new features AGAIN as the function add_engineered will be called with data\n",
    "        features = add_new_features_tf(features)\n",
    "        \n",
    "        #Normalize few numerical columns\n",
    "        for col_norm in list(num_feats):\n",
    "            mean_value = cols_mean[col_norm]\n",
    "            std_value = cols_std[col_norm]\n",
    "            features[col_norm] = (features[col_norm] - mean_value) / std_value\n",
    "\n",
    "#         print(\"..... Done processing \")\n",
    "#         print(features)\n",
    "        return features\n",
    "    \n",
    "    return fn_add_engineered\n",
    "\n",
    "#Generate pre-processing function as per training data\n",
    "add_engineered = create_add_engineered_fn(traindf.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test run add_engineered on copy of X_test\n",
    "# dummy = traindf.copy()\n",
    "# dummy = add_engineered(dummy)\n",
    "# dummy.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your feature columns\n",
    "def create_feature_cols():\n",
    "#   lat_buck = tf.feature_column.bucketized_column(tf.feature_column.numeric_column('latitude'), \n",
    "#                                                  boundaries = np.arange(32.0, 42, 1).tolist())\n",
    "#   long_buck = tf.feature_column.bucketized_column(tf.feature_column.numeric_column('longitude'),\n",
    "#                                                   boundaries = np.arange(1, 52, 1).tolist())\n",
    "    werks_c = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            key='WERKS',\n",
    "            vocabulary_list=['ML01','ML02','ML03'])\n",
    "    scenario_c = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            key='SCENARIO',\n",
    "            vocabulary_list=['1','2','3','4'])\n",
    "    ktokk_c = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            key='KTOKK',\n",
    "            vocabulary_list=['1','2'])    \n",
    "    vstatu_c = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            key='VSTATU',\n",
    "            vocabulary_list=['1','2'])\n",
    "    ekorg_c = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            key='EKORG',\n",
    "            vocabulary_list=['1','2'])   \n",
    "    ekgrp_c = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            key='EKGRP',\n",
    "            vocabulary_list=['A','B','C'])\n",
    "    \n",
    "#     werks_c = tf.feature_column.categorical_column_with_hash_bucket(\n",
    "#             key='WERKS',hash_bucket_size=3)\n",
    "#     scenario_c = tf.feature_column.categorical_column_with_hash_bucket(\n",
    "#             key='SCENARIO',hash_bucket_size=4)\n",
    "#     ktokk_c = tf.feature_column.categorical_column_with_hash_bucket(\n",
    "#             key='KTOKK',hash_bucket_size=2)\n",
    "#     vstatu_c = tf.feature_column.categorical_column_with_hash_bucket(\n",
    "#             key='VSTATU',hash_bucket_size=2)\n",
    "#     ekorg_c = tf.feature_column.categorical_column_with_hash_bucket(\n",
    "#             key='EKORG',hash_bucket_size=2)\n",
    "#     ekgrp_c = tf.feature_column.categorical_column_with_hash_bucket(\n",
    "#             key='EKGRP',hash_bucket_size=3)\n",
    "\n",
    "    return [\n",
    "        tf.feature_column.indicator_column(werks_c),\n",
    "        tf.feature_column.indicator_column(scenario_c),\n",
    "        tf.feature_column.indicator_column(ktokk_c),\n",
    "        tf.feature_column.indicator_column(vstatu_c),\n",
    "        tf.feature_column.indicator_column(ekorg_c),\n",
    "        tf.feature_column.indicator_column(ekgrp_c),\n",
    "        tf.feature_column.numeric_column('VPATD'),\n",
    "        tf.feature_column.numeric_column(\"TOTGRQTY\"),\n",
    "        tf.feature_column.numeric_column(\"TOTIRQTY\"),\n",
    "        tf.feature_column.numeric_column(\"NODLGR\"),\n",
    "        tf.feature_column.numeric_column(\"NODLIR\"),\n",
    "        tf.feature_column.numeric_column(\"DIFGRIRD\"),\n",
    "        tf.feature_column.numeric_column(\"grminusirbyvpatd\"),\n",
    "        tf.feature_column.numeric_column(\"difgrirdbytotgrqty\"),\n",
    "        tf.feature_column.numeric_column(\"DIFGRIRV\")\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['WERKS', 'SCENARIO', 'KTOKK', 'VSTATU', 'VPATD', 'EKORG', 'EKGRP',\n",
       "       'TOTGRQTY', 'TOTIRQTY', 'NODLGR', 'NODLIR', 'DIFGRIRD', 'DIFGRIRV',\n",
       "       'STATUS'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create input function to load data into datasets\n",
    "CSV_COLUMNS = traindf.columns  #['WERKS', 'SCENARIO', 'KTOKK', 'VSTATU', 'VPATD', 'EKORG', 'EKGRP',\n",
    "                               #'TOTGRQTY', 'TOTIRQTY', 'NODLGR', 'NODLIR', 'DIFGRIRD', 'DIFGRIRV',\n",
    "                               #'STATUS']\n",
    "LABEL_COLUMN = 'STATUS'\n",
    "DEFAULTS = [['ML01'],['3'], ['1'], ['1'], [30.0], ['1'], ['A'], [0.], [80.0], [0.], [90.0], [-80.0], [-38100.0], [1]]  #First row is passed\n",
    "\n",
    "def read_dataset(filename, mode, batch_size = 512):\n",
    "    def _input_fn(v_test=False):\n",
    "        def decode_csv(value_column):\n",
    "            columns = tf.decode_csv(value_column, record_defaults = DEFAULTS)\n",
    "            features = dict(zip(CSV_COLUMNS, columns))\n",
    "            label = features.pop(LABEL_COLUMN)\n",
    "            return add_engineered(features), label\n",
    "        \n",
    "        # Create list of files that match pattern\n",
    "        file_list = tf.gfile.Glob(filename)\n",
    "\n",
    "        # Create dataset from file list\n",
    "        dataset = tf.data.TextLineDataset(file_list).map(decode_csv)\n",
    "\n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            num_epochs = None # indefinitely\n",
    "            dataset = dataset.shuffle(buffer_size = 10 * batch_size)\n",
    "        else:\n",
    "            num_epochs = 1 # end-of-input after this\n",
    "\n",
    "        dataset = dataset.repeat(num_epochs).batch(batch_size)\n",
    "        batch_features, batch_labels = dataset.make_one_shot_iterator().get_next()\n",
    "        \n",
    "        #Begins - Uncomment for testing only -----------------------------------------------------<\n",
    "        if v_test == True:\n",
    "            with tf.Session() as sess:\n",
    "                print(sess.run(batch_features))\n",
    "        #End - Uncomment for testing only -----------------------------------------------------<\n",
    "        return batch_features, batch_labels\n",
    "    return _input_fn\n",
    "\n",
    "# Serving function for external call\n",
    "def serving_fn():\n",
    "    feature_placeholders  = {'WERKS' : tf.placeholder(tf.string, [None]),\n",
    "            'SCENARIO' : tf.placeholder(tf.string, [None]),\n",
    "            'KTOKK' : tf.placeholder(tf.string, [None]),\n",
    "            'VSTATU' : tf.placeholder(tf.string, [None]),\n",
    "            'EKORG' : tf.placeholder(tf.string, [None]),\n",
    "            'EKGRP' : tf.placeholder(tf.string, [None]),\n",
    "            'VPATD' : tf.placeholder(tf.float32, [None]),\n",
    "            'TOTGRQTY' : tf.placeholder(tf.float32, [None]),\n",
    "            'TOTIRQTY' : tf.placeholder(tf.float32, [None]),\n",
    "            'NODLGR' : tf.placeholder(tf.float32, [None]),\n",
    "            'NODLIR' : tf.placeholder(tf.float32, [None]),\n",
    "            'DIFGRIRD' : tf.placeholder(tf.float32, [None]),\n",
    "            'DIFGRIRV' : tf.placeholder(tf.float32, [None])\n",
    "    }\n",
    "\n",
    "    #Features with transformation logic\n",
    "    features = {\n",
    "                key: tf.expand_dims(tensor, -1)\n",
    "                for key, tensor in feature_placeholders.items()\n",
    "            }\n",
    "    \n",
    "    #feat_changed = add_engineered(features.copy())\n",
    "    return tf.estimator.export.ServingInputReceiver(add_engineered(features), feature_placeholders )\n",
    "#serving_fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hrafiq\\Documents\\HRafiq\\hrafiq\\Machine_Deep_learning\\Deep learning\\GCP_GRIR\\Tflow_Pipeline_Estimator\\grir_train.csv\n",
      "{'NODLIR': array([ 0.00666673,  1.1668546 ,  0.8334673 , -0.1400237 ,  1.3668871 ,\n",
      "        0.6601059 , -0.553424  ,  1.4068935 , -0.1400237 ,  1.0468352 ,\n",
      "       -0.64677244, -0.51341754,  0.526751  , -1.1668566 ,  0.8334673 ,\n",
      "        0.7001124 , -0.10001722, -0.24670765, -1.0735083 , -0.8868113 ],\n",
      "      dtype=float32), 'EKGRP': array([b'A', b'A', b'A', b'A', b'A', b'A', b'A', b'A', b'A', b'A', b'A',\n",
      "       b'A', b'A', b'A', b'A', b'A', b'A', b'A', b'A', b'A'], dtype=object), 'SCENARIO': array([b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3',\n",
      "       b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3'], dtype=object), 'NODLGR': array([-1.2586846, -1.2586846, -1.2586846, -1.2586846, -1.2586846,\n",
      "       -1.2586846, -1.2586846, -1.2586846, -1.2586846, -1.2586846,\n",
      "       -1.2586846, -1.2586846, -1.2586846, -1.2586846, -1.2586846,\n",
      "       -1.2586846, -1.2586846, -1.2586846, -1.2586846, -1.2586846],\n",
      "      dtype=float32), 'grminusirbyvpatd': array([-1.4461993 , -2.0698836 , -2.0698836 , -1.81579   , -2.970761  ,\n",
      "       -1.7811409 , -1.7118425 , -1.4346496 , -1.734942  , -0.64926934,\n",
      "       -0.32972744, -0.5684214 , -0.8148152 , -1.0150102 , -0.9226125 ,\n",
      "       -2.2777781 , -3.80234   , -2.7397666 , -1.6425444 , -1.1690062 ],\n",
      "      dtype=float32), 'difgrirdbytotgrqty': array([-0.51340175, -0.51340175, -0.51340175, -0.51340175, -0.51340175,\n",
      "       -0.51340175, -0.51340175, -0.51340175, -0.51340175, -0.51340175,\n",
      "       -0.51340175, -0.51340175, -0.51340175, -0.51340175, -0.51340175,\n",
      "       -0.51340175, -0.51340175, -0.51340175, -0.51340175, -0.51340175],\n",
      "      dtype=float32), 'DIFGRIRD': array([-0.8159822 , -1.2422822 , -1.2422822 , -1.0686044 , -1.8580487 ,\n",
      "       -2.5369709 , -2.4422376 , -2.0633044 , -2.4738154 , -0.98965997,\n",
      "       -1.0528156 , -1.542271  , -2.0475154 , -2.4580266 , -2.26856   ,\n",
      "       -1.3843821 , -2.4264488 , -1.7001599 , -2.3475044 , -1.7001599 ],\n",
      "      dtype=float32), 'VPATD': array([-1.242383 , -1.242383 , -1.242383 , -1.242383 , -1.242383 ,\n",
      "       -0.0151804, -0.0151804, -0.0151804, -0.0151804, -0.0151804,\n",
      "        1.2120222,  1.2120222,  1.2120222,  1.2120222,  1.2120222,\n",
      "       -1.242383 , -1.242383 , -1.242383 , -0.0151804, -0.0151804],\n",
      "      dtype=float32), 'WERKS': array([b'ML01', b'ML01', b'ML01', b'ML01', b'ML01', b'ML01', b'ML01',\n",
      "       b'ML01', b'ML01', b'ML01', b'ML01', b'ML01', b'ML01', b'ML01',\n",
      "       b'ML01', b'ML01', b'ML01', b'ML01', b'ML01', b'ML01'], dtype=object), 'TOTGRQTY': array([-1.045735, -1.045735, -1.045735, -1.045735, -1.045735, -1.045735,\n",
      "       -1.045735, -1.045735, -1.045735, -1.045735, -1.045735, -1.045735,\n",
      "       -1.045735, -1.045735, -1.045735, -1.045735, -1.045735, -1.045735,\n",
      "       -1.045735, -1.045735], dtype=float32), 'VSTATU': array([b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1'], dtype=object), 'EKORG': array([b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1'], dtype=object), 'KTOKK': array([b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1'], dtype=object), 'TOTIRQTY': array([-0.22744055,  0.20457521,  0.20457521,  0.02856879,  0.82859796,\n",
      "        1.5166231 ,  1.4206196 ,  1.0366056 ,  1.4526207 , -0.05143413,\n",
      "        0.01256821,  0.5085863 ,  1.020605  ,  1.4366201 ,  1.2446132 ,\n",
      "        0.34858048,  1.404619  ,  0.66859215,  1.3246161 ,  0.66859215],\n",
      "      dtype=float32), 'DIFGRIRV': array([-1.3794957 , -1.5333624 , -0.917896  , -0.31122202, -2.9357464 ,\n",
      "       -0.8739341 , -2.7467105 , -2.9401426 , -2.32028   ,  0.08883115,\n",
      "       -1.757568  , -0.03865832, -2.0257356 , -1.2783835 , -1.0629703 ,\n",
      "       -0.98383886, -2.3114877 , -0.4255229 , -0.7948027 , -2.1268477 ],\n",
      "      dtype=float32)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'DIFGRIRD': <tf.Tensor 'IteratorGetNext_1:0' shape=(?,) dtype=float32>,\n",
       "  'DIFGRIRV': <tf.Tensor 'IteratorGetNext_1:1' shape=(?,) dtype=float32>,\n",
       "  'EKGRP': <tf.Tensor 'IteratorGetNext_1:2' shape=(?,) dtype=string>,\n",
       "  'EKORG': <tf.Tensor 'IteratorGetNext_1:3' shape=(?,) dtype=string>,\n",
       "  'KTOKK': <tf.Tensor 'IteratorGetNext_1:4' shape=(?,) dtype=string>,\n",
       "  'NODLGR': <tf.Tensor 'IteratorGetNext_1:5' shape=(?,) dtype=float32>,\n",
       "  'NODLIR': <tf.Tensor 'IteratorGetNext_1:6' shape=(?,) dtype=float32>,\n",
       "  'SCENARIO': <tf.Tensor 'IteratorGetNext_1:7' shape=(?,) dtype=string>,\n",
       "  'TOTGRQTY': <tf.Tensor 'IteratorGetNext_1:8' shape=(?,) dtype=float32>,\n",
       "  'TOTIRQTY': <tf.Tensor 'IteratorGetNext_1:9' shape=(?,) dtype=float32>,\n",
       "  'VPATD': <tf.Tensor 'IteratorGetNext_1:10' shape=(?,) dtype=float32>,\n",
       "  'VSTATU': <tf.Tensor 'IteratorGetNext_1:11' shape=(?,) dtype=string>,\n",
       "  'WERKS': <tf.Tensor 'IteratorGetNext_1:12' shape=(?,) dtype=string>,\n",
       "  'difgrirdbytotgrqty': <tf.Tensor 'IteratorGetNext_1:13' shape=(?,) dtype=float32>,\n",
       "  'grminusirbyvpatd': <tf.Tensor 'IteratorGetNext_1:14' shape=(?,) dtype=float32>},\n",
       " <tf.Tensor 'IteratorGetNext_1:15' shape=(?,) dtype=int32>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test dataset read function\n",
    "eval_file = os.getcwd() + \"\\grir_train.csv\"\n",
    "fn_d = read_dataset(filename = eval_file,\n",
    "                    mode = tf.estimator.ModeKeys.EVAL,\n",
    "                    batch_size = 20)\n",
    "\n",
    "fn_d(v_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create estimator train and evaluate function\n",
    "def train_and_evaluate(output_dir, num_train_steps, train_file, eval_file):    \n",
    "##### Create Canned estimator instance\n",
    "    ## setting the checkpoint interval to be much lower for this task\n",
    "#     run_config = tf.estimator.RunConfig(save_checkpoints_secs = 40, \n",
    "#                                         keep_checkpoint_max = 3)\n",
    "    \n",
    "    estimator = tf.estimator.DNNClassifier(feature_columns=create_feature_cols(),\n",
    "                                          n_classes=2,\n",
    "                                          hidden_units=[32,64,64,64,64,64,\n",
    "                                                        64,64,64,64,64,64,\n",
    "                                                        64,64,64,64,64,64,\n",
    "                                                        32],\n",
    "                                          dropout = 0.2,\n",
    "                                          optimizer=tf.train.AdamOptimizer(learning_rate=0.001))\n",
    "#                                           config = run_config)\n",
    "    train_spec = tf.estimator.TrainSpec(input_fn = read_dataset(\n",
    "                                                filename = train_file,\n",
    "                                                mode = tf.estimator.ModeKeys.TRAIN,\n",
    "                                                batch_size = 128),\n",
    "                                      max_steps = num_train_steps)\n",
    "    exp = tf.estimator.LatestExporter(\"decision\", serving_fn)\n",
    "    eval_spec = tf.estimator.EvalSpec(input_fn = read_dataset(\n",
    "                                                filename = eval_file,\n",
    "                                                mode = tf.estimator.ModeKeys.EVAL,\n",
    "                                                batch_size = 128),\n",
    "                                    steps = None, \n",
    "                                    exporters = exp,\n",
    "                                    start_delay_secs = 20, # start evaluating after N seconds, \n",
    "                                    throttle_secs = 45)  # evaluate every N seconds\n",
    "    tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = os.getcwd() + \"\\grir_train.csv\"\n",
    "eval_file = os.getcwd() + \"\\grir_eval.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\hrafiq\\AppData\\Local\\Temp\\tmptj5bya1t\n",
      "INFO:tensorflow:Using config: {'_master': '', '_log_step_count_steps': 100, '_num_ps_replicas': 0, '_keep_checkpoint_every_n_hours': 10000, '_num_worker_replicas': 1, '_is_chief': True, '_task_type': 'worker', '_save_checkpoints_steps': None, '_model_dir': 'C:\\\\Users\\\\hrafiq\\\\AppData\\\\Local\\\\Temp\\\\tmptj5bya1t', '_service': None, '_tf_random_seed': None, '_keep_checkpoint_max': 5, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x00000201035B1EB8>, '_save_checkpoints_secs': 600, '_task_id': 0, '_session_config': None, '_save_summary_steps': 100}\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after 45 secs (eval_spec.throttle_secs) or training is finished.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\hrafiq\\AppData\\Local\\Temp\\tmptj5bya1t\\model.ckpt.\n",
      "INFO:tensorflow:loss = 88.63139, step = 1\n",
      "INFO:tensorflow:global_step/sec: 36.6932\n",
      "INFO:tensorflow:loss = 87.67997, step = 101 (2.743 sec)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-31b3e811c9d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Final trainer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_and_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_train_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-33-4b52229e04c7>\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[1;34m(output_dir, num_train_steps, train_file, eval_file)\u001b[0m\n\u001b[0;32m     29\u001b[0m                                     \u001b[0mstart_delay_secs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m# start evaluating after N seconds,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m                                     throttle_secs = 45)  # evaluate every N seconds\n\u001b[1;32m---> 31\u001b[1;33m     \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_and_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_spec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_spec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\hrafiq\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\estimator\\training.py\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[1;34m(estimator, train_spec, eval_spec)\u001b[0m\n\u001b[0;32m    428\u001b[0m       config.task_type != run_config_lib.TaskType.EVALUATOR):\n\u001b[0;32m    429\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Running training and evaluation locally (non-distributed).'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 430\u001b[1;33m     \u001b[0mexecutor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_local\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    431\u001b[0m     \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hrafiq\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\estimator\\training.py\u001b[0m in \u001b[0;36mrun_local\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    607\u001b[0m           \u001b[0minput_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    608\u001b[0m           \u001b[0mmax_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 609\u001b[1;33m           hooks=train_hooks)\n\u001b[0m\u001b[0;32m    610\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m       \u001b[1;31m# Final export signal: For any eval result with global_step >= train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hrafiq\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[0;32m    300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m     \u001b[0msaving_listeners\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loss for final step: %s.'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hrafiq\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m    781\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 783\u001b[1;33m           \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    784\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    785\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hrafiq\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    519\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m                           run_metadata=run_metadata)\n\u001b[0m\u001b[0;32m    522\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mshould_stop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hrafiq\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    890\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 892\u001b[1;33m                               run_metadata=run_metadata)\n\u001b[0m\u001b[0;32m    893\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[1;32mc:\\users\\hrafiq\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    950\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    951\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 952\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    953\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    954\u001b[0m       \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hrafiq\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1022\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1023\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1024\u001b[1;33m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[0;32m   1025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1026\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hrafiq\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    825\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    826\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 827\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    828\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    829\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hrafiq\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    887\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 889\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    890\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hrafiq\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1120\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1121\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hrafiq\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1315\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1317\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1318\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1319\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hrafiq\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1321\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1322\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1323\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1324\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hrafiq\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1302\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1304\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Final trainer\n",
    "train_and_evaluate(None, num_train_steps=20000, train_file=train_file, eval_file=eval_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Only DNN Deep wide classifier\n",
    "# def get_deep_wide_features():\n",
    "#     werks_c = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "#             key='WERKS',\n",
    "#             vocabulary_list=['ML01','ML02','ML03'])\n",
    "#     scenario_c = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "#             key='SCENARIO',\n",
    "#             vocabulary_list=['1','2','3','4'])\n",
    "#     ktokk_c = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "#             key='KTOKK',\n",
    "#             vocabulary_list=['1','2'])    \n",
    "#     vstatu_c = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "#             key='VSTATU',\n",
    "#             vocabulary_list=['1','2'])\n",
    "#     ekorg_c = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "#             key='EKORG',\n",
    "#             vocabulary_list=['1','2'])   \n",
    "#     ekgrp_c = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "#             key='EKGRP',\n",
    "#             vocabulary_list=['A','B','C'])\n",
    "#     deep_columns = [\n",
    "#         tf.feature_column.numeric_column('VPATD'),\n",
    "#         tf.feature_column.numeric_column(\"TOTGRQTY\"),\n",
    "#         tf.feature_column.numeric_column(\"TOTIRQTY\"),\n",
    "#         tf.feature_column.numeric_column(\"NODLGR\"),\n",
    "#         tf.feature_column.numeric_column(\"NODLIR\"),\n",
    "#         tf.feature_column.numeric_column(\"DIFGRIRD\"),\n",
    "#         tf.feature_column.numeric_column(\"DIFGRIRV\")\n",
    "#     ]\n",
    "#     wide_columns = [\n",
    "#         tf.feature_column.indicator_column(werks_c),\n",
    "#         tf.feature_column.indicator_column(scenario_c),\n",
    "#         tf.feature_column.indicator_column(ktokk_c),\n",
    "#         tf.feature_column.indicator_column(vstatu_c),\n",
    "#         tf.feature_column.indicator_column(ekorg_c),\n",
    "#         tf.feature_column.indicator_column(ekgrp_c),\n",
    "#     ]\n",
    "#     return deep_columns, wide_columns\n",
    "\n",
    "# def train_and_evaluate_deep(output_dir, num_train_steps):    \n",
    "# ##### Create Canned estimator instance\n",
    "#     #Get features\n",
    "#     deep, wide = get_deep_wide_features()\n",
    "\n",
    "#     estimator = tf.estimator.DNNLinearCombinedClassifier(\n",
    "#                                     linear_feature_columns = wide,\n",
    "#                                     dnn_feature_columns = deep,\n",
    "#                                     n_classes=2,\n",
    "#                                     dnn_hidden_units = [32,64,64,64,64,64,\n",
    "#                                                         64,64,64,64,64,64,\n",
    "#                                                         64,64,64,64,64,64,\n",
    "#                                                         32],\n",
    "#                                     dnn_dropout = 0.1,\n",
    "#                                     dnn_optimizer=tf.train.AdamOptimizer(learning_rate=0.0001))\n",
    "#     train_spec = tf.estimator.TrainSpec(input_fn = make_input_fn(traindf, None), \n",
    "#                                       max_steps = num_train_steps)\n",
    "#     exp = tf.estimator.LatestExporter(\"decision\", serving_fn)\n",
    "#     eval_spec = tf.estimator.EvalSpec(input_fn = make_input_fn(evaldf, 1), \n",
    "#                                     steps = None, \n",
    "#                                     exporters = exp,\n",
    "#                                     start_delay_secs = 1, # start evaluating after N seconds, \n",
    "#                                     throttle_secs = 40)  # evaluate every N seconds\n",
    "#     tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #setup exponential decay function for learning rates\n",
    "# def get_global_step():\n",
    "#     if tf.train.get_global_step() is None:\n",
    "#         return 1\n",
    "#     else:\n",
    "#         return tf.train.get_global_step()\n",
    "\n",
    "# def get_exp_decay_optimizer():\n",
    "#     def exp_decay(global_step=global_step):\n",
    "#         return tf.train.exponential_decay(\n",
    "#           learning_rate=0.0001, global_step=global_step,\n",
    "#           decay_steps=100, decay_rate=0.8, staircase=True)\n",
    "#     # use customized decay function in learning_rate\n",
    "#     return tf.train.AdagradOptimizer(learning_rate=exp_decay(tf.train.get_global_step()))\n",
    "\n",
    "# # setup stepwise decay function for learning rates\n",
    "# def get_stepw_decay_optimizer2():\n",
    "#     def step_decay():\n",
    "#         return tf.train.piecewise_constant(get_global_step(), \n",
    "#                                            boundaries=[10000,20000,50000,100000], \n",
    "#                                            values=[0.001,0.0005,0.0001,0.00005,0.00002])\n",
    "#     # use customized decay function in learning_rate\n",
    "#     return tf.train.AdamOptimizer(learning_rate=step_decay)#,epsilon=0.001)\n",
    "\n",
    "# # setup stepwise decay function for learning rates\n",
    "# def get_stepw_decay_optimizer():\n",
    "#     def step_decay(global_step):\n",
    "#         return tf.train.piecewise_constant(global_step, boundaries=[10000,20000,50000,100000], values=[0.001,0.0005,0.0001,0.00005,0.00002])\n",
    "#                                          # use customized decay function in learning_rate\n",
    "#     return tf.train.AdamOptimizer(learning_rate=step_decay(tf.train.get_global_step()))#,epsilon=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score = classifier.evaluate(input_fn=get_input_fn(training_set, num_epochs=1, shuffle=False))[\"accuracy\"]\n",
    "print(\"\\nTrain Accuracy: {0:f}\\n\".format(accuracy_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score = classifier.evaluate(input_fn=get_validation_input_fn(test_set, num_epochs=1, shuffle=False))[\"accuracy\"]\n",
    "print(\"\\nTest Accuracy: {0:f}\\n\".format(accuracy_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run model on Prediction data set\n",
    "predictions = classifier.predict_classes(input_fn=get_prediction_input_fn(test_set))\n",
    "for p in list(predictions):\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in list(test_set['STATUS']):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict with disk saved model\n",
    "from tensorflow.contrib import predictor\n",
    "\n",
    "export_dir = os.getcwd() + \"/tflow_grir_model\"\n",
    "predict_fn = predictor.from_saved_model(export_dir,signature_def_key='predict')\n",
    "\n",
    "predictions = predict_fn({\"DIFGRIRV\": [-38100],\"NODLIR\": [90],\"VSTATU\": [\"1\"],\"NODLGR\": [0],\"DIFGRIRD\": [-80],\"VPATD\": [30],\n",
    "                          \"WERKS\": [\"ML01\"],\n",
    "                          \"EKORG\": [\"1\"],\"TOTGRQTY\": [0],\"SCENARIO\": [\"3\"],\"TOTIRQTY\": [80],\"KTOKK\": [\"1\"],\"EKGRP\": [\"A\"]})\n",
    "print(predictions['probabilities'][0,1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
