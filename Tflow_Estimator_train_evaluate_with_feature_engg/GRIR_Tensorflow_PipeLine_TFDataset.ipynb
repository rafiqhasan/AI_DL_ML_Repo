{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from tensorflow.python.training import training_util\n",
    "\n",
    "print(tf.__version__)\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = '{:.1f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"GRIR_GCP_Data.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WERKS</th>\n",
       "      <th>SCENARIO</th>\n",
       "      <th>KTOKK</th>\n",
       "      <th>VSTATU</th>\n",
       "      <th>VPATD</th>\n",
       "      <th>EKORG</th>\n",
       "      <th>EKGRP</th>\n",
       "      <th>TOTGRQTY</th>\n",
       "      <th>TOTIRQTY</th>\n",
       "      <th>NODLGR</th>\n",
       "      <th>NODLIR</th>\n",
       "      <th>DIFGRIRD</th>\n",
       "      <th>DIFGRIRV</th>\n",
       "      <th>STATUS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ML01</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>-80</td>\n",
       "      <td>-38100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ML01</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>177</td>\n",
       "      <td>-107</td>\n",
       "      <td>-41600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ML01</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>152</td>\n",
       "      <td>-107</td>\n",
       "      <td>-27600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ML01</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>-96</td>\n",
       "      <td>-13800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ML01</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>192</td>\n",
       "      <td>-146</td>\n",
       "      <td>-73500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ML01</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "      <td>0</td>\n",
       "      <td>139</td>\n",
       "      <td>-189</td>\n",
       "      <td>-26600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ML01</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>183</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>-183</td>\n",
       "      <td>-69200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ML01</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "      <td>195</td>\n",
       "      <td>-159</td>\n",
       "      <td>-73600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ML01</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>185</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>-185</td>\n",
       "      <td>-59500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ML01</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>168</td>\n",
       "      <td>-91</td>\n",
       "      <td>-4700</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  WERKS  SCENARIO  KTOKK  VSTATU  VPATD  EKORG EKGRP  TOTGRQTY  TOTIRQTY  \\\n",
       "0  ML01         3      1       1     30      1     A         0        80   \n",
       "1  ML01         3      1       1     30      1     A         0       107   \n",
       "2  ML01         3      1       1     30      1     A         0       107   \n",
       "3  ML01         3      1       1     30      1     A         0        96   \n",
       "4  ML01         3      1       1     30      1     A         0       146   \n",
       "5  ML01         3      1       1     60      1     A         0       189   \n",
       "6  ML01         3      1       1     60      1     A         0       183   \n",
       "7  ML01         3      1       1     60      1     A         0       159   \n",
       "8  ML01         3      1       1     60      1     A         0       185   \n",
       "9  ML01         3      1       1     60      1     A         0        91   \n",
       "\n",
       "   NODLGR  NODLIR  DIFGRIRD  DIFGRIRV  STATUS  \n",
       "0       0      90       -80    -38100       1  \n",
       "1       0     177      -107    -41600       0  \n",
       "2       0     152      -107    -27600       1  \n",
       "3       0      79       -96    -13800       1  \n",
       "4       0     192      -146    -73500       0  \n",
       "5       0     139      -189    -26600       1  \n",
       "6       0      48      -183    -69200       0  \n",
       "7       0     195      -159    -73600       0  \n",
       "8       0      79      -185    -59500       0  \n",
       "9       0     168       -91     -4700       1  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SCENARIO</th>\n",
       "      <th>KTOKK</th>\n",
       "      <th>VSTATU</th>\n",
       "      <th>VPATD</th>\n",
       "      <th>EKORG</th>\n",
       "      <th>TOTGRQTY</th>\n",
       "      <th>TOTIRQTY</th>\n",
       "      <th>NODLGR</th>\n",
       "      <th>NODLIR</th>\n",
       "      <th>DIFGRIRD</th>\n",
       "      <th>DIFGRIRV</th>\n",
       "      <th>STATUS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8279.0</td>\n",
       "      <td>8279.0</td>\n",
       "      <td>8279.0</td>\n",
       "      <td>8279.0</td>\n",
       "      <td>8279.0</td>\n",
       "      <td>8279.0</td>\n",
       "      <td>8279.0</td>\n",
       "      <td>8279.0</td>\n",
       "      <td>8279.0</td>\n",
       "      <td>8279.0</td>\n",
       "      <td>8279.0</td>\n",
       "      <td>8279.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.1</td>\n",
       "      <td>60.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>65.9</td>\n",
       "      <td>94.1</td>\n",
       "      <td>103.1</td>\n",
       "      <td>89.5</td>\n",
       "      <td>-28.2</td>\n",
       "      <td>-6716.3</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>24.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>63.0</td>\n",
       "      <td>62.4</td>\n",
       "      <td>82.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>63.2</td>\n",
       "      <td>22797.4</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>-75000.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-56.0</td>\n",
       "      <td>-9600.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-546.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5482.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>59200.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       SCENARIO  KTOKK  VSTATU  VPATD  EKORG  TOTGRQTY  TOTIRQTY  NODLGR  \\\n",
       "count    8279.0 8279.0  8279.0 8279.0 8279.0    8279.0    8279.0  8279.0   \n",
       "mean        2.6    1.5     1.1   60.3    1.3      65.9      94.1   103.1   \n",
       "std         1.1    0.5     0.3   24.4    0.5      63.0      62.4    82.0   \n",
       "min         1.0    1.0     1.0   30.0    1.0       0.0       0.0     0.0   \n",
       "25%         2.0    1.0     1.0   30.0    1.0       0.0      54.0     0.0   \n",
       "50%         3.0    1.0     1.0   60.0    1.0      55.0      99.0   112.0   \n",
       "75%         4.0    2.0     1.0   90.0    2.0     121.0     146.0   172.0   \n",
       "max         4.0    2.0     2.0   90.0    2.0     200.0     200.0   268.0   \n",
       "\n",
       "       NODLIR  DIFGRIRD  DIFGRIRV  STATUS  \n",
       "count  8279.0    8279.0    8279.0  8279.0  \n",
       "mean     89.5     -28.2   -6716.3     0.4  \n",
       "std      75.0      63.2   22797.4     0.5  \n",
       "min       0.0    -200.0  -75000.0     0.0  \n",
       "25%      10.0     -56.0   -9600.0     0.0  \n",
       "50%      82.0      -2.0    -546.0     0.0  \n",
       "75%     154.0      11.0    5482.0     1.0  \n",
       "max     242.0      74.0   59200.0     1.0  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['WERKS', 'SCENARIO', 'KTOKK', 'VSTATU', 'VPATD', 'EKORG', 'EKGRP',\n",
       "       'TOTGRQTY', 'TOTIRQTY', 'NODLGR', 'NODLIR', 'DIFGRIRD', 'DIFGRIRV',\n",
       "       'STATUS'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1gAAADQCAYAAAAalMCAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/w+7u+KPm2HCDgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x298406ce550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Facet1\n",
    "g = sns.FacetGrid(df, col=\"SCENARIO\")\n",
    "g = g.map(plt.hist, \"TOTGRQTY\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1gAAADQCAYAAAAalMCAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2984077bf98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Facet1\n",
    "g = sns.FacetGrid(df, col=\"SCENARIO\")\n",
    "g = g.map(plt.hist, \"TOTIRQTY\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WERKS</th>\n",
       "      <th>SCENARIO</th>\n",
       "      <th>KTOKK</th>\n",
       "      <th>VSTATU</th>\n",
       "      <th>VPATD</th>\n",
       "      <th>EKORG</th>\n",
       "      <th>EKGRP</th>\n",
       "      <th>TOTGRQTY</th>\n",
       "      <th>TOTIRQTY</th>\n",
       "      <th>NODLGR</th>\n",
       "      <th>NODLIR</th>\n",
       "      <th>DIFGRIRD</th>\n",
       "      <th>DIFGRIRV</th>\n",
       "      <th>STATUS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ML01</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>-80</td>\n",
       "      <td>-38100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ML01</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>177</td>\n",
       "      <td>-107</td>\n",
       "      <td>-41600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ML01</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>152</td>\n",
       "      <td>-107</td>\n",
       "      <td>-27600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ML01</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>-96</td>\n",
       "      <td>-13800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ML01</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>192</td>\n",
       "      <td>-146</td>\n",
       "      <td>-73500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2155</th>\n",
       "      <td>ML03</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>2</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>-115</td>\n",
       "      <td>-55300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2156</th>\n",
       "      <td>ML03</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>2</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>-120</td>\n",
       "      <td>-63500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2157</th>\n",
       "      <td>ML03</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>2</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>157</td>\n",
       "      <td>0</td>\n",
       "      <td>186</td>\n",
       "      <td>-157</td>\n",
       "      <td>-45000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2158</th>\n",
       "      <td>ML03</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>2</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>121</td>\n",
       "      <td>-97</td>\n",
       "      <td>-62300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2159</th>\n",
       "      <td>ML03</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>2</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>152</td>\n",
       "      <td>0</td>\n",
       "      <td>170</td>\n",
       "      <td>-152</td>\n",
       "      <td>-55700</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2160 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     WERKS  SCENARIO  KTOKK  VSTATU  VPATD  EKORG EKGRP  TOTGRQTY  TOTIRQTY  \\\n",
       "0     ML01         3      1       1     30      1     A         0        80   \n",
       "1     ML01         3      1       1     30      1     A         0       107   \n",
       "2     ML01         3      1       1     30      1     A         0       107   \n",
       "3     ML01         3      1       1     30      1     A         0        96   \n",
       "4     ML01         3      1       1     30      1     A         0       146   \n",
       "...    ...       ...    ...     ...    ...    ...   ...       ...       ...   \n",
       "2155  ML03         3      2       1     90      2     C         0       115   \n",
       "2156  ML03         3      2       1     90      2     C         0       120   \n",
       "2157  ML03         3      2       1     90      2     C         0       157   \n",
       "2158  ML03         3      2       1     90      2     C         0        97   \n",
       "2159  ML03         3      2       1     90      2     C         0       152   \n",
       "\n",
       "      NODLGR  NODLIR  DIFGRIRD  DIFGRIRV  STATUS  \n",
       "0          0      90       -80    -38100       1  \n",
       "1          0     177      -107    -41600       0  \n",
       "2          0     152      -107    -27600       1  \n",
       "3          0      79       -96    -13800       1  \n",
       "4          0     192      -146    -73500       0  \n",
       "...      ...     ...       ...       ...     ...  \n",
       "2155       0      59      -115    -55300       0  \n",
       "2156       0      60      -120    -63500       0  \n",
       "2157       0     186      -157    -45000       0  \n",
       "2158       0     121       -97    -62300       0  \n",
       "2159       0     170      -152    -55700       0  \n",
       "\n",
       "[2160 rows x 14 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Filter out scenario = 3 ( It has TOTGRQTY == 0 )\n",
    "df_s1 = df[df['SCENARIO'].eq(3) & df['TOTGRQTY'].eq(0)]\n",
    "df_s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8279 entries, 0 to 8278\n",
      "Data columns (total 14 columns):\n",
      "WERKS       8279 non-null object\n",
      "SCENARIO    8279 non-null object\n",
      "KTOKK       8279 non-null object\n",
      "VSTATU      8279 non-null object\n",
      "VPATD       8279 non-null int64\n",
      "EKORG       8279 non-null object\n",
      "EKGRP       8279 non-null object\n",
      "TOTGRQTY    8279 non-null int64\n",
      "TOTIRQTY    8279 non-null int64\n",
      "NODLGR      8279 non-null int64\n",
      "NODLIR      8279 non-null int64\n",
      "DIFGRIRD    8279 non-null int64\n",
      "DIFGRIRV    8279 non-null int64\n",
      "STATUS      8279 non-null int64\n",
      "dtypes: int64(8), object(6)\n",
      "memory usage: 905.6+ KB\n"
     ]
    }
   ],
   "source": [
    "#Mark some columns as categorical so that TF treats them as categorical\n",
    "for col_cat in ['SCENARIO','KTOKK','VSTATU','EKORG']:\n",
    "    df[col_cat] = df[col_cat].astype('str') #Very important to keep this as STR -> Tensorflow treats only STR as categorical\n",
    "    \n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DIFGRIRD</th>\n",
       "      <th>DIFGRIRV</th>\n",
       "      <th>NODLGR</th>\n",
       "      <th>NODLIR</th>\n",
       "      <th>Random</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>TOTGRQTY</th>\n",
       "      <th>TOTIRQTY</th>\n",
       "      <th>VPATD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DIFGRIRD  DIFGRIRV  NODLGR  NODLIR  Random  STATUS  TOTGRQTY  TOTIRQTY  \\\n",
       "0       0.2       0.1     0.3     0.3       0     0.2       0.3       0.6   \n",
       "1       0.1       0.1     0.1     0.3       1     1.0       0.0       0.8   \n",
       "2       1.0       0.9     0.8     1.0       2     1.0       0.9       0.4   \n",
       "3       0.5       0.2     0.1     0.1       3     1.0       0.4       0.9   \n",
       "4       1.0       0.6     0.5     0.5       4     1.0       1.0       0.9   \n",
       "5       0.7       0.4     0.2     0.4       5     0.8       0.7       0.2   \n",
       "6       0.5       0.3     0.4     1.0       6     1.0       0.9       0.7   \n",
       "7       0.8       0.3     0.7     0.6       7     0.7       0.9       0.8   \n",
       "8       0.8       0.6     1.0     1.0       8     1.0       0.0       0.3   \n",
       "9       1.0       0.5     0.4     0.4       9     1.0       0.0       0.1   \n",
       "\n",
       "   VPATD  \n",
       "0    0.9  \n",
       "1    1.0  \n",
       "2    0.8  \n",
       "3    1.0  \n",
       "4    1.0  \n",
       "5    1.0  \n",
       "6    0.3  \n",
       "7    0.6  \n",
       "8    0.4  \n",
       "9    1.0  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Split dataset -> Split 10 times and choose the one with best P values( Significance test )\n",
    "p_res = {}\n",
    "t_res = []\n",
    "for i in range(10):\n",
    "    np.random.seed(seed=i) #makes result reproducible\n",
    "    msk = np.random.rand(len(df)) < 0.8\n",
    "    X_train = df[msk]\n",
    "    X_test = df[~msk]\n",
    "\n",
    "    #Run Significance Tests on both the distributions( Train and Test ) for all numerical attributes\n",
    "    p_res = {}\n",
    "    for c_ in X_train.columns:\n",
    "        if not X_train[c_].dtype == 'object':\n",
    "            try:\n",
    "                _, a = scipy.stats.ks_2samp(X_train[c_].values,X_test[c_].values)\n",
    "                #print('P-value for column {} is {}'.format(c_.upper(), a))\n",
    "                p_res['Random'] = i\n",
    "                p_res[c_] = a\n",
    "            except:\n",
    "                p_res['Random'] = i\n",
    "                p_res[c_] = 'Error'\n",
    "    t_res.append(p_res)\n",
    "\n",
    "p_df = pd.DataFrame(t_res)\n",
    "p_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare train and test data set\n",
    "np.random.seed(seed=2) #makes result reproducible\n",
    "msk = np.random.rand(len(df)) < 0.8\n",
    "traindf = df[msk]\n",
    "evaldf = df[~msk]\n",
    "#evaldf[evaldf['STATUS'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6629 entries, 0 to 8278\n",
      "Data columns (total 14 columns):\n",
      "WERKS       6629 non-null object\n",
      "SCENARIO    6629 non-null object\n",
      "KTOKK       6629 non-null object\n",
      "VSTATU      6629 non-null object\n",
      "VPATD       6629 non-null int64\n",
      "EKORG       6629 non-null object\n",
      "EKGRP       6629 non-null object\n",
      "TOTGRQTY    6629 non-null int64\n",
      "TOTIRQTY    6629 non-null int64\n",
      "NODLGR      6629 non-null int64\n",
      "NODLIR      6629 non-null int64\n",
      "DIFGRIRD    6629 non-null int64\n",
      "DIFGRIRV    6629 non-null int64\n",
      "STATUS      6629 non-null int64\n",
      "dtypes: int64(8), object(6)\n",
      "memory usage: 776.8+ KB\n"
     ]
    }
   ],
   "source": [
    "traindf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1650 entries, 16 to 8272\n",
      "Data columns (total 14 columns):\n",
      "WERKS       1650 non-null object\n",
      "SCENARIO    1650 non-null object\n",
      "KTOKK       1650 non-null object\n",
      "VSTATU      1650 non-null object\n",
      "VPATD       1650 non-null int64\n",
      "EKORG       1650 non-null object\n",
      "EKGRP       1650 non-null object\n",
      "TOTGRQTY    1650 non-null int64\n",
      "TOTIRQTY    1650 non-null int64\n",
      "NODLGR      1650 non-null int64\n",
      "NODLIR      1650 non-null int64\n",
      "DIFGRIRD    1650 non-null int64\n",
      "DIFGRIRV    1650 non-null int64\n",
      "STATUS      1650 non-null int64\n",
      "dtypes: int64(8), object(6)\n",
      "memory usage: 193.4+ KB\n"
     ]
    }
   ],
   "source": [
    "evaldf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Files To be used in Tensorflow pipeline dataset API\n",
    "traindf.to_csv(\"grir_train.csv\", index=False, header=False)\n",
    "evaldf.to_csv(\"grir_eval.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################## Tensorflow Pipeline building and Modeling ############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_new_features(df_temp):   \n",
    "    #Add any feature engineering or new column here\n",
    "    df_temp['grminusirbyvpatd'] = ( df_temp['TOTGRQTY'] - df_temp['TOTIRQTY'] ) / df_temp['VPATD']\n",
    "    \n",
    "    df_temp['difgrirdbytotgrqty'] = tf.where( tf.not_equal(tf.cast(df_temp['TOTGRQTY'], tf.float32), tf.cast(0, tf.float32)),\n",
    "                                              tf.cast(tf.divide(df_temp['DIFGRIRD'], df_temp['TOTGRQTY']), tf.float32),\n",
    "                                              tf.cast(tf.zeros_like(df_temp['DIFGRIRD']), tf.float32))\n",
    "    return df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test add_new_features for X_train\n",
    "# df_dummy = add_new_features(traindf.copy())\n",
    "# print(df_dummy.head())\n",
    "# print(df_dummy.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RETURNS a pre-processing( New columns + Transformations ) function to be used inside pipeline\n",
    "def create_add_engineered_fn(df):\n",
    "    #Add new features in the set so that it's details can be copied to parameters of fn_add_engineered\n",
    "    df = add_new_features(df)\n",
    "    \n",
    "    #Get min max for each numerical column to use for scaling\n",
    "    cols_mean = {}\n",
    "    cols_std = {}\n",
    "    num_feats = []\n",
    "    for col_norm in list(df.columns):\n",
    "        if not df[col_norm].dtype == 'object' and not col_norm in ['STATUS']:\n",
    "            cols_mean[col_norm] = df[col_norm].mean()\n",
    "            cols_std[col_norm] = df[col_norm].std()\n",
    "            num_feats.append(col_norm)\n",
    "\n",
    "    #Pass all the above calculated values to be used by main function which will be called in Pipeline\n",
    "    def fn_add_engineered(features, cols_mean = cols_mean, cols_std = cols_std, num_feats = num_feats):\n",
    "        #Save value here for 0-1 scaling during training and serving\n",
    "#         print(\"mean\", cols_mean)\n",
    "#         print(\"std\", cols_std)\n",
    "#         print(features)\n",
    "        \n",
    "        #Add new features AGAIN as the function add_engineered will be called with data\n",
    "        features = add_new_features(features)\n",
    "        \n",
    "        #Normalize few numerical columns\n",
    "        for col_norm in list(num_feats):\n",
    "            mean_value = cols_mean[col_norm]\n",
    "            std_value = cols_std[col_norm]\n",
    "            features[col_norm] = (features[col_norm] - mean_value) / std_value\n",
    "\n",
    "#         print(\"..... Done processing \")\n",
    "        #print(features)\n",
    "        return features\n",
    "    \n",
    "    return fn_add_engineered\n",
    "\n",
    "#Generate pre-processing function as per training data\n",
    "add_engineered = create_add_engineered_fn(traindf.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test run add_engineered on copy of X_test\n",
    "# dummy = traindf.copy()\n",
    "# dummy = add_engineered(dummy)\n",
    "# dummy.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your feature columns\n",
    "def create_feature_cols():\n",
    "#   lat_buck = tf.feature_column.bucketized_column(tf.feature_column.numeric_column('latitude'), \n",
    "#                                                  boundaries = np.arange(32.0, 42, 1).tolist())\n",
    "#   long_buck = tf.feature_column.bucketized_column(tf.feature_column.numeric_column('longitude'),\n",
    "#                                                   boundaries = np.arange(1, 52, 1).tolist())\n",
    "    werks_c = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            key='WERKS',\n",
    "            vocabulary_list=['ML01','ML02','ML03'])\n",
    "    scenario_c = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            key='SCENARIO',\n",
    "            vocabulary_list=['1','2','3','4'])\n",
    "    ktokk_c = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            key='KTOKK',\n",
    "            vocabulary_list=['1','2'])    \n",
    "    vstatu_c = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            key='VSTATU',\n",
    "            vocabulary_list=['1','2'])\n",
    "    ekorg_c = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            key='EKORG',\n",
    "            vocabulary_list=['1','2'])   \n",
    "    ekgrp_c = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            key='EKGRP',\n",
    "            vocabulary_list=['A','B','C'])\n",
    "    \n",
    "#     werks_c = tf.feature_column.categorical_column_with_hash_bucket(\n",
    "#             key='WERKS',hash_bucket_size=3)\n",
    "#     scenario_c = tf.feature_column.categorical_column_with_hash_bucket(\n",
    "#             key='SCENARIO',hash_bucket_size=4)\n",
    "#     ktokk_c = tf.feature_column.categorical_column_with_hash_bucket(\n",
    "#             key='KTOKK',hash_bucket_size=2)\n",
    "#     vstatu_c = tf.feature_column.categorical_column_with_hash_bucket(\n",
    "#             key='VSTATU',hash_bucket_size=2)\n",
    "#     ekorg_c = tf.feature_column.categorical_column_with_hash_bucket(\n",
    "#             key='EKORG',hash_bucket_size=2)\n",
    "#     ekgrp_c = tf.feature_column.categorical_column_with_hash_bucket(\n",
    "#             key='EKGRP',hash_bucket_size=3)\n",
    "\n",
    "    return [\n",
    "        tf.feature_column.indicator_column(werks_c),\n",
    "        tf.feature_column.indicator_column(scenario_c),\n",
    "        tf.feature_column.indicator_column(ktokk_c),\n",
    "        tf.feature_column.indicator_column(vstatu_c),\n",
    "        tf.feature_column.indicator_column(ekorg_c),\n",
    "        tf.feature_column.indicator_column(ekgrp_c),\n",
    "        tf.feature_column.numeric_column('VPATD'),\n",
    "        tf.feature_column.numeric_column(\"TOTGRQTY\"),\n",
    "        tf.feature_column.numeric_column(\"TOTIRQTY\"),\n",
    "        tf.feature_column.numeric_column(\"NODLGR\"),\n",
    "        tf.feature_column.numeric_column(\"NODLIR\"),\n",
    "        tf.feature_column.numeric_column(\"DIFGRIRD\"),\n",
    "        tf.feature_column.numeric_column(\"grminusirbyvpatd\"),\n",
    "        tf.feature_column.numeric_column(\"difgrirdbytotgrqty\"),\n",
    "        tf.feature_column.numeric_column(\"DIFGRIRV\")\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['WERKS', 'SCENARIO', 'KTOKK', 'VSTATU', 'VPATD', 'EKORG', 'EKGRP',\n",
       "       'TOTGRQTY', 'TOTIRQTY', 'NODLGR', 'NODLIR', 'DIFGRIRD', 'DIFGRIRV',\n",
       "       'STATUS'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create input function to load data into datasets\n",
    "CSV_COLUMNS = traindf.columns  #['WERKS', 'SCENARIO', 'KTOKK', 'VSTATU', 'VPATD', 'EKORG', 'EKGRP',\n",
    "                               #'TOTGRQTY', 'TOTIRQTY', 'NODLGR', 'NODLIR', 'DIFGRIRD', 'DIFGRIRV',\n",
    "                               #'STATUS']\n",
    "LABEL_COLUMN = 'STATUS'\n",
    "DEFAULTS = [['ML01'],['3'], ['1'], ['1'], [30.0], ['1'], ['A'], [0.], [80.0], [0.], [90.0], [-80.0], [-38100.0], [1]]  #First row is passed\n",
    "\n",
    "def read_dataset(filename, mode, batch_size = 512):\n",
    "    def _input_fn(v_test=False):\n",
    "        def decode_csv(value_column):\n",
    "            columns = tf.decode_csv(value_column, record_defaults = DEFAULTS)\n",
    "            features = dict(zip(CSV_COLUMNS, columns))\n",
    "            label = features.pop(LABEL_COLUMN)\n",
    "            return add_engineered(features), label\n",
    "        \n",
    "        # Create list of files that match pattern\n",
    "        file_list = tf.gfile.Glob(filename)\n",
    "\n",
    "        # Create dataset from file list\n",
    "        dataset = tf.data.TextLineDataset(file_list).map(decode_csv)\n",
    "\n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            num_epochs = None # indefinitely\n",
    "            dataset = dataset.shuffle(buffer_size = 10 * batch_size)\n",
    "        else:\n",
    "            num_epochs = 1 # end-of-input after this\n",
    "\n",
    "        dataset = dataset.repeat(num_epochs).batch(batch_size)\n",
    "        batch_features, batch_labels = dataset.make_one_shot_iterator().get_next()\n",
    "        \n",
    "        #Begins - Uncomment for testing only -----------------------------------------------------<\n",
    "        if v_test == True:\n",
    "            with tf.Session() as sess:\n",
    "                print(sess.run(batch_features))\n",
    "        #End - Uncomment for testing only -----------------------------------------------------<\n",
    "        return batch_features, batch_labels\n",
    "    return _input_fn\n",
    "\n",
    "# Serving function for external call\n",
    "def serving_fn():\n",
    "    feature_placeholders  = {'WERKS' : tf.placeholder(tf.string, [None]),\n",
    "            'SCENARIO' : tf.placeholder(tf.string, [None]),\n",
    "            'KTOKK' : tf.placeholder(tf.string, [None]),\n",
    "            'VSTATU' : tf.placeholder(tf.string, [None]),\n",
    "            'EKORG' : tf.placeholder(tf.string, [None]),\n",
    "            'EKGRP' : tf.placeholder(tf.string, [None]),\n",
    "            'VPATD' : tf.placeholder(tf.float32, [None]),\n",
    "            'TOTGRQTY' : tf.placeholder(tf.float32, [None]),\n",
    "            'TOTIRQTY' : tf.placeholder(tf.float32, [None]),\n",
    "            'NODLGR' : tf.placeholder(tf.float32, [None]),\n",
    "            'NODLIR' : tf.placeholder(tf.float32, [None]),\n",
    "            'DIFGRIRD' : tf.placeholder(tf.float32, [None]),\n",
    "            'DIFGRIRV' : tf.placeholder(tf.float32, [None])\n",
    "    }\n",
    "\n",
    "    #Features with transformation logic\n",
    "    features = {\n",
    "                key: tf.expand_dims(tensor, -1)\n",
    "                for key, tensor in feature_placeholders.items()\n",
    "            }\n",
    "    \n",
    "    #feat_changed = add_engineered(features.copy())\n",
    "    return tf.estimator.export.ServingInputReceiver(add_engineered(features), feature_placeholders )\n",
    "#serving_fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TOTIRQTY': array([ 0.3005787 ,  0.23657636,  1.5326236 , -0.13143703, -0.38744637,\n",
      "       -0.46744928,  1.4686213 , -0.2594417 , -0.69145745, -0.49945045,\n",
      "        0.44458395,  1.5486242 ,  0.09257112,  0.81259733, -0.32344404,\n",
      "        0.84459853, -0.3394446 , -0.21143995,  0.90860087, -0.46744928,\n",
      "       -0.69145745,  1.516623  ,  1.3726177 ,  0.4925857 ,  0.02856879,\n",
      "       -0.09943587, -0.00343238, -0.595454  ,  0.8605991 ,  0.18857463,\n",
      "       -0.69145745,  0.14057288,  0.34858045,  0.17257404,  1.0046043 ,\n",
      "        0.6845927 ,  1.244613  ,  0.36458105,  1.0846072 ,  0.60458976,\n",
      "       -0.6274551 ,  1.3086154 , -0.32344404, -0.08343529, -0.24344112,\n",
      "       -0.09943587, -0.5634528 , -0.09943587, -0.3554452 ,  0.81259733,\n",
      "       -0.32344404,  0.81259733,  1.1806108 , -0.69145745,  1.4686213 ,\n",
      "        1.1646101 ,  1.3406166 ,  1.5646248 ,  0.06056996,  0.7645956 ,\n",
      "        1.4366201 ,  1.132609  ,  0.748595  ,  0.17257404,  1.4206195 ,\n",
      "        1.4206195 , -0.4514487 ,  1.0526061 ,  0.92460144,  0.46058452,\n",
      "       -0.19543937,  0.06056996,  0.90860087,  1.6286271 ,  0.47658512,\n",
      "        1.6126266 ,  0.95660263,  1.2926148 ,  1.404619  ,  1.4366201 ,\n",
      "        0.9726032 ,  0.73259443, -0.30744344, -0.38744637,  0.6845927 ,\n",
      "        0.22057578,  0.04456937,  1.2926148 ,  0.2845781 ,  1.5646248 ,\n",
      "        0.748595  , -0.06743471,  1.5326236 ,  0.4925857 , -0.32344404,\n",
      "       -0.24344112, -0.22744054,  0.9726032 ,  1.2286125 ,  0.6845927 ,\n",
      "        0.5885892 ,  1.020605  ,  1.1806108 ,  0.5725886 , -0.17943878,\n",
      "        0.84459853,  1.2926148 ,  0.6525915 ,  1.6446277 ,  1.3886184 ,\n",
      "       -0.5634528 ,  0.9726032 ,  0.9886038 ,  1.5326236 ,  1.5806253 ,\n",
      "       -0.13143703, -0.21143995,  1.2126119 , -0.32344404, -0.24344112,\n",
      "        0.63659096,  0.7005933 , -0.6274551 ,  1.516623  ,  1.6446277 ,\n",
      "       -0.40344694, -0.6274551 , -0.61145455, -0.09943587,  0.46058452,\n",
      "       -0.21143995,  0.5405874 ,  0.12457228, -0.05143413,  1.2126119 ,\n",
      "       -0.37144578,  1.1966114 ,  0.9726032 ,  0.14057288,  0.5885892 ,\n",
      "        0.2845781 ,  1.3886184 ,  1.5966259 ,  1.5646248 , -0.19543937,\n",
      "       -0.17943878, -0.03543354,  1.3886184 ,  0.14057288,  0.8605991 ,\n",
      "        1.2926148 , -0.4514487 ,  1.5646248 ,  1.2926148 ,  1.4846219 ,\n",
      "       -0.03543354, -0.6434557 ,  0.4925857 ,  0.6685921 , -0.65945625,\n",
      "        0.940602  ,  0.92460144, -0.2754423 ,  1.404619  ,  1.6606282 ,\n",
      "       -0.69145745,  1.5486242 ,  0.33257988,  0.10857171,  1.6446277 ,\n",
      "        0.82859796,  0.79659677,  0.81259733,  1.6286271 , -0.14743762,\n",
      "        0.5885892 , -0.21143995,  0.79659677,  1.4526206 ,  0.5725886 ,\n",
      "        0.73259443,  0.41258278, -0.707458  ,  0.44458395,  1.2286125 ,\n",
      "        0.95660263,  0.6845927 , -0.69145745,  0.02856879,  0.17257404,\n",
      "        1.4206195 ,  0.60458976,  0.42858335,  0.14057288,  0.8605991 ,\n",
      "       -0.61145455, -0.29144287,  0.25257695, -0.3554452 , -0.49945045,\n",
      "        0.5725886 ,  0.38058162,  0.92460144, -0.22744054,  1.3886184 ,\n",
      "        1.0686067 , -0.11543646,  0.8926003 ,  1.3406166 ,  0.3965822 ,\n",
      "       -0.61145455,  0.6845927 ,  0.90860087, -0.01943296,  0.47658512,\n",
      "        1.516623  , -0.03543354, -0.32344404,  0.71659386,  0.18857463,\n",
      "       -0.4354481 ,  0.60458976,  0.5885892 , -0.53145164, -0.707458  ,\n",
      "        0.6685921 ,  1.1806108 ,  1.404619  , -0.05143413,  0.47658512,\n",
      "       -0.69145745,  1.5326236 ,  0.8926003 ,  0.06056996, -0.6754569 ,\n",
      "       -0.09943587,  0.90860087, -0.53145164,  1.2766143 ,  0.02856879,\n",
      "        0.73259443, -0.08343529,  0.7005933 ,  0.6685921 , -0.37144578,\n",
      "        0.79659677, -0.24344112,  1.3086154 ,  1.132609  , -0.61145455,\n",
      "        0.34858045, -0.707458  , -0.515451  ,  0.7005933 ,  1.3886184 ,\n",
      "       -0.1634382 , -0.22744054,  0.79659677, -0.17943878,  0.5405874 ,\n",
      "       -0.2594417 , -0.22744054,  1.1166084 ,  0.90860087, -0.40344694,\n",
      "        0.6845927 ,  1.6926295 ,  0.5085863 ,  0.33257988,  1.0366055 ,\n",
      "        0.3965822 ,  1.3726177 ,  0.7805962 ,  1.132609  , -0.515451  ,\n",
      "        0.81259733,  1.0686067 , -0.29144287,  0.60458976,  0.5725886 ,\n",
      "        0.09257112, -0.38744637,  1.6606282 ,  1.516623  ,  0.01256821,\n",
      "        0.10857171, -0.24344112, -0.6274551 ,  1.6286271 ,  1.2126119 ,\n",
      "       -0.08343529,  1.020605  ,  0.07657054,  0.33257988,  1.4366201 ,\n",
      "       -0.03543354,  0.63659096,  1.3566172 , -0.6434557 ,  0.2045752 ,\n",
      "        0.41258278,  0.7805962 , -0.08343529,  0.90860087, -0.6434557 ,\n",
      "       -0.69145745,  1.3566172 ,  0.79659677,  1.0046043 ,  1.0046043 ,\n",
      "        0.36458105,  1.3726177 ,  0.04456937, -0.32344404,  0.81259733,\n",
      "        0.34858045,  0.81259733,  1.5486242 ,  0.3005787 ,  1.5806253 ,\n",
      "       -0.37144578,  1.244613  , -0.48344988,  1.5006224 ,  1.244613  ,\n",
      "       -0.11543646,  0.9726032 ,  0.6685921 , -0.41944754,  0.2045752 ,\n",
      "       -0.3554452 , -0.41944754, -0.707458  , -0.61145455,  1.2926148 ,\n",
      "       -0.69145745,  0.5085863 ,  1.244613  ,  0.84459853, -0.61145455,\n",
      "       -0.11543646, -0.05143413, -0.4354481 ,  1.516623  ,  1.6446277 ,\n",
      "        1.3406166 ,  0.01256821,  0.6685921 ,  0.8605991 ,  0.3005787 ,\n",
      "       -0.595454  ,  1.0366055 , -0.09943587, -0.00343238,  1.2286125 ,\n",
      "        1.3246161 ,  0.15657346, -0.53145164, -0.3554452 ,  0.92460144,\n",
      "        0.09257112, -0.57945335,  1.4206195 ,  0.87659967,  0.95660263,\n",
      "        1.3886184 ,  1.4846219 ,  0.46058452,  0.02856879,  0.95660263,\n",
      "       -0.32344404,  1.132609  , -0.32344404,  0.6205904 , -0.21143995,\n",
      "        1.4366201 , -0.6434557 ,  1.3566172 ,  1.6286271 ,  0.8926003 ,\n",
      "        1.4846219 ,  0.44458395,  1.020605  ,  0.25257695, -0.5634528 ,\n",
      "        0.14057288, -0.40344694, -0.6754569 ,  1.4526206 ,  0.41258278,\n",
      "       -0.13143703, -0.53145164,  0.6845927 ,  0.7805962 ,  0.31657928,\n",
      "        0.9726032 ,  0.748595  , -0.32344404,  1.4526206 ,  1.3886184 ,\n",
      "        0.2845781 ,  1.6446277 , -0.03543354, -0.515451  ,  0.940602  ,\n",
      "       -0.40344694,  1.0686067 ,  0.52458686,  1.4846219 ,  1.4526206 ,\n",
      "       -0.4354481 ,  0.55658805,  1.4846219 ,  0.23657636, -0.03543354,\n",
      "       -0.21143995,  0.2845781 ,  1.0046043 ,  0.6685921 ,  1.020605  ,\n",
      "        0.33257988,  0.31657928, -0.5634528 ,  0.7005933 ,  0.7645956 ,\n",
      "        0.17257404,  0.33257988,  0.04456937,  0.5085863 , -0.707458  ,\n",
      "       -0.2594417 ,  0.23657636,  1.1806108 ,  1.6766288 ,  1.516623  ,\n",
      "        0.5085863 , -0.515451  ,  1.0686067 ,  1.4526206 , -0.53145164,\n",
      "        1.4846219 ,  0.90860087, -0.41944754,  0.87659967, -0.00343238,\n",
      "        0.8926003 ,  0.15657346, -0.30744344, -0.4354481 ,  0.5885892 ,\n",
      "        0.12457228,  0.26857755,  0.15657346,  1.6926295 ,  1.0526061 ,\n",
      "        1.4366201 ,  0.940602  ,  0.71659386,  0.90860087,  1.5966259 ,\n",
      "       -0.4354481 ,  1.3246161 ,  1.1166084 , -0.37144578, -0.6274551 ,\n",
      "        0.92460144, -0.37144578,  1.6606282 ,  0.46058452,  0.7645956 ,\n",
      "        1.2286125 ,  1.5006224 ,  0.52458686,  0.90860087,  0.79659677,\n",
      "        0.23657636,  0.3005787 ,  1.5326236 , -0.37144578, -0.19543937,\n",
      "        1.4206195 ,  0.44458395, -0.3554452 , -0.17943878, -0.37144578,\n",
      "        1.1166084 ,  0.9886038 , -0.5474522 , -0.6434557 ,  1.0046043 ,\n",
      "        0.71659386,  1.2926148 ,  1.3086154 ,  0.79659677, -0.40344694,\n",
      "        0.81259733,  1.4366201 ,  0.87659967, -0.14743762,  0.7645956 ,\n",
      "       -0.05143413, -0.4514487 ,  0.87659967,  0.6685921 , -0.5634528 ,\n",
      "       -0.29144287,  0.47658512, -0.595454  , -0.3554452 ,  0.71659386,\n",
      "       -0.11543646,  1.6606282 ], dtype=float32), 'TOTGRQTY': array([-1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "       -1.0457349e+00, -1.0457349e+00, -1.0457349e+00, -1.0457349e+00,\n",
      "        7.3166490e-01, -2.9986179e-01,  1.6614015e-03,  6.2057739e-01,\n",
      "        1.3823202e+00,  1.8266702e+00,  1.5410166e+00,  9.3797022e-01,\n",
      "       -7.7686802e-02,  1.1760149e+00,  1.6521040e+00, -1.4116538e-01,\n",
      "        1.4775380e+00,  1.1601452e+00, -1.2529573e-01,  1.0649273e+00,\n",
      "        3.9840242e-01,  1.2712327e+00,  5.7296848e-01,  1.1274889e-01,\n",
      "        1.6614015e-03,  7.1579528e-01,  3.8253278e-01,  4.9362028e-01,\n",
      "        4.4601136e-01,  2.0329754e+00,  1.4616684e+00,  1.7314522e+00,\n",
      "        1.0649273e+00,  1.1442755e+00,  1.2712327e+00,  1.6362344e+00,\n",
      "        1.6614015e-03,  1.5410166e+00,  1.3823202e+00,  4.9270324e-02,\n",
      "       -2.9986179e-01,  1.0331881e+00,  3.3400685e-02,  1.8108004e+00,\n",
      "        8.2688272e-01,  1.0331881e+00,  1.4299291e+00,  1.6044952e+00,\n",
      "        6.8405598e-01,  1.2236238e+00,  1.1918845e+00,  4.9362028e-01,\n",
      "        5.7296848e-01,  1.9060184e+00,  1.6614015e-03,  2.0796673e-01,\n",
      "        1.6521040e+00,  8.1101310e-01,  4.9270324e-02,  1.6035782e-01,\n",
      "        6.5139964e-02,  1.3981898e+00,  1.0649273e+00, -2.0464393e-01,\n",
      "       -2.8399214e-01,  1.1442755e+00,  1.0490577e+00,  1.4299291e+00,\n",
      "        1.5727558e+00,  1.0173185e+00,  1.6614015e-03,  9.0623093e-01,\n",
      "        1.7314522e+00,  1.1601452e+00,  9.6879251e-02,  1.0966667e+00,\n",
      "        3.8253278e-01, -1.2529573e-01,  1.2236238e+00,  7.9514349e-01,\n",
      "       -2.3638321e-01,  1.7531043e-02,  7.4753451e-01, -2.2051357e-01,\n",
      "        1.6614015e-03,  1.0331881e+00,  1.7622745e-01,  1.6203648e+00],\n",
      "      dtype=float32), 'VSTATU': array([b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1'], dtype=object), 'DIFGRIRD': array([-1.3370154 , -1.2738599 , -2.55276   , -0.9107155 , -0.65809333,\n",
      "       -0.5791489 , -2.4896042 , -0.7844044 , -0.3581045 , -0.5475711 ,\n",
      "       -1.4791154 , -2.5685487 , -1.1317599 , -1.8422598 , -0.72124887,\n",
      "       -1.8738376 , -0.70545995, -0.8317711 , -1.9369931 , -0.5791489 ,\n",
      "       -0.3581045 , -2.5369709 , -2.394871  , -1.5264821 , -1.0686044 ,\n",
      "       -0.9422933 , -1.0370265 , -0.45283782, -1.8896264 , -1.2264932 ,\n",
      "       -0.3581045 , -1.1791265 , -1.3843821 , -1.2107043 , -2.0317266 ,\n",
      "       -1.7159487 , -2.26856   , -1.4001709 , -2.110671  , -1.6370043 ,\n",
      "       -0.42126006, -2.3317153 , -0.72124887, -0.95808214, -0.8001933 ,\n",
      "       -0.9422933 , -0.4844156 , -0.9422933 , -0.6896711 , -1.8422598 ,\n",
      "       -0.72124887, -1.8422598 , -2.2054043 , -0.3581045 , -2.4896042 ,\n",
      "       -2.1896155 , -2.3632932 , -2.5843375 , -1.1001822 , -1.7948931 ,\n",
      "       -2.4580264 , -2.1580377 , -1.7791042 , -1.2107043 , -2.4422376 ,\n",
      "       -2.4422376 , -0.59493774, -2.0790932 , -1.952782  , -1.4949043 ,\n",
      "       -0.8475599 , -1.1001822 , -1.9369931 , -2.6474931 , -1.5106932 ,\n",
      "       -2.6317043 , -1.9843597 , -2.3159266 , -2.4264486 , -2.4580264 ,\n",
      "       -2.0001485 , -1.7633153 , -0.7370377 , -0.65809333, -1.7159487 ,\n",
      "       -1.258071  , -1.0843933 , -2.3159266 , -1.3212265 , -2.5843375 ,\n",
      "       -1.7791042 , -0.97387105, -2.55276   , -1.5264821 , -0.72124887,\n",
      "       -0.8001933 , -0.81598216, -2.0001485 , -2.252771  , -1.7159487 ,\n",
      "       -1.6212153 , -2.0475154 , -2.2054043 , -1.6054264 , -0.86334884,\n",
      "       -1.8738376 , -2.3159266 , -1.6843709 , -2.663282  , -2.4106598 ,\n",
      "       -0.4844156 , -2.0001485 , -2.0159376 , -2.55276   , -2.6001265 ,\n",
      "       -0.9107155 , -0.8317711 , -2.236982  , -0.72124887, -0.8001933 ,\n",
      "       -1.6685821 , -1.7317376 , -0.42126006, -2.5369709 , -2.663282  ,\n",
      "       -0.6423044 , -0.42126006, -0.43704894, -0.9422933 , -1.4949043 ,\n",
      "       -0.8317711 , -1.5738487 , -1.1633377 , -0.9896599 , -2.236982  ,\n",
      "       -0.6738822 , -2.221193  , -2.0001485 , -1.1791265 , -1.6212153 ,\n",
      "       -1.3212265 , -2.4106598 , -2.6159153 , -2.5843375 , -0.8475599 ,\n",
      "       -0.86334884, -1.0054488 , -2.4106598 , -1.1791265 , -1.8896264 ,\n",
      "       -2.3159266 , -0.59493774, -2.5843375 , -2.3159266 , -2.505393  ,\n",
      "       -1.0054488 , -0.40547118, -1.5264821 , -1.7001598 , -0.38968226,\n",
      "       -1.9685708 , -1.952782  , -0.76861554, -2.4264486 , -2.679071  ,\n",
      "       -0.3581045 , -2.5685487 , -1.3685932 , -1.1475488 , -2.663282  ,\n",
      "       -1.8580487 , -1.8264709 , -1.8422598 , -2.6474931 , -0.8949266 ,\n",
      "       -1.6212153 , -0.8317711 , -1.8264709 , -2.4738154 , -1.6054264 ,\n",
      "       -1.7633153 , -1.4475377 , -0.3423156 , -1.4791154 , -2.252771  ,\n",
      "       -1.9843597 , -1.7159487 , -0.3581045 , -1.0686044 , -1.2107043 ,\n",
      "       -2.4422376 , -1.6370043 , -1.4633265 , -1.1791265 , -1.8896264 ,\n",
      "       -0.43704894, -0.75282663, -1.2896488 , -0.6896711 , -0.5475711 ,\n",
      "       -1.6054264 , -1.4159598 , -1.952782  , -0.81598216, -2.4106598 ,\n",
      "       -2.094882  , -0.9265044 , -1.9212042 , -2.3632932 , -1.4317487 ,\n",
      "       -0.43704894, -1.7159487 , -1.9369931 , -1.0212377 , -1.5106932 ,\n",
      "       -2.5369709 , -1.0054488 , -0.72124887, -1.7475264 , -1.2264932 ,\n",
      "       -0.61072665, -1.6370043 , -1.6212153 , -0.51599336, -0.3423156 ,\n",
      "       -1.7001598 , -2.2054043 , -2.4264486 , -0.9896599 , -1.5106932 ,\n",
      "       -0.3581045 , -2.55276   , -1.9212042 , -1.1001822 , -0.37389338,\n",
      "       -0.9422933 , -1.9369931 , -0.51599336, -2.3001375 , -1.0686044 ,\n",
      "       -1.7633153 , -0.95808214, -1.7317376 , -1.7001598 , -0.6738822 ,\n",
      "       -1.8264709 , -0.8001933 , -2.3317153 , -2.1580377 , -0.43704894,\n",
      "       -1.3843821 , -0.3423156 , -0.5317822 , -1.7317376 , -2.4106598 ,\n",
      "       -0.8791377 , -0.81598216, -1.8264709 , -0.86334884, -1.5738487 ,\n",
      "       -0.7844044 , -0.81598216, -2.1422486 , -1.9369931 , -0.6423044 ,\n",
      "       -1.7159487 , -2.7106485 , -1.5422709 , -1.3685932 , -2.0633044 ,\n",
      "       -1.4317487 , -2.394871  , -1.810682  , -2.1580377 , -0.5317822 ,\n",
      "       -1.8422598 , -2.094882  , -0.75282663, -1.6370043 , -1.6054264 ,\n",
      "       -1.1317599 , -0.65809333, -2.679071  , -2.5369709 , -1.0528154 ,\n",
      "       -1.1475488 , -0.8001933 , -0.42126006, -2.6474931 , -2.236982  ,\n",
      "       -0.95808214, -2.0475154 , -1.115971  , -1.3685932 , -2.4580264 ,\n",
      "       -1.0054488 , -1.6685821 , -2.379082  , -0.40547118, -1.2422822 ,\n",
      "       -1.4475377 , -1.810682  , -0.95808214, -1.9369931 , -0.40547118,\n",
      "       -0.3581045 , -2.379082  , -1.8264709 , -2.0317266 , -2.0317266 ,\n",
      "       -1.4001709 , -2.394871  , -1.0843933 , -0.72124887, -1.8422598 ,\n",
      "       -1.3843821 , -1.8422598 , -2.5685487 , -1.3370154 , -2.6001265 ,\n",
      "       -0.6738822 , -2.26856   , -0.56336   , -2.521182  , -2.26856   ,\n",
      "       -0.9265044 , -2.0001485 , -1.7001598 , -0.62651557, -1.2422822 ,\n",
      "       -0.6896711 , -0.62651557, -0.3423156 , -0.43704894, -2.3159266 ,\n",
      "       -0.3581045 , -1.5422709 , -2.26856   , -1.8738376 , -0.43704894,\n",
      "       -0.9265044 , -0.9896599 , -0.61072665, -2.5369709 , -2.663282  ,\n",
      "       -2.3632932 , -1.0528154 , -1.7001598 , -1.8896264 , -1.3370154 ,\n",
      "       -0.45283782, -2.0633044 , -0.9422933 , -1.0370265 , -2.252771  ,\n",
      "       -2.3475044 , -1.1949154 , -0.51599336, -0.6896711 , -1.952782  ,\n",
      "       -1.1317599 , -0.4686267 , -2.4422376 , -1.9054153 , -1.9843597 ,\n",
      "       -2.4106598 , -2.505393  , -1.4949043 , -1.0686044 , -1.9843597 ,\n",
      "       -0.72124887, -2.1580377 , -0.72124887, -1.6527932 , -0.8317711 ,\n",
      "       -2.4580264 , -0.40547118, -2.379082  , -2.6474931 , -1.9212042 ,\n",
      "       -2.505393  , -1.4791154 , -2.0475154 , -1.2896488 , -0.4844156 ,\n",
      "       -1.1791265 , -0.6423044 , -0.37389338, -2.4738154 , -1.4475377 ,\n",
      "       -0.9107155 , -0.51599336, -1.7159487 , -1.810682  , -1.3528043 ,\n",
      "       -2.0001485 , -1.7791042 , -0.72124887, -2.4738154 , -2.4106598 ,\n",
      "       -1.3212265 , -2.663282  , -1.0054488 , -0.5317822 , -1.9685708 ,\n",
      "       -0.6423044 , -2.094882  , -1.5580598 , -2.505393  , -2.4738154 ,\n",
      "       -0.61072665, -1.5896376 , -2.505393  , -1.2738599 , -1.0054488 ,\n",
      "       -0.8317711 , -1.3212265 , -2.0317266 , -1.7001598 , -2.0475154 ,\n",
      "       -1.3685932 , -1.3528043 , -0.4844156 , -1.7317376 , -1.7948931 ,\n",
      "       -1.2107043 , -1.3685932 , -1.0843933 ,  0.22608429,  0.39976203,\n",
      "        0.25766206,  0.38397315,  0.21029541,  0.16292875,  0.03661766,\n",
      "        0.4313398 ,  0.4313398 ,  0.11556208,  0.21029541,  0.38397315,\n",
      "        0.00503988,  0.25766206,  0.28923982,  0.19450651,  0.39976203,\n",
      "        0.38397315,  0.41555092,  0.41555092,  0.4313398 ,  0.13135096,\n",
      "        0.25766206,  0.22608429,  0.28923982,  0.3523954 ,  0.41555092,\n",
      "        0.3050287 ,  0.13135096,  0.4313398 ,  0.36818427,  0.05240654,\n",
      "        0.4313398 ,  0.22608429,  0.27345094,  0.41555092,  0.32081762,\n",
      "        0.11556208,  0.39976203,  0.16292875,  0.36818427,  0.27345094,\n",
      "        0.21029541,  0.11556208,  0.16292875,  0.32081762,  0.39976203,\n",
      "        0.25766206,  0.27345094,  0.38397315,  0.36818427,  0.39976203,\n",
      "        0.24187317,  0.36818427,  0.39976203,  0.3366065 ,  0.4313398 ,\n",
      "        0.28923982,  0.08398432,  0.3366065 ,  0.3523954 ,  0.14713986,\n",
      "        0.3366065 ,  0.14713986,  0.27345094,  0.22608429,  0.39976203,\n",
      "        0.0997732 ,  0.3050287 ,  0.28923982,  0.24187317,  0.3366065 ,\n",
      "        0.4313398 ,  0.32081762,  0.3523954 ,  0.13135096,  0.32081762,\n",
      "        0.3050287 ,  0.27345094,  0.36818427,  0.3523954 ,  0.32081762,\n",
      "        0.28923982, -0.02653789], dtype=float32), 'NODLIR': array([-1.1401857 ,  0.34005406,  0.8468028 ,  0.6334349 ,  0.18002814,\n",
      "        0.08667969, -1.0068307 , -0.22003666, -0.8868113 ,  1.4068935 ,\n",
      "       -0.64677244, -0.08668172,  1.366887  , -0.7667919 ,  0.6867769 ,\n",
      "       -1.0068307 ,  0.5800929 ,  0.10001518, -0.7667919 ,  0.90014476,\n",
      "        1.1135126 ,  0.40673152, -1.0735081 ,  1.5802549 ,  0.92681575,\n",
      "        0.92681575,  0.40673152, -0.500082  , -0.16669469,  0.31338307,\n",
      "        1.420229  ,  0.526751  ,  0.19336364,  1.5802549 ,  1.0068287 ,\n",
      "       -0.98015976, -0.9001468 , -1.1268501 ,  0.31338307, -0.3400561 ,\n",
      "        1.2068611 ,  0.8468028 ,  0.6334349 , -0.46007553, -0.2733786 ,\n",
      "       -0.38006258,  1.1001772 ,  0.39339602,  1.2201966 ,  1.5535839 ,\n",
      "        0.04667321, -0.6067659 ,  0.36672503,  0.7801253 ,  1.0334997 ,\n",
      "        1.286874  ,  0.8201318 , -1.1135147 , -1.1801921 , -0.56675947,\n",
      "        0.10001518,  0.6200994 ,  0.6067639 ,  0.4600735 ,  0.56675744,\n",
      "       -0.11335271, -0.07334623, -0.78012735, -0.58009493, -1.0601727 ,\n",
      "       -0.26004314,  0.4334025 , -1.0068307 , -0.62010145, -0.44674003,\n",
      "       -0.3533916 , -0.7934629 ,  0.18002814, -0.2867141 , -0.67344344,\n",
      "       -0.6334369 , -0.9268178 ,  1.393558  , -0.48674652,  1.1801901 ,\n",
      "       -0.80679834, -0.7401209 ,  1.4469    , -0.03333975,  1.420229  ,\n",
      "       -0.6601079 ,  0.02000222,  1.1668546 ,  0.0600087 , -0.24670763,\n",
      "        1.5135775 , -0.70011437,  1.1401837 , -0.70011437,  0.0600087 ,\n",
      "        0.5800929 ,  1.2602031 , -0.9401533 ,  0.30004758,  0.4600735 ,\n",
      "        1.5935904 , -1.0735081 ,  1.340216  , -0.2733786 ,  1.4869064 ,\n",
      "        0.8334673 , -1.1268501 , -1.1401857 ,  0.35338956,  0.9134802 ,\n",
      "       -1.1668566 ,  1.0868417 , -0.42006904,  0.2467056 ,  1.4335644 ,\n",
      "       -0.8468048 ,  0.22003461,  1.1001772 , -0.43340454, -0.80679834,\n",
      "       -0.19336566, -0.16669469,  0.8201318 , -0.59343046,  0.4600735 ,\n",
      "        1.1401837 , -0.83346933,  0.04667321,  1.3002095 , -0.18003017,\n",
      "       -0.7134499 , -0.2733786 ,  0.92681575,  1.5802549 ,  1.366887  ,\n",
      "       -1.1801921 ,  0.446738  ,  0.6467704 , -0.70011437, -0.07334623,\n",
      "       -0.70011437, -0.16669469,  0.6601059 ,  1.0334997 , -0.7401209 ,\n",
      "       -0.1266882 , -0.9001468 ,  0.35338956,  0.98015773, -0.9134823 ,\n",
      "        0.30004758, -0.1266882 ,  1.0201643 , -1.1535212 ,  0.8868093 ,\n",
      "        0.8468028 ,  0.92681575,  0.51341546,  0.34005406, -0.46007553,\n",
      "        0.16669264,  0.20669912, -0.7667919 , -0.8601403 ,  0.526751  ,\n",
      "        0.28671208, -0.08668172, -0.07334623,  0.51341546, -0.6867789 ,\n",
      "        0.2467056 ,  0.90014476,  0.38006052,  0.7934608 , -0.62010145,\n",
      "        0.59342843,  0.6467704 , -0.9934952 , -0.43340454,  0.9668222 ,\n",
      "        0.22003461,  0.56675744,  0.51341546, -0.8868113 , -0.40673354,\n",
      "       -1.1535212 ,  1.2468675 ,  0.08667969, -0.9268178 ,  0.50008   ,\n",
      "       -0.526753  , -0.9401533 ,  1.1935256 ,  1.4602355 ,  0.71344787,\n",
      "       -0.553424  ,  1.4869064 ,  0.12668617,  0.18002814, -0.82013386,\n",
      "        0.16669264, -0.44674003,  1.5669194 , -1.1668566 ,  1.6202614 ,\n",
      "       -0.6334369 ,  1.1801901 , -0.8468048 , -1.1668566 , -0.82013386,\n",
      "        0.54008645, -0.1266882 ,  0.6867769 , -0.7934629 ,  0.02000222,\n",
      "        1.2335321 ,  0.92681575, -0.3267206 , -0.7134499 ,  1.3802226 ,\n",
      "       -0.26004314, -0.5134175 , -0.7134499 ,  0.20669912,  1.5402484 ,\n",
      "        0.07334419, -0.95348877,  0.08667969,  0.8201318 ,  1.0601707 ,\n",
      "        0.8468028 ,  1.0068287 ,  1.5402484 , -0.04667524,  0.8067963 ,\n",
      "       -0.7401209 , -0.1400237 , -0.08668172, -1.1135147 , -0.5134175 ,\n",
      "       -0.75345635, -0.78012735,  0.16669264, -0.07334623, -0.95348877,\n",
      "        1.0334997 , -0.3133851 ,  1.2735386 ,  0.15335715,  0.8868093 ,\n",
      "        1.420229  , -0.23337215, -0.04667524, -0.8468048 , -0.8601403 ,\n",
      "        1.0201643 , -0.500082  ,  0.6867769 , -0.64677244, -0.7401209 ,\n",
      "        0.11335067,  0.23337011,  1.500242  ,  0.8468028 ,  0.95348674,\n",
      "        1.4602355 ,  0.03333772,  0.18002814,  0.54008645, -0.44674003,\n",
      "        0.23337011, -0.2867141 ,  0.07334419,  0.0600087 , -0.82013386,\n",
      "        0.2467056 ,  0.08667969, -0.9001468 , -0.70011437, -0.07334623,\n",
      "        0.446738  , -0.95348877, -0.3267206 ,  0.27337658, -0.24670763,\n",
      "        0.00666673, -0.96682423, -0.22003666,  0.9668222 , -0.96682423,\n",
      "        0.446738  , -1.0735081 , -0.03333975, -0.36672708, -0.43340454,\n",
      "        1.393558  ,  1.5669194 ,  1.2068611 ,  1.340216  ,  0.4334025 ,\n",
      "        0.56675744,  0.23337011, -0.7934629 ,  1.500242  ,  0.71344787,\n",
      "        1.340216  ,  1.0068287 ,  1.2068611 , -0.95348877,  0.40673152,\n",
      "        0.08667969,  1.5402484 , -0.40673354, -0.6067659 ,  1.0601707 ,\n",
      "       -0.6067659 ,  1.5402484 ,  1.2068611 , -1.1801921 ,  0.8601383 ,\n",
      "        1.473571  ,  0.95348674,  0.8468028 ,  0.54008645, -0.3533916 ,\n",
      "        0.02000222,  1.1401837 ,  1.4602355 , -0.8468048 ,  1.1535192 ,\n",
      "       -0.500082  , -0.8468048 , -0.08668172,  0.9934932 ,  0.4334025 ,\n",
      "       -0.62010145,  1.4602355 , -0.7667919 , -0.36672708,  1.1135126 ,\n",
      "        0.92681575, -0.46007553, -0.64677244,  1.366887  ,  1.0601707 ,\n",
      "       -0.8734758 , -0.43340454, -0.36672708,  1.3802226 ,  1.1268481 ,\n",
      "        0.22003461,  0.22003461, -0.8468048 ,  1.4335644 , -0.7134499 ,\n",
      "       -0.2867141 ,  0.7534543 ,  1.2068611 ,  1.6202614 ,  0.40673152,\n",
      "        1.420229  ,  0.8601383 ,  0.8067963 ,  0.20669912,  0.03333772,\n",
      "       -0.83346933, -0.80679834,  0.6867769 ,  0.08667969,  0.34005406,\n",
      "       -0.98015976,  0.27337658,  1.5935904 , -0.83346933, -0.1266882 ,\n",
      "        0.95348674, -0.2733786 ,  1.6202614 , -1.0601727 ,  0.76678985,\n",
      "        0.9934932 ,  1.5402484 , -0.72678536,  0.23337011, -0.26004314,\n",
      "        1.1935256 ,  0.20669912, -1.1401857 ,  1.0735061 ,  1.6069258 ,\n",
      "        0.446738  , -1.1001792 , -0.8468048 , -0.95348877,  0.19336364,\n",
      "        1.1935256 , -0.18003017,  0.2467056 ,  0.20669912, -0.553424  ,\n",
      "        1.0601707 ,  1.0601707 , -0.59343046, -0.42006904, -0.15335919,\n",
      "        0.27337658,  1.4335644 ,  1.1001772 ,  1.0735061 , -0.42006904,\n",
      "       -0.48674652,  0.18002814, -0.02000426,  0.18002814,  0.71344787,\n",
      "       -0.7934629 , -0.3400561 ,  0.67344135,  0.48674446,  1.0868417 ,\n",
      "        0.35338956, -0.40673354,  0.420067  , -0.2733786 , -0.59343046,\n",
      "        1.6736033 ,  0.36672503,  0.59342843, -0.47341102,  0.92681575,\n",
      "        1.313545  ,  1.0201643 , -0.26004314,  0.10001518,  1.313545  ,\n",
      "       -0.6867789 , -0.10001721,  0.5534219 , -0.22003666, -0.3133851 ,\n",
      "       -0.500082  ,  1.4869064 ,  1.7136098 , -0.26004314,  0.40673152,\n",
      "        0.76678985,  0.8067963 ,  0.03333772,  0.14002165, -0.18003017,\n",
      "       -0.38006258,  0.8067963 , -0.1266882 , -0.8734758 ,  0.40673152,\n",
      "       -1.1401857 , -0.62010145, -0.70011437,  1.8469647 , -1.0868437 ,\n",
      "       -0.500082  ,  1.3268806 , -0.9401533 ,  1.1001772 ,  0.473409  ,\n",
      "        2.0336616 , -0.67344344, -0.9134823 ,  1.3535515 , -0.2733786 ,\n",
      "        0.38006052,  1.4335644 ,  1.340216  ,  0.11335067, -1.0468372 ,\n",
      "       -0.11335271,  1.5802549 ,  1.0601707 , -0.7134499 , -0.526753  ,\n",
      "        0.39339602,  1.8202938 ,  0.8468028 ,  1.8069583 , -0.15335919,\n",
      "        1.2335321 ,  0.8601383 , -0.72678536, -1.0468372 , -0.95348877,\n",
      "        0.16669264, -0.04667524, -0.56675947,  0.71344787,  0.8868093 ,\n",
      "        1.7936227 ,  0.15335715,  0.2600411 ,  0.02000222,  0.40673152,\n",
      "        1.5535839 , -1.1401857 ,  0.74011886,  0.7534543 ,  1.1401837 ,\n",
      "        1.5135775 , -0.64677244], dtype=float32), 'DIFGRIRV': array([-2.48733544e+00, -2.13124418e+00, -2.83463430e+00, -6.14558995e-01,\n",
      "       -1.23881781e+00, -8.07991326e-01, -3.48880934e-03, -2.52250481e+00,\n",
      "       -1.50698531e+00, -2.49675378e-01, -2.21916795e+00, -4.65088606e-01,\n",
      "       -2.65439057e+00, -1.26079869e+00,  2.42697760e-01, -5.00258088e-01,\n",
      "       -2.09607458e+00, -4.65088606e-01, -1.24321401e+00, -2.09607458e+00,\n",
      "       -1.63447475e+00, -1.06736648e+00, -1.94220793e+00, -1.33113778e+00,\n",
      "       -2.10486698e+00, -1.67843664e+00, -9.14125815e-02, -1.60809767e+00,\n",
      "        2.11924434e-01, -5.79389513e-01, -1.39708054e+00, -2.32467628e+00,\n",
      "       -2.27694437e-01, -1.69602144e+00, -2.28950691e+00, -2.89178467e+00,\n",
      "       -2.98410463e+00, -2.96651983e+00, -1.91143465e+00, -1.85868037e+00,\n",
      "       -4.82673347e-01, -1.88505757e+00, -1.05857408e+00, -1.80592608e+00,\n",
      "       -9.31084573e-01, -2.71656305e-01, -9.44273174e-01, -1.81032228e+00,\n",
      "       -2.80825710e+00, -2.45656204e+00, -2.00375462e+00, -2.03892422e+00,\n",
      "       -2.46535444e+00, -1.59930527e+00, -2.47854304e+00, -7.28859901e-01,\n",
      "       -5.00258088e-01, -1.41026914e+00, -1.21683681e+00, -2.58405161e+00,\n",
      "       -2.14003658e+00, -1.22185901e-01, -2.61922097e+00, -1.85868037e+00,\n",
      "       -1.08934736e+00, -9.13499832e-01, -2.54448581e+00, -5.66200912e-01,\n",
      "       -2.60163617e+00, -2.98410463e+00, -3.42621282e-02,  2.42697760e-01,\n",
      "       -4.95861918e-01, -2.13124418e+00, -3.68372440e-01, -5.62430732e-02,\n",
      "       -1.66964424e+00, -1.32234538e+00, -2.97970843e+00, -4.38711464e-01,\n",
      "       -4.51900035e-01, -1.10693216e+00, -6.71709478e-01, -6.76105678e-01,\n",
      "       -5.57408571e-01, -1.82351089e+00, -1.26582086e-01, -1.18606353e+00,\n",
      "       -6.62917078e-01, -3.28806758e-01, -2.17520595e+00, -1.10693216e+00,\n",
      "       -1.29596829e+00, -4.78277147e-01, -1.35751486e+00, -5.44219971e-01,\n",
      "       -2.60163617e+00, -5.83785713e-01, -9.75046456e-01, -1.02780080e+00,\n",
      "       -2.04771662e+00, -5.22239029e-01,  9.76235271e-02, -3.99145752e-01,\n",
      "       -2.90936947e+00, -1.48563027e-01, -1.91583085e+00,  2.72845104e-02,\n",
      "       -1.66147783e-01, -1.79713380e+00, -8.25576067e-01, -6.80501819e-01,\n",
      "       -1.37070346e+00, -1.67404044e+00, -2.52690101e+00, -1.93781173e+00,\n",
      "       -7.24463701e-01, -2.01254702e+00, -2.85221910e+00, -1.07615876e+00,\n",
      "       -2.80825710e+00,  4.48692665e-02, -1.22185901e-01,  2.51490146e-01,\n",
      "       -9.92631257e-01, -2.42578864e+00,  2.20716804e-01, -2.18902051e-01,\n",
      "        4.48692665e-02,  2.07528248e-01, -7.37652302e-01, -2.89618087e+00,\n",
      "       -6.23351395e-01, -1.99935842e+00, -1.93781173e+00, -1.74437952e+00,\n",
      "       -2.21916795e+00, -1.93781173e+00, -6.06392622e-02, -2.65439057e+00,\n",
      "       -1.30476058e+00,  1.32793039e-01, -2.34665728e+00, -2.96651983e+00,\n",
      "       -2.29829931e+00, -2.32028031e+00, -1.32674158e+00, -1.12451684e+00,\n",
      "       -1.37070346e+00, -1.02780080e+00, -2.14505866e-01, -2.57525921e+00,\n",
      "       -2.13124418e+00, -2.02573562e+00, -1.14210165e+00, -5.13446689e-01,\n",
      "       -1.48940051e+00, -1.33553398e+00, -1.88945377e+00, -2.48733544e+00,\n",
      "       -2.88738847e+00, -2.27192211e+00, -1.01021600e+00, -5.88181853e-01,\n",
      "       -9.00311291e-01, -9.31084573e-01, -1.14649785e+00, -2.21037555e+00,\n",
      "       -1.14210165e+00,  8.88311490e-02, -2.73352194e+00, -2.65439057e+00,\n",
      "        2.47093946e-01, -1.18606353e+00, -3.48880934e-03, -1.23881781e+00,\n",
      "       -1.24321401e+00, -4.51900035e-01, -6.80501819e-01, -5.57408571e-01,\n",
      "       -1.31355298e+00, -1.37949586e+00, -1.26959109e+00, -4.56296206e-01,\n",
      "       -1.78394520e+00, -6.36539936e-01, -1.26519489e+00, -1.99935842e+00,\n",
      "       -2.77748370e+00, -4.82673347e-01, -2.02573562e+00, -1.14210165e+00,\n",
      "       -7.06878960e-01,  1.40959453e-02, -7.24463701e-01, -2.42578864e+00,\n",
      "       -1.72679472e+00, -5.62430732e-02, -5.48616171e-01, -2.12684798e+00,\n",
      "       -1.66147783e-01, -6.80501819e-01, -1.08495116e+00,  5.36616445e-02,\n",
      "       -2.73791814e+00, -2.30269551e+00, -1.79336354e-01, -2.66318297e+00,\n",
      "       -2.75110674e+00, -2.17960215e+00, -2.52250481e+00, -1.30915678e+00,\n",
      "       -5.48616171e-01, -1.36630726e+00, -2.62801337e+00, -6.10162795e-01,\n",
      "       -8.82726490e-01, -2.50492024e+00, -1.29157209e+00,  2.16320619e-01,\n",
      "        2.03132063e-01, -1.53336239e+00,  1.02019720e-01, -1.77515280e+00,\n",
      "       -2.99289703e+00, -1.38828826e+00, -1.88505757e+00, -4.65088606e-01,\n",
      "       -2.00375462e+00, -1.23002541e+00, -9.31084573e-01, -2.36424208e+00,\n",
      "       -1.45423102e+00, -2.70274854e+00,  1.45981610e-01, -1.19925213e+00,\n",
      "       -1.21683681e+00, -1.28717589e+00, -1.94660413e+00, -1.98177373e+00,\n",
      "       -1.50698531e+00, -1.11572456e+00, -2.77748370e+00, -1.06736648e+00,\n",
      "       -1.25200641e+00, -1.79336354e-01, -1.55534339e+00, -1.96858513e+00,\n",
      "       -5.88181853e-01,  1.76754922e-01, -1.76196420e+00, -2.77308774e+00,\n",
      "       -1.39708054e+00, -1.62568235e+00, -1.08495116e+00, -2.54697520e-02,\n",
      "       -1.86747277e+00,  9.32273418e-02, -8.25576067e-01, -4.56296206e-01,\n",
      "       -1.09374356e+00, -1.12891304e+00, -2.54071563e-01, -2.80825710e+00,\n",
      "       -2.40820408e+00,  1.67962551e-01, -2.52250481e+00, -3.48880934e-03,\n",
      "       -1.86307657e+00, -3.00168943e+00, -2.27631831e+00, -2.74671054e+00,\n",
      "        2.72845104e-02, -2.76052505e-01, -1.26079869e+00, -2.89241076e-01,\n",
      "       -5.26635230e-01, -1.00142360e+00, -7.38278255e-02, -2.02133942e+00,\n",
      "       -2.41699624e+00, -2.41260028e+00, -1.68722904e+00, -3.42621282e-02,\n",
      "       -1.10253596e+00, -2.52250481e+00,  2.33905375e-01, -2.17080975e+00,\n",
      "       -6.49728537e-01, -4.74506952e-02, -1.85868037e+00, -7.33256102e-01,\n",
      "       -1.17727113e+00, -2.35984588e+00, -1.81471848e+00, -2.54071563e-01,\n",
      "       -2.28511071e+00, -2.73352194e+00,  1.89943492e-01,  1.67962551e-01,\n",
      "       -1.07615876e+00, -1.61751598e-01, -2.28511071e+00, -2.44337344e+00,\n",
      "       -3.86583172e-02, -2.40820408e+00, -8.34368467e-01, -1.69602144e+00,\n",
      "       -2.14003658e+00, -2.37743068e+00, -1.19045973e+00, -2.85661530e+00,\n",
      "       -9.09103632e-01, -1.03219688e+00, -1.76636040e+00, -9.88235056e-01,\n",
      "       -2.80448705e-01, -2.17080975e+00, -9.61857915e-01, -2.93637246e-01,\n",
      "       -1.34432638e+00, -2.99729323e+00, -2.82144570e+00, -1.88945377e+00,\n",
      "       -2.94453907e+00, -1.28717589e+00, -1.59930527e+00, -8.26202035e-02,\n",
      "       -2.15762115e+00, -1.13770545e+00, -2.24554491e+00, -1.06736648e+00,\n",
      "       -3.77164811e-01, -2.81704950e+00,  1.19604476e-01, -2.43897724e+00,\n",
      "       -2.05713481e-01, -2.60603237e+00, -2.17080975e+00, -1.38828826e+00,\n",
      "       -2.34226108e+00, -1.39268434e+00,  2.25113004e-01, -1.02340460e+00,\n",
      "       -6.93690419e-01, -9.09103632e-01,  5.80578335e-02, -7.77217984e-01,\n",
      "       -1.85868037e+00, -1.04098928e+00, -1.91143465e+00, -1.44983482e+00,\n",
      "       -1.21244061e+00,  1.02019720e-01, -2.43458104e+00, -3.37599158e-01,\n",
      "       -3.59580100e-01, -3.85957211e-01, -8.43160808e-01, -1.55973959e+00,\n",
      "        8.00387785e-02, -8.73934150e-01, -3.90353382e-01, -1.00142360e+00,\n",
      "       -1.92524925e-01, -2.64120197e+00, -1.79273760e+00, -8.91518891e-01,\n",
      "       -2.99729323e+00,  1.06415905e-01, -1.35311866e+00, -1.92022705e+00,\n",
      "       -4.47503835e-01, -8.26202035e-02, -6.80501819e-01, -2.61482477e+00,\n",
      "       -1.52959228e-01, -2.59284401e+00, -2.61922097e+00, -2.58405161e+00,\n",
      "       -2.56646681e+00, -2.87859607e+00, -9.00311291e-01, -2.50052404e+00,\n",
      "       -4.03541952e-01, -8.60745549e-01, -2.83023810e+00, -1.70481384e+00,\n",
      "       -1.05857408e+00, -1.61249387e+00, -2.56207061e+00,  2.29509190e-01,\n",
      "       -8.03595126e-01, -2.66318297e+00, -1.59930527e+00, -2.85661530e+00,\n",
      "       -1.75756800e+00, -1.80152988e+00, -2.56207061e+00, -1.58172047e+00,\n",
      "       -2.34665728e+00, -2.39941168e+00, -2.07409358e+00, -1.97737753e+00,\n",
      "       -3.24410588e-01, -1.99496222e+00, -5.09050488e-01, -1.16408265e+00,\n",
      "       -2.69835234e+00, -2.64999437e+00, -2.08728218e+00, -2.55767441e+00,\n",
      "       -1.69602144e+00, -4.69484776e-01, -6.80501819e-01,  2.20716804e-01,\n",
      "       -1.60809767e+00, -6.05766654e-01, -2.76429534e+00, -6.01370454e-01,\n",
      "       -2.97091603e+00, -5.44219971e-01, -1.80592608e+00,  2.25113004e-01,\n",
      "       -1.30476058e+00, -2.32907248e+00, -2.13564038e+00, -2.44337344e+00,\n",
      "        1.31562099e-01,  1.67830661e-01, -3.04583758e-01,  2.09198803e-01,\n",
      "        2.25244880e-01, -3.21079977e-02, -7.65534639e-02,  2.73602962e-01,\n",
      "        2.67536223e-01, -2.33453438e-01, -6.09469935e-02,  2.50918627e-01,\n",
      "       -1.77182227e-01,  4.91335690e-02,  5.80138713e-02,  7.16860145e-02,\n",
      "        2.48588651e-01,  2.91099787e-01,  2.65953600e-01,  2.36235350e-01,\n",
      "        2.57249147e-01, -2.45762765e-01, -2.15121329e-01, -8.10375735e-02,\n",
      "       -1.62377562e-02,  2.46390551e-01,  2.82659113e-01,  2.07748055e-01,\n",
      "       -1.85754791e-01,  2.71580726e-01,  2.14650065e-01, -6.88161701e-02,\n",
      "        2.45115653e-01,  2.32102945e-01,  2.60941923e-01,  2.27882594e-01,\n",
      "        1.15428090e-01, -1.86238378e-01,  2.04934493e-01,  1.64313704e-01,\n",
      "        1.39211476e-01,  2.36894786e-01,  2.00308003e-02,  2.04264577e-02,\n",
      "        1.68050468e-01,  7.90276527e-02,  2.80329138e-01, -5.83532453e-02,\n",
      "       -1.21394590e-01,  2.71932423e-01,  2.83835586e-02,  1.66995391e-01,\n",
      "        2.45599240e-01,  1.24528207e-01,  2.80241191e-01,  1.77853972e-01,\n",
      "        2.60722131e-01,  4.83422540e-02, -3.04407924e-01,  1.41673341e-01,\n",
      "       -1.40605927e-01,  2.13936176e-02,  1.87657475e-01, -1.87435839e-02,\n",
      "        2.00098693e-01,  8.90069976e-02,  2.12715745e-01, -2.00624410e-02,\n",
      "        1.54949829e-01,  2.43620947e-01, -1.42804027e-01,  2.59051591e-01,\n",
      "        2.83933997e-01,  1.84042100e-02,  2.47489601e-01, -2.44146679e-02,\n",
      "       -2.34580017e-03, -3.87902036e-02, -1.77429570e-03,  1.39343366e-01,\n",
      "        2.24761307e-01,  5.84534891e-02, -6.21444639e-03,  1.46201417e-01],\n",
      "      dtype=float32), 'SCENARIO': array([b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3',\n",
      "       b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3',\n",
      "       b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3',\n",
      "       b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3',\n",
      "       b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3',\n",
      "       b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3',\n",
      "       b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3',\n",
      "       b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3',\n",
      "       b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3',\n",
      "       b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3',\n",
      "       b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3',\n",
      "       b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3',\n",
      "       b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3',\n",
      "       b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3',\n",
      "       b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3',\n",
      "       b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3',\n",
      "       b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3',\n",
      "       b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3',\n",
      "       b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3',\n",
      "       b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3',\n",
      "       b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3',\n",
      "       b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3',\n",
      "       b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3',\n",
      "       b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3',\n",
      "       b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3',\n",
      "       b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3',\n",
      "       b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3',\n",
      "       b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3',\n",
      "       b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3',\n",
      "       b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3',\n",
      "       b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3',\n",
      "       b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3',\n",
      "       b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3',\n",
      "       b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3',\n",
      "       b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3',\n",
      "       b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3',\n",
      "       b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3',\n",
      "       b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3',\n",
      "       b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'3', b'4',\n",
      "       b'4', b'4', b'4', b'4', b'4', b'4', b'4', b'4', b'4', b'4', b'4',\n",
      "       b'4', b'4', b'4', b'4', b'4', b'4', b'4', b'4', b'4', b'4', b'4',\n",
      "       b'4', b'4', b'4', b'4', b'4', b'4', b'4', b'4', b'4', b'4', b'4',\n",
      "       b'4', b'4', b'4', b'4', b'4', b'4', b'4', b'4', b'4', b'4', b'4',\n",
      "       b'4', b'4', b'4', b'4', b'4', b'4', b'4', b'4', b'4', b'4', b'4',\n",
      "       b'4', b'4', b'4', b'4', b'4', b'4', b'4', b'4', b'4', b'4', b'4',\n",
      "       b'4', b'4', b'4', b'4', b'4', b'4', b'4', b'4', b'4', b'4', b'4',\n",
      "       b'4', b'4', b'4', b'4', b'4', b'4'], dtype=object), 'WERKS': array([b'ML01', b'ML01', b'ML01', b'ML01', b'ML01', b'ML01', b'ML01',\n",
      "       b'ML01', b'ML01', b'ML01', b'ML01', b'ML01', b'ML01', b'ML01',\n",
      "       b'ML01', b'ML01', b'ML01', b'ML01', b'ML01', b'ML01', b'ML01',\n",
      "       b'ML01', b'ML01', b'ML01', b'ML01', b'ML01', b'ML01', b'ML01',\n",
      "       b'ML01', b'ML01', b'ML01', b'ML01', b'ML01', b'ML01', b'ML01',\n",
      "       b'ML01', b'ML01', b'ML01', b'ML01', b'ML01', b'ML01', b'ML01',\n",
      "       b'ML01', b'ML01', b'ML01', b'ML01', b'ML01', b'ML01', b'ML01',\n",
      "       b'ML01', b'ML01', b'ML01', b'ML01', b'ML01', b'ML01', b'ML01',\n",
      "       b'ML01', b'ML01', b'ML01', b'ML01', b'ML01', b'ML01', b'ML01',\n",
      "       b'ML01', b'ML01', b'ML01', b'ML01', b'ML01', b'ML01', b'ML01',\n",
      "       b'ML01', b'ML01', b'ML01', b'ML01', b'ML01', b'ML01', b'ML01',\n",
      "       b'ML01', b'ML01', b'ML01', b'ML01', b'ML01', b'ML01', b'ML01',\n",
      "       b'ML01', b'ML01', b'ML01', b'ML01', b'ML01', b'ML01', b'ML01',\n",
      "       b'ML01', b'ML01', b'ML01', b'ML01', b'ML01', b'ML01', b'ML01',\n",
      "       b'ML01', b'ML01', b'ML01', b'ML01', b'ML01', b'ML01', b'ML01',\n",
      "       b'ML01', b'ML01', b'ML01', b'ML01', b'ML01', b'ML01', b'ML01',\n",
      "       b'ML01', b'ML01', b'ML01', b'ML01', b'ML01', b'ML01', b'ML01',\n",
      "       b'ML01', b'ML01', b'ML01', b'ML01', b'ML01', b'ML01', b'ML01',\n",
      "       b'ML01', b'ML01', b'ML01', b'ML01', b'ML01', b'ML01', b'ML01',\n",
      "       b'ML01', b'ML01', b'ML01', b'ML01', b'ML02', b'ML02', b'ML02',\n",
      "       b'ML02', b'ML02', b'ML02', b'ML02', b'ML02', b'ML02', b'ML02',\n",
      "       b'ML02', b'ML02', b'ML02', b'ML02', b'ML02', b'ML02', b'ML02',\n",
      "       b'ML02', b'ML02', b'ML02', b'ML02', b'ML02', b'ML02', b'ML02',\n",
      "       b'ML02', b'ML02', b'ML02', b'ML02', b'ML02', b'ML02', b'ML02',\n",
      "       b'ML02', b'ML02', b'ML02', b'ML02', b'ML02', b'ML02', b'ML02',\n",
      "       b'ML02', b'ML02', b'ML02', b'ML02', b'ML02', b'ML02', b'ML02',\n",
      "       b'ML02', b'ML02', b'ML02', b'ML02', b'ML02', b'ML02', b'ML02',\n",
      "       b'ML02', b'ML02', b'ML02', b'ML02', b'ML02', b'ML02', b'ML02',\n",
      "       b'ML02', b'ML02', b'ML02', b'ML02', b'ML02', b'ML02', b'ML02',\n",
      "       b'ML02', b'ML02', b'ML02', b'ML02', b'ML02', b'ML02', b'ML02',\n",
      "       b'ML02', b'ML02', b'ML02', b'ML02', b'ML02', b'ML02', b'ML02',\n",
      "       b'ML02', b'ML02', b'ML02', b'ML02', b'ML02', b'ML02', b'ML02',\n",
      "       b'ML02', b'ML02', b'ML02', b'ML02', b'ML02', b'ML02', b'ML02',\n",
      "       b'ML02', b'ML02', b'ML02', b'ML02', b'ML02', b'ML02', b'ML02',\n",
      "       b'ML02', b'ML02', b'ML02', b'ML02', b'ML02', b'ML02', b'ML02',\n",
      "       b'ML02', b'ML02', b'ML02', b'ML02', b'ML02', b'ML02', b'ML02',\n",
      "       b'ML02', b'ML02', b'ML02', b'ML02', b'ML02', b'ML02', b'ML02',\n",
      "       b'ML02', b'ML02', b'ML02', b'ML02', b'ML02', b'ML02', b'ML02',\n",
      "       b'ML02', b'ML02', b'ML02', b'ML02', b'ML02', b'ML02', b'ML02',\n",
      "       b'ML02', b'ML02', b'ML02', b'ML02', b'ML02', b'ML02', b'ML02',\n",
      "       b'ML02', b'ML02', b'ML02', b'ML02', b'ML02', b'ML02', b'ML02',\n",
      "       b'ML02', b'ML03', b'ML03', b'ML03', b'ML03', b'ML03', b'ML03',\n",
      "       b'ML03', b'ML03', b'ML03', b'ML03', b'ML03', b'ML03', b'ML03',\n",
      "       b'ML03', b'ML03', b'ML03', b'ML03', b'ML03', b'ML03', b'ML03',\n",
      "       b'ML03', b'ML03', b'ML03', b'ML03', b'ML03', b'ML03', b'ML03',\n",
      "       b'ML03', b'ML03', b'ML03', b'ML03', b'ML03', b'ML03', b'ML03',\n",
      "       b'ML03', b'ML03', b'ML03', b'ML03', b'ML03', b'ML03', b'ML03',\n",
      "       b'ML03', b'ML03', b'ML03', b'ML03', b'ML03', b'ML03', b'ML03',\n",
      "       b'ML03', b'ML03', b'ML03', b'ML03', b'ML03', b'ML03', b'ML03',\n",
      "       b'ML03', b'ML03', b'ML03', b'ML03', b'ML03', b'ML03', b'ML03',\n",
      "       b'ML03', b'ML03', b'ML03', b'ML03', b'ML03', b'ML03', b'ML03',\n",
      "       b'ML03', b'ML03', b'ML03', b'ML03', b'ML03', b'ML03', b'ML03',\n",
      "       b'ML03', b'ML03', b'ML03', b'ML03', b'ML03', b'ML03', b'ML03',\n",
      "       b'ML03', b'ML03', b'ML03', b'ML03', b'ML03', b'ML03', b'ML03',\n",
      "       b'ML03', b'ML03', b'ML03', b'ML03', b'ML03', b'ML03', b'ML03',\n",
      "       b'ML03', b'ML03', b'ML03', b'ML03', b'ML03', b'ML03', b'ML03',\n",
      "       b'ML03', b'ML03', b'ML03', b'ML03', b'ML03', b'ML03', b'ML03',\n",
      "       b'ML03', b'ML03', b'ML03', b'ML03', b'ML03', b'ML03', b'ML03',\n",
      "       b'ML03', b'ML03', b'ML03', b'ML03', b'ML03', b'ML03', b'ML03',\n",
      "       b'ML03', b'ML03', b'ML03', b'ML03', b'ML03', b'ML03', b'ML03',\n",
      "       b'ML03', b'ML03', b'ML03', b'ML03', b'ML03', b'ML03', b'ML03',\n",
      "       b'ML03', b'ML01', b'ML01', b'ML01', b'ML01', b'ML01', b'ML01',\n",
      "       b'ML01', b'ML01', b'ML01', b'ML01', b'ML01', b'ML01', b'ML01',\n",
      "       b'ML01', b'ML01', b'ML01', b'ML01', b'ML01', b'ML01', b'ML01',\n",
      "       b'ML01', b'ML01', b'ML01', b'ML01', b'ML01', b'ML01', b'ML01',\n",
      "       b'ML01', b'ML01', b'ML01', b'ML01', b'ML01', b'ML01', b'ML01',\n",
      "       b'ML01', b'ML01', b'ML01', b'ML01', b'ML01', b'ML01', b'ML01',\n",
      "       b'ML01', b'ML01', b'ML01', b'ML01', b'ML01', b'ML01', b'ML01',\n",
      "       b'ML01', b'ML01', b'ML01', b'ML01', b'ML01', b'ML01', b'ML01',\n",
      "       b'ML01', b'ML01', b'ML01', b'ML01', b'ML01', b'ML01', b'ML01',\n",
      "       b'ML01', b'ML01', b'ML01', b'ML01', b'ML01', b'ML01', b'ML01',\n",
      "       b'ML01', b'ML01', b'ML01', b'ML01', b'ML01', b'ML01', b'ML01',\n",
      "       b'ML01', b'ML01', b'ML01', b'ML01', b'ML01', b'ML01', b'ML01',\n",
      "       b'ML01'], dtype=object), 'EKGRP': array([b'A', b'A', b'A', b'A', b'A', b'A', b'A', b'A', b'B', b'B', b'B',\n",
      "       b'B', b'B', b'B', b'B', b'B', b'B', b'C', b'C', b'C', b'C', b'C',\n",
      "       b'C', b'A', b'A', b'A', b'A', b'A', b'A', b'A', b'A', b'A', b'A',\n",
      "       b'A', b'A', b'A', b'A', b'A', b'A', b'A', b'B', b'B', b'B', b'B',\n",
      "       b'B', b'B', b'B', b'B', b'B', b'B', b'B', b'B', b'B', b'B', b'C',\n",
      "       b'C', b'C', b'C', b'C', b'C', b'C', b'C', b'C', b'C', b'C', b'C',\n",
      "       b'C', b'A', b'A', b'A', b'A', b'A', b'A', b'A', b'A', b'A', b'A',\n",
      "       b'B', b'B', b'B', b'B', b'B', b'B', b'B', b'B', b'B', b'B', b'B',\n",
      "       b'B', b'B', b'B', b'B', b'B', b'C', b'C', b'C', b'C', b'C', b'C',\n",
      "       b'C', b'C', b'C', b'C', b'C', b'A', b'A', b'A', b'A', b'A', b'A',\n",
      "       b'A', b'A', b'A', b'A', b'A', b'B', b'B', b'B', b'B', b'B', b'B',\n",
      "       b'B', b'C', b'C', b'C', b'C', b'C', b'C', b'C', b'C', b'C', b'C',\n",
      "       b'C', b'C', b'C', b'C', b'C', b'A', b'A', b'A', b'A', b'A', b'A',\n",
      "       b'A', b'A', b'A', b'A', b'A', b'A', b'A', b'A', b'A', b'A', b'A',\n",
      "       b'A', b'A', b'A', b'B', b'B', b'B', b'B', b'B', b'B', b'B', b'C',\n",
      "       b'C', b'C', b'C', b'C', b'A', b'A', b'A', b'A', b'A', b'A', b'A',\n",
      "       b'A', b'A', b'A', b'A', b'A', b'A', b'A', b'A', b'A', b'A', b'B',\n",
      "       b'B', b'B', b'B', b'B', b'B', b'B', b'B', b'B', b'B', b'B', b'C',\n",
      "       b'C', b'C', b'C', b'C', b'C', b'C', b'C', b'C', b'A', b'A', b'A',\n",
      "       b'A', b'A', b'A', b'A', b'A', b'A', b'A', b'A', b'A', b'A', b'A',\n",
      "       b'A', b'A', b'B', b'B', b'B', b'B', b'B', b'B', b'B', b'B', b'B',\n",
      "       b'B', b'B', b'C', b'C', b'C', b'C', b'C', b'C', b'C', b'C', b'C',\n",
      "       b'C', b'C', b'C', b'C', b'C', b'C', b'C', b'C', b'C', b'A', b'A',\n",
      "       b'A', b'A', b'A', b'A', b'A', b'A', b'A', b'A', b'A', b'A', b'A',\n",
      "       b'A', b'A', b'A', b'B', b'B', b'B', b'B', b'B', b'B', b'B', b'B',\n",
      "       b'B', b'B', b'C', b'C', b'C', b'C', b'C', b'C', b'C', b'C', b'C',\n",
      "       b'C', b'C', b'A', b'A', b'A', b'A', b'A', b'A', b'A', b'A', b'A',\n",
      "       b'A', b'A', b'A', b'A', b'A', b'A', b'B', b'B', b'B', b'B', b'B',\n",
      "       b'B', b'B', b'B', b'B', b'B', b'C', b'C', b'C', b'C', b'C', b'C',\n",
      "       b'C', b'C', b'C', b'C', b'C', b'A', b'A', b'A', b'A', b'A', b'A',\n",
      "       b'A', b'A', b'A', b'A', b'A', b'A', b'A', b'A', b'B', b'B', b'B',\n",
      "       b'B', b'B', b'B', b'B', b'B', b'B', b'B', b'B', b'B', b'C', b'C',\n",
      "       b'C', b'C', b'C', b'C', b'C', b'C', b'C', b'C', b'C', b'C', b'C',\n",
      "       b'A', b'A', b'A', b'A', b'A', b'A', b'A', b'A', b'A', b'A', b'A',\n",
      "       b'B', b'B', b'B', b'B', b'B', b'B', b'B', b'B', b'C', b'C', b'C',\n",
      "       b'C', b'C', b'C', b'C', b'A', b'A', b'A', b'A', b'A', b'A', b'A',\n",
      "       b'A', b'A', b'A', b'A', b'A', b'A', b'B', b'B', b'B', b'B', b'B',\n",
      "       b'B', b'B', b'B', b'B', b'B', b'B', b'B', b'B', b'B', b'B', b'C',\n",
      "       b'C', b'C', b'C', b'C', b'C', b'C', b'C', b'C', b'C', b'C', b'A',\n",
      "       b'A', b'A', b'A', b'A', b'A', b'A', b'A', b'A', b'A', b'A', b'A',\n",
      "       b'B', b'B', b'B', b'B', b'B', b'B', b'B', b'B', b'B', b'B', b'B',\n",
      "       b'B', b'B', b'C', b'C', b'C', b'C', b'C', b'C', b'C', b'C', b'C',\n",
      "       b'C', b'A', b'A', b'A', b'A', b'A', b'A', b'A', b'A', b'A', b'B',\n",
      "       b'B', b'B', b'B', b'B', b'B', b'B', b'B', b'B', b'B', b'B', b'B',\n",
      "       b'C', b'C', b'C', b'C', b'C', b'C', b'C', b'C', b'C', b'C', b'C',\n",
      "       b'C', b'C', b'A', b'A', b'A', b'A', b'A', b'A', b'A', b'A', b'A',\n",
      "       b'A', b'A', b'A', b'A', b'A', b'A'], dtype=object), 'grminusirbyvpatd': array([-2.2084801 , -2.1160824 , -1.0612091 , -0.26042917, -1.2152051 ,\n",
      "       -0.34897697, -1.0304097 , -0.19883072, -0.77631617, -0.3258775 ,\n",
      "       -0.5376222 , -1.0689088 , -0.7532168 , -0.71471775, -1.3076028 ,\n",
      "       -1.296053  , -0.16033168, -1.4692987 , -3.0862582 , -0.34897697,\n",
      "        0.00906405, -3.9640362 , -0.9842109 , -2.485673  , -0.707018  ,\n",
      "       -0.27582878, -1.7695912 , -0.91491276, -0.7378171 , -0.41442528,\n",
      "        0.00906405, -1.977486  , -2.2777784 , -0.8109653 , -1.41155   ,\n",
      "       -0.6531193 , -0.9226125 , -2.3008778 , -0.8456144 , -0.61462027,\n",
      "       -0.23347987, -0.95341176, -0.16803151, -0.28352857, -0.5106729 ,\n",
      "       -0.61462027, -0.2796787 , -0.61462027, -0.1526319 , -0.71471775,\n",
      "       -0.16803151, -1.2729537 , -1.538597  ,  0.00906405, -3.8947377 ,\n",
      "       -1.5270473 , -0.9688113 , -1.0766087 , -1.8619888 , -1.2383045 ,\n",
      "       -1.7233922 , -3.40965   , -1.2267548 , -0.8109653 , -1.7118425 ,\n",
      "       -1.0073103 , -0.10643306, -0.8302149 , -0.76861644, -2.4394743 ,\n",
      "       -0.545322  , -0.35282683, -1.3422519 , -4.125732  , -2.4625735 ,\n",
      "       -1.0997081 , -0.78401595, -3.6406443 , -3.80234   , -1.7233922 ,\n",
      "       -1.3884507 , -0.67621875, -1.3307022 , -1.2152051 , -1.1805559 ,\n",
      "       -0.42982495, -0.34512702, -3.6406443 , -2.1853807 , -1.81579   ,\n",
      "       -0.68391854, -0.2912284 , -1.0612091 , -0.5607216 , -0.45292434,\n",
      "       -0.5106729 , -0.21423034, -3.1786559 , -3.5482464 , -1.1805559 ,\n",
      "       -2.6242697 , -1.4231    , -1.538597  , -0.59922063, -1.5154976 ,\n",
      "       -0.7301174 , -3.6406443 , -1.1574565 , -4.1488314 , -0.9919107 ,\n",
      "       -0.96111155, -3.1786559 , -1.4000005 , -1.7926906 , -1.8273398 ,\n",
      "       -0.5915208 , -0.22193013, -0.90721285, -0.45292434, -0.20653051,\n",
      "       -1.1459069 , -0.66081905, -0.8687139 , -1.0535091 , -4.1488314 ,\n",
      "       -1.1921057 , -0.8687139 , -0.24502957, -1.6309947 , -2.4394743 ,\n",
      "       -1.4692987 , -2.5549715 , -0.77631617, -0.6492694 , -0.90721285,\n",
      "       -0.14493208, -0.89951307, -1.3884507 , -0.7878659 , -0.6069205 ,\n",
      "       -2.1853807 , -1.6887432 , -1.8388895 , -1.0766087 , -0.22962995,\n",
      "       -1.5154976 , -1.7233922 , -1.6887432 , -0.7878659 , -0.7378171 ,\n",
      "       -0.94571185, -1.1228075 , -4.0333343 , -1.619445  , -1.7580414 ,\n",
      "       -0.30662805, -0.01403539, -2.485673  , -1.1690062 , -0.21038043,\n",
      "       -1.3653513 , -3.1093576 , -1.376901  , -1.700293  , -1.1228075 ,\n",
      "        0.00906405, -1.8042403 , -0.48372358, -0.37592626, -4.1488314 ,\n",
      "       -2.9707613 , -1.261404  , -0.71471775, -1.1074078 , -0.25272936,\n",
      "       -2.6242697 , -0.5337723 , -2.9245625 , -1.734942  , -1.0997081 ,\n",
      "       -0.67621875, -2.370176  , -0.7532168 , -1.0073103 , -1.573246  ,\n",
      "       -0.78401595, -1.1805559 , -0.18728103, -0.3374273 , -0.40672547,\n",
      "       -3.8254395 , -2.6473691 , -0.9957606 , -0.3913259 , -0.7378171 ,\n",
      "       -0.24502957, -0.47602373, -0.44522452, -1.261404  , -1.0535091 ,\n",
      "       -2.6011703 , -2.3239772 , -1.3538016 , -0.52222264, -1.6887432 ,\n",
      "       -1.457749  , -0.6030706 , -1.3307022 , -3.7099426 , -0.9726612 ,\n",
      "       -0.029435  , -2.762866  , -1.3422519 , -0.67236876, -0.55302185,\n",
      "       -1.0535091 , -0.30662805, -1.3076028 , -2.809065  , -0.41442528,\n",
      "       -0.11413284, -0.61462027, -1.1112578 , -0.3027781 ,  0.01676383,\n",
      "       -0.64541954, -3.4789484 , -0.9996106 , -1.700293  , -2.4625735 ,\n",
      "       -0.18728103, -1.7926906 , -0.7532168 , -1.8619888 , -0.19883072,\n",
      "       -0.61462027, -0.76091653, -1.0073103 , -1.6078953 , -1.81579   ,\n",
      "       -2.8321645 , -0.62617   , -1.1921057 , -1.1690062 , -0.14493208,\n",
      "       -2.9245625 , -1.4231    , -3.6637437 , -0.8687139 , -0.029435  ,\n",
      "       -0.4914234 , -0.7532168 , -1.0304097 , -1.1921057 , -0.9919107 ,\n",
      "       -0.24502957, -0.52222264, -0.707018  , -0.5568717 , -0.58382106,\n",
      "       -0.19883072, -0.21423034, -3.3865507 , -3.0862582 , -0.39517576,\n",
      "       -0.6531193 , -1.1382071 , -0.5684214 , -2.254679  , -3.2710538 ,\n",
      "       -2.3470767 , -1.6771935 , -1.2498543 , -0.8687139 , -0.07563384,\n",
      "       -2.9476619 , -0.83791465, -1.3538016 , -1.1228075 , -1.0997081 ,\n",
      "       -0.3682265 , -0.40672547, -1.8850882 , -3.9640362 , -0.6954683 ,\n",
      "       -0.7647665 , -0.5106729 , -0.02173518, -4.125732  , -1.5616963 ,\n",
      "       -0.62617   , -0.8148152 , -0.36052668, -2.254679  , -3.8485389 ,\n",
      "       -0.66081905, -2.693568  , -1.6656438 , -0.22193013, -2.0698836 ,\n",
      "       -2.370176  , -1.2498543 , -0.62617   , -0.76091653, -0.22193013,\n",
      "       -0.18728103, -3.733042  , -1.261404  , -0.8071155 , -3.2248545 ,\n",
      "       -0.94956183, -1.6771935 , -0.34512702, -0.45292434, -1.2729537 ,\n",
      "       -0.9380121 , -0.71471775, -4.010235  , -2.2084801 , -1.8273398 ,\n",
      "       -1.2383045 , -3.5713458 , -0.3374273 , -1.0458094 , -3.5713458 ,\n",
      "       -1.6078953 , -1.3884507 , -2.7397668 , -1.1690062 , -0.42212513,\n",
      "       -0.1526319 , -0.38362607, -0.17573129, -0.24502957, -3.6406443 ,\n",
      "       -0.18728103, -1.0535091 , -0.9226125 , -2.9938605 , -0.24502957,\n",
      "       -0.26812896, -1.700293  , -1.1459069 , -3.9640362 , -1.8735385 ,\n",
      "       -1.6540941 , -1.7926906 , -2.7397668 , -1.3076028 , -0.90336305,\n",
      "       -0.91491276, -3.2710538 , -0.27582878, -0.68391854, -0.91491276,\n",
      "       -3.6868432 , -2.0005853 , -0.3027781 , -0.42982495, -1.3538016 ,\n",
      "       -1.9081876 , -0.26812896, -1.0073103 , -3.0400593 , -1.376901  ,\n",
      "       -1.6887432 , -1.0381097 , -2.4394743 , -0.707018  , -1.376901  ,\n",
      "       -0.45292434, -3.40965   , -0.45292434, -0.62232006, -0.5337723 ,\n",
      "       -1.0150102 , -0.8456144 , -0.9765112 , -1.8619888 , -3.0631588 ,\n",
      "       -3.9178371 , -1.0073103 , -3.2479544 , -0.8687139 , -0.2796787 ,\n",
      "       -0.3913259 , -1.1921057 , -0.19883072, -1.02271   , -2.370176  ,\n",
      "       -0.5915208 , -0.06793401, -0.6531193 , -2.901463  , -2.2315795 ,\n",
      "       -1.3884507 , -1.2267548 , -0.45292434, -1.02271   , -3.7792408 ,\n",
      "       -0.89181334, -1.1151075 , -1.7233922 , -0.3143278 , -1.3653513 ,\n",
      "       -0.12953246, -0.83791465, -2.5318718 , -3.9178371 , -3.8716383 ,\n",
      "       -0.37207636, -1.0881584 , -3.9178371 , -2.1160824 , -0.66081905,\n",
      "       -0.22193013, -0.46062416, -3.2248545 , -1.1690062 , -1.4231    ,\n",
      "       -2.254679  , -2.2315795 , -0.2796787 , -0.66081905, -2.8783634 ,\n",
      "       -0.8109653 , -0.48372358, -0.34512702,  0.0783623 ,  0.37865472,\n",
      "        0.30935648,  0.30935648,  0.22850852,  0.19385938,  0.20155919,\n",
      "        0.39020446,  0.39020446,  0.24005823,  0.28625706,  0.37095493,\n",
      "       -0.24502957,  0.26315767,  0.32475612,  0.2169588 ,  0.37865472,\n",
      "        0.30935648,  0.35555533,  0.35555533,  0.39020446,  0.17075998,\n",
      "        0.12456113,  0.24005823,  0.32475612,  0.26315767,  0.37865472,\n",
      "        0.29780677,  0.24775805,  0.39020446,  0.3632551 , -0.17573129,\n",
      "        0.39405432,  0.0783623 ,  0.3170563 ,  0.38635457,  0.2169588 ,\n",
      "        0.15921026,  0.3324559 ,  0.19385938,  0.28625706,  0.27470735,\n",
      "        0.22850852,  0.15921026, -0.01403539,  0.30935648,  0.37865472,\n",
      "        0.12456113,  0.14766055,  0.35555533,  0.28625706,  0.36710504,\n",
      "        0.25160795,  0.28625706,  0.36710504,  0.3209062 ,  0.37865472,\n",
      "        0.17075998,  0.13611086,  0.3478555 ,  0.26315767, -0.03713479,\n",
      "        0.3209062 ,  0.25545785,  0.14766055,  0.24005823,  0.36710504,\n",
      "        0.23235844,  0.3324559 ,  0.17075998,  0.10146172,  0.3209062 ,\n",
      "        0.39020446,  0.34015572,  0.26315767, -0.06023423,  0.30935648,\n",
      "        0.29780677,  0.27470735,  0.3632551 ,  0.26315767,  0.2169588 ,\n",
      "        0.28625706,  0.05526288], dtype=float32), 'difgrirdbytotgrqty': array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        , -0.125     , -0.06382979,\n",
      "       -0.18181819, -0.03809524, -0.09803922, -0.09944751, -0.1595092 ,\n",
      "       -0.008     , -0.01639344, -0.15      , -0.0882353 , -0.07017544,\n",
      "       -0.17610063, -0.08633094, -0.1724138 , -0.12030075, -0.03296703,\n",
      "       -0.02739726, -0.01960784, -0.02739726, -0.01515152, -0.18018018,\n",
      "       -0.13333334, -0.14432989, -0.10638298, -0.03092784, -0.01265823,\n",
      "       -0.05142857, -0.15037593, -0.00724638, -0.03424658, -0.147929  ,\n",
      "       -0.01515152, -0.08588957, -0.07189543, -0.02898551, -0.17021276,\n",
      "       -0.16030534, -0.04411765, -0.1       , -0.04237288, -0.08396947,\n",
      "       -0.09615385, -0.1257485 , -0.16513762, -0.05594406, -0.0212766 ,\n",
      "       -0.12371134, -0.10784314, -0.02150538, -0.07575758, -0.03797468,\n",
      "       -0.07647059, -0.04273504, -0.04347826, -0.09210526, -0.01428571,\n",
      "       -0.06493507, -0.17293233, -0.13207547, -0.125     , -0.13768116,\n",
      "       -0.0530303 , -0.12179487, -0.06666667, -0.10769231, -0.04545455,\n",
      "       -0.17886178, -0.05142857, -0.07194245, -0.18055555, -0.05185185,\n",
      "       -0.01111111, -0.13793103, -0.04195804, -0.1724138 , -0.15686275,\n",
      "       -0.13432837, -0.09734514, -0.09615385, -0.09090909, -0.0610687 ,\n",
      "       -0.12987013, -0.17857143], dtype=float32), 'VPATD': array([-1.242383 , -1.242383 ,  1.2120222,  1.2120222, -1.242383 ,\n",
      "       -0.0151804,  1.2120222,  1.2120222, -1.242383 , -0.0151804,\n",
      "        1.2120222,  1.2120222, -0.0151804,  1.2120222, -1.242383 ,\n",
      "       -0.0151804,  1.2120222, -1.242383 , -1.242383 , -0.0151804,\n",
      "        1.2120222, -1.242383 ,  1.2120222, -1.242383 , -0.0151804,\n",
      "        1.2120222, -1.242383 , -1.242383 ,  1.2120222,  1.2120222,\n",
      "        1.2120222, -1.242383 , -1.242383 , -0.0151804, -0.0151804,\n",
      "        1.2120222,  1.2120222, -1.242383 ,  1.2120222,  1.2120222,\n",
      "       -0.0151804,  1.2120222,  1.2120222,  1.2120222, -0.0151804,\n",
      "       -0.0151804, -0.0151804, -0.0151804,  1.2120222,  1.2120222,\n",
      "        1.2120222, -0.0151804, -0.0151804,  1.2120222, -1.242383 ,\n",
      "       -0.0151804,  1.2120222,  1.2120222, -1.242383 , -0.0151804,\n",
      "       -0.0151804, -1.242383 , -0.0151804, -0.0151804, -0.0151804,\n",
      "        1.2120222,  1.2120222,  1.2120222,  1.2120222, -1.242383 ,\n",
      "       -0.0151804,  1.2120222, -0.0151804, -1.242383 , -1.242383 ,\n",
      "        1.2120222,  1.2120222, -1.242383 , -1.242383 , -0.0151804,\n",
      "       -0.0151804,  1.2120222, -1.242383 , -1.242383 , -0.0151804,\n",
      "        1.2120222,  1.2120222, -1.242383 , -1.242383 , -0.0151804,\n",
      "        1.2120222,  1.2120222,  1.2120222,  1.2120222, -0.0151804,\n",
      "       -0.0151804,  1.2120222, -1.242383 , -1.242383 , -0.0151804,\n",
      "       -1.242383 , -0.0151804, -0.0151804,  1.2120222, -1.242383 ,\n",
      "        1.2120222, -1.242383 , -0.0151804, -1.242383 ,  1.2120222,\n",
      "       -1.242383 , -1.242383 , -0.0151804, -0.0151804, -0.0151804,\n",
      "       -0.0151804,  1.2120222,  1.2120222, -0.0151804,  1.2120222,\n",
      "       -0.0151804,  1.2120222, -1.242383 ,  1.2120222, -1.242383 ,\n",
      "       -1.242383 , -1.242383 , -0.0151804, -1.242383 , -1.242383 ,\n",
      "       -1.242383 , -1.242383 , -0.0151804, -0.0151804,  1.2120222,\n",
      "        1.2120222,  1.2120222, -0.0151804, -0.0151804,  1.2120222,\n",
      "       -1.242383 , -0.0151804, -0.0151804,  1.2120222,  1.2120222,\n",
      "       -1.242383 , -1.242383 , -0.0151804, -0.0151804,  1.2120222,\n",
      "        1.2120222, -1.242383 , -1.242383 , -0.0151804, -0.0151804,\n",
      "        1.2120222,  1.2120222, -1.242383 , -0.0151804, -0.0151804,\n",
      "       -0.0151804, -1.242383 , -1.242383 , -0.0151804,  1.2120222,\n",
      "        1.2120222, -0.0151804,  1.2120222,  1.2120222, -1.242383 ,\n",
      "       -1.242383 , -0.0151804,  1.2120222,  1.2120222,  1.2120222,\n",
      "       -1.242383 , -0.0151804, -1.242383 , -0.0151804, -0.0151804,\n",
      "        1.2120222, -1.242383 , -1.242383 , -0.0151804, -0.0151804,\n",
      "        1.2120222, -0.0151804, -0.0151804,  1.2120222,  1.2120222,\n",
      "       -1.242383 , -1.242383 , -0.0151804,  1.2120222,  1.2120222,\n",
      "       -0.0151804, -0.0151804,  1.2120222, -1.242383 , -1.242383 ,\n",
      "       -1.242383 , -1.242383 , -0.0151804, -0.0151804, -0.0151804,\n",
      "       -0.0151804, -0.0151804, -0.0151804, -1.242383 , -0.0151804,\n",
      "        1.2120222, -1.242383 , -0.0151804, -0.0151804,  1.2120222,\n",
      "        1.2120222,  1.2120222, -1.242383 , -1.242383 ,  1.2120222,\n",
      "        1.2120222,  1.2120222, -0.0151804, -0.0151804,  1.2120222,\n",
      "        1.2120222, -1.242383 ,  1.2120222, -1.242383 , -1.242383 ,\n",
      "       -0.0151804, -0.0151804,  1.2120222, -1.242383 , -0.0151804,\n",
      "       -0.0151804,  1.2120222, -1.242383 , -0.0151804, -1.242383 ,\n",
      "       -1.242383 , -0.0151804, -0.0151804, -0.0151804,  1.2120222,\n",
      "       -1.242383 , -1.242383 , -1.242383 ,  1.2120222,  1.2120222,\n",
      "        1.2120222, -1.242383 , -1.242383 , -0.0151804,  1.2120222,\n",
      "        1.2120222, -0.0151804,  1.2120222, -0.0151804,  1.2120222,\n",
      "        1.2120222,  1.2120222, -1.242383 , -1.242383 , -0.0151804,\n",
      "        1.2120222,  1.2120222,  1.2120222, -1.242383 , -1.242383 ,\n",
      "       -1.242383 , -0.0151804, -0.0151804,  1.2120222,  1.2120222,\n",
      "       -1.242383 ,  1.2120222, -1.242383 , -0.0151804, -0.0151804,\n",
      "        1.2120222, -0.0151804, -0.0151804, -1.242383 , -0.0151804,\n",
      "       -0.0151804, -0.0151804,  1.2120222, -1.242383 , -0.0151804,\n",
      "       -0.0151804,  1.2120222,  1.2120222, -1.242383 , -1.242383 ,\n",
      "       -0.0151804, -1.242383 , -0.0151804, -0.0151804, -1.242383 ,\n",
      "       -1.242383 , -0.0151804, -0.0151804,  1.2120222, -0.0151804,\n",
      "       -0.0151804, -1.242383 , -0.0151804,  1.2120222, -1.242383 ,\n",
      "       -0.0151804, -0.0151804,  1.2120222, -0.0151804, -0.0151804,\n",
      "       -0.0151804,  1.2120222, -1.242383 , -1.242383 , -0.0151804,\n",
      "       -1.242383 , -1.242383 , -0.0151804,  1.2120222, -1.242383 ,\n",
      "       -1.242383 , -0.0151804, -1.242383 , -1.242383 ,  1.2120222,\n",
      "        1.2120222, -0.0151804, -0.0151804, -0.0151804, -1.242383 ,\n",
      "       -0.0151804, -0.0151804,  1.2120222, -1.242383 , -0.0151804,\n",
      "        1.2120222, -1.242383 , -1.242383 , -1.242383 , -0.0151804,\n",
      "       -0.0151804, -1.242383 , -1.242383 , -0.0151804, -0.0151804,\n",
      "       -1.242383 , -1.242383 ,  1.2120222, -0.0151804,  1.2120222,\n",
      "       -1.242383 , -1.242383 , -0.0151804, -0.0151804, -0.0151804,\n",
      "       -1.242383 , -0.0151804,  1.2120222, -1.242383 , -0.0151804,\n",
      "       -0.0151804,  1.2120222, -1.242383 , -0.0151804, -0.0151804,\n",
      "       -0.0151804, -1.242383 , -0.0151804,  1.2120222, -0.0151804,\n",
      "        1.2120222, -1.242383 ,  1.2120222, -0.0151804, -1.242383 ,\n",
      "       -1.242383 , -0.0151804, -1.242383 , -0.0151804, -0.0151804,\n",
      "        1.2120222, -1.242383 , -0.0151804,  1.2120222, -1.242383 ,\n",
      "       -0.0151804,  1.2120222,  1.2120222, -1.242383 , -1.242383 ,\n",
      "       -0.0151804, -0.0151804, -0.0151804,  1.2120222, -1.242383 ,\n",
      "       -0.0151804,  1.2120222, -1.242383 , -0.0151804, -0.0151804,\n",
      "        1.2120222,  1.2120222, -1.242383 , -1.242383 , -1.242383 ,\n",
      "       -0.0151804, -0.0151804, -1.242383 , -1.242383 , -0.0151804,\n",
      "        1.2120222,  1.2120222, -1.242383 , -0.0151804, -0.0151804,\n",
      "       -1.242383 , -1.242383 , -0.0151804,  1.2120222, -1.242383 ,\n",
      "       -0.0151804,  1.2120222,  1.2120222, -1.242383 ,  1.2120222,\n",
      "        1.2120222, -1.242383 , -0.0151804, -0.0151804,  1.2120222,\n",
      "       -0.0151804, -0.0151804,  1.2120222,  1.2120222,  1.2120222,\n",
      "       -1.242383 , -0.0151804,  1.2120222, -0.0151804,  1.2120222,\n",
      "       -1.242383 , -1.242383 , -1.242383 , -0.0151804, -0.0151804,\n",
      "       -1.242383 , -0.0151804,  1.2120222, -1.242383 , -0.0151804,\n",
      "       -0.0151804,  1.2120222, -0.0151804,  1.2120222, -1.242383 ,\n",
      "        1.2120222, -1.242383 ,  1.2120222,  1.2120222, -1.242383 ,\n",
      "       -0.0151804, -1.242383 , -0.0151804, -1.242383 , -0.0151804,\n",
      "       -0.0151804, -0.0151804, -1.242383 , -0.0151804,  1.2120222,\n",
      "       -1.242383 , -1.242383 , -0.0151804, -1.242383 , -0.0151804,\n",
      "       -0.0151804, -1.242383 , -0.0151804, -0.0151804, -1.242383 ,\n",
      "       -1.242383 , -0.0151804,  1.2120222, -1.242383 , -1.242383 ,\n",
      "       -0.0151804,  1.2120222, -1.242383 , -0.0151804, -0.0151804,\n",
      "        1.2120222,  1.2120222, -1.242383 , -1.242383 , -0.0151804,\n",
      "       -0.0151804,  1.2120222, -1.242383 , -1.242383 , -0.0151804,\n",
      "       -0.0151804, -0.0151804,  1.2120222, -1.242383 , -1.242383 ,\n",
      "       -0.0151804, -0.0151804], dtype=float32), 'NODLGR': array([-1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 , -1.2586846 ,\n",
      "       -1.2586846 , -1.2586846 , -1.2586846 , -0.25751656, -0.4284477 ,\n",
      "        1.622726  ,  0.4994642 ,  0.68260473, -0.36740085,  0.8413265 ,\n",
      "        1.3052825 ,  0.93900144, -0.2819353 ,  0.2796956 ,  1.3785386 ,\n",
      "       -0.5993788 ,  0.10876445,  0.68260473, -0.11100415, -0.2086791 ,\n",
      "       -0.47728518,  1.4273762 ,  1.5983073 , -0.08658542,  0.34074244,\n",
      "        0.73144215,  0.73144215,  0.23085812,  0.14539255, -0.03774795,\n",
      "       -0.29414466,  0.81690776,  0.01108952, -0.7581006 ,  0.426208  ,\n",
      "       -1.0389161 , -0.3918196 , -0.6237976 ,  1.8424946 , -0.9168224 ,\n",
      "       -0.34298214,  1.3174918 , -0.77031   ,  1.0366764 ,  0.6093485 ,\n",
      "        2.0134258 , -0.5017039 , -0.672635  ,  1.2076075 , -0.14763226,\n",
      "        0.5483017 ,  1.4762136 ,  1.3419105 ,  0.07213635, -0.89240366,\n",
      "       -0.02553858,  1.622726  ,  0.93900144, -0.5993788 , -0.3918196 ,\n",
      "        0.4994642 ,  1.8547039 ,  0.792489  ,  1.7936571 , -0.09879479,\n",
      "        1.2686543 ,  0.8779546 , -0.58716947, -0.99007857, -0.8801943 ,\n",
      "        0.30411434, -0.01332922, -0.3551915 ,  0.8413265 ,  0.81690776,\n",
      "        1.8180759 ,  0.34074244,  0.32853305,  0.20643939,  0.34074244,\n",
      "        1.4517949 , -0.99007857,  0.8046984 ,  0.8291171 ,  1.1831888 ,\n",
      "        1.3785386 , -0.6115882 ], dtype=float32), 'KTOKK': array([b'1', b'1', b'2', b'2', b'2', b'2', b'2', b'2', b'1', b'1', b'1',\n",
      "       b'1', b'2', b'2', b'2', b'2', b'2', b'1', b'1', b'1', b'2', b'2',\n",
      "       b'2', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'2', b'2',\n",
      "       b'2', b'2', b'2', b'2', b'2', b'2', b'2', b'1', b'1', b'1', b'1',\n",
      "       b'2', b'2', b'2', b'2', b'2', b'2', b'2', b'2', b'2', b'2', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'2', b'2', b'2', b'2', b'2', b'2',\n",
      "       b'2', b'1', b'1', b'1', b'1', b'1', b'2', b'2', b'2', b'2', b'2',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'2', b'2', b'2', b'2', b'2',\n",
      "       b'2', b'2', b'2', b'2', b'2', b'1', b'1', b'1', b'1', b'2', b'2',\n",
      "       b'2', b'2', b'2', b'2', b'2', b'1', b'1', b'1', b'1', b'2', b'2',\n",
      "       b'2', b'2', b'2', b'2', b'2', b'1', b'1', b'1', b'1', b'1', b'2',\n",
      "       b'2', b'1', b'1', b'1', b'1', b'1', b'1', b'2', b'2', b'2', b'2',\n",
      "       b'2', b'2', b'2', b'2', b'2', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'2', b'2', b'2', b'2', b'2', b'2', b'2', b'2', b'2',\n",
      "       b'2', b'2', b'2', b'1', b'1', b'2', b'2', b'2', b'2', b'2', b'1',\n",
      "       b'1', b'1', b'1', b'2', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'2', b'2', b'2', b'2', b'2', b'2', b'2', b'2', b'2', b'1',\n",
      "       b'1', b'1', b'1', b'2', b'2', b'2', b'2', b'2', b'2', b'2', b'1',\n",
      "       b'1', b'1', b'1', b'2', b'2', b'2', b'2', b'2', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'2', b'2', b'2', b'2', b'2', b'2', b'2', b'2', b'2',\n",
      "       b'2', b'2', b'1', b'1', b'1', b'1', b'1', b'1', b'2', b'2', b'2',\n",
      "       b'2', b'2', b'1', b'1', b'1', b'1', b'1', b'1', b'2', b'2', b'2',\n",
      "       b'2', b'2', b'2', b'2', b'2', b'2', b'2', b'2', b'2', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'2', b'2', b'2', b'2', b'2', b'2',\n",
      "       b'2', b'2', b'2', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'2', b'2', b'1', b'1', b'1', b'1', b'1', b'1', b'2', b'2', b'2',\n",
      "       b'2', b'2', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'2',\n",
      "       b'2', b'2', b'2', b'2', b'2', b'2', b'1', b'1', b'1', b'2', b'2',\n",
      "       b'2', b'2', b'2', b'2', b'2', b'1', b'1', b'1', b'1', b'2', b'2',\n",
      "       b'2', b'2', b'2', b'2', b'2', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'2', b'2', b'2', b'2', b'2', b'2', b'2', b'1', b'1', b'1',\n",
      "       b'2', b'2', b'2', b'2', b'2', b'2', b'2', b'2', b'2', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'2', b'2', b'2', b'2', b'2', b'2', b'2', b'2',\n",
      "       b'1', b'1', b'1', b'1', b'2', b'2', b'2', b'2', b'2', b'2', b'2',\n",
      "       b'1', b'1', b'1', b'1', b'2', b'2', b'2', b'2', b'1', b'1', b'1',\n",
      "       b'1', b'2', b'2', b'2', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'2', b'2', b'2', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'2', b'2', b'2', b'2', b'2', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'2', b'2', b'2', b'2', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'2', b'2', b'2', b'2', b'2',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'2', b'2', b'2', b'2', b'2', b'2',\n",
      "       b'2', b'2', b'1', b'1', b'1', b'1', b'1', b'1', b'2', b'2', b'2',\n",
      "       b'2', b'1', b'1', b'1', b'2', b'2', b'2', b'2', b'2', b'2', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'2', b'2', b'2', b'2', b'2', b'2',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'2', b'2', b'2', b'2',\n",
      "       b'2', b'2', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'2', b'2', b'2', b'2'], dtype=object), 'EKORG': array([b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'2', b'2', b'2', b'2', b'2', b'2', b'2', b'2', b'2',\n",
      "       b'2', b'2', b'2', b'2', b'2', b'2', b'2', b'2', b'2', b'2', b'2',\n",
      "       b'2', b'2', b'2', b'2', b'2', b'2', b'2', b'2', b'2', b'2', b'2',\n",
      "       b'2', b'2', b'2', b'2', b'2', b'2', b'2', b'2', b'2', b'2', b'2',\n",
      "       b'2', b'2', b'2', b'2', b'2', b'2', b'2', b'2', b'2', b'2', b'2',\n",
      "       b'2', b'2', b'2', b'2', b'2', b'2', b'2', b'2', b'2', b'2', b'2',\n",
      "       b'2', b'2', b'2', b'2', b'2', b'2', b'2', b'2', b'2', b'2', b'2',\n",
      "       b'2', b'2', b'2', b'2', b'2', b'2', b'2', b'2', b'2', b'2', b'2',\n",
      "       b'2', b'2', b'2', b'2', b'2', b'2', b'2', b'2', b'2', b'2', b'2',\n",
      "       b'2', b'2', b'2', b'2', b'2', b'2', b'2', b'2', b'2', b'2', b'2',\n",
      "       b'2', b'2', b'2', b'2', b'2', b'2', b'2', b'2', b'2', b'2', b'2',\n",
      "       b'2', b'2', b'2', b'2', b'2', b'2', b'2', b'2', b'2', b'2', b'2',\n",
      "       b'2', b'2', b'2', b'2', b'2', b'2', b'2', b'2', b'2', b'2', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1',\n",
      "       b'1', b'1', b'1', b'1', b'1', b'1'], dtype=object)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'DIFGRIRD': <tf.Tensor 'IteratorGetNext_22:0' shape=(?,) dtype=float32>,\n",
       "  'DIFGRIRV': <tf.Tensor 'IteratorGetNext_22:1' shape=(?,) dtype=float32>,\n",
       "  'EKGRP': <tf.Tensor 'IteratorGetNext_22:2' shape=(?,) dtype=string>,\n",
       "  'EKORG': <tf.Tensor 'IteratorGetNext_22:3' shape=(?,) dtype=string>,\n",
       "  'KTOKK': <tf.Tensor 'IteratorGetNext_22:4' shape=(?,) dtype=string>,\n",
       "  'NODLGR': <tf.Tensor 'IteratorGetNext_22:5' shape=(?,) dtype=float32>,\n",
       "  'NODLIR': <tf.Tensor 'IteratorGetNext_22:6' shape=(?,) dtype=float32>,\n",
       "  'SCENARIO': <tf.Tensor 'IteratorGetNext_22:7' shape=(?,) dtype=string>,\n",
       "  'TOTGRQTY': <tf.Tensor 'IteratorGetNext_22:8' shape=(?,) dtype=float32>,\n",
       "  'TOTIRQTY': <tf.Tensor 'IteratorGetNext_22:9' shape=(?,) dtype=float32>,\n",
       "  'VPATD': <tf.Tensor 'IteratorGetNext_22:10' shape=(?,) dtype=float32>,\n",
       "  'VSTATU': <tf.Tensor 'IteratorGetNext_22:11' shape=(?,) dtype=string>,\n",
       "  'WERKS': <tf.Tensor 'IteratorGetNext_22:12' shape=(?,) dtype=string>,\n",
       "  'difgrirdbytotgrqty': <tf.Tensor 'IteratorGetNext_22:13' shape=(?,) dtype=float32>,\n",
       "  'grminusirbyvpatd': <tf.Tensor 'IteratorGetNext_22:14' shape=(?,) dtype=float32>},\n",
       " <tf.Tensor 'IteratorGetNext_22:15' shape=(?,) dtype=int32>)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test dataset read function\n",
    "eval_file = os.getcwd() + \"\\grir_eval.csv\"\n",
    "fn_d = read_dataset(filename = eval_file,\n",
    "                    mode = tf.estimator.ModeKeys.EVAL,\n",
    "                    batch_size = 512)\n",
    "\n",
    "fn_d(v_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create estimator train and evaluate function\n",
    "def train_and_evaluate(output_dir, num_train_steps, train_file, eval_file):    \n",
    "##### Create Canned estimator instance\n",
    "    ## setting the checkpoint interval to be much lower for this task\n",
    "#     run_config = tf.estimator.RunConfig(save_checkpoints_secs = 40, \n",
    "#                                         keep_checkpoint_max = 3)\n",
    "    \n",
    "    estimator = tf.estimator.DNNClassifier(feature_columns=create_feature_cols(),\n",
    "                                          n_classes=2,\n",
    "                                          hidden_units=[32,64,64,64,64,64,\n",
    "                                                        64,64,64,64,64,64,\n",
    "                                                        64,64,64,64,64,64,\n",
    "                                                        32],\n",
    "                                          dropout = 0.1,\n",
    "                                          optimizer=tf.train.AdamOptimizer(learning_rate=0.0003))\n",
    "#                                           config = run_config)\n",
    "    train_spec = tf.estimator.TrainSpec(input_fn = read_dataset(\n",
    "                                                filename = train_file,\n",
    "                                                mode = tf.estimator.ModeKeys.TRAIN,\n",
    "                                                batch_size = 128),\n",
    "                                      max_steps = num_train_steps)\n",
    "    exp = tf.estimator.LatestExporter(\"decision\", serving_fn)\n",
    "    eval_spec = tf.estimator.EvalSpec(input_fn = read_dataset(\n",
    "                                                filename = eval_file,\n",
    "                                                mode = tf.estimator.ModeKeys.EVAL,\n",
    "                                                batch_size = 128),\n",
    "                                    steps = None, \n",
    "                                    exporters = exp,\n",
    "                                    start_delay_secs = 20, # start evaluating after N seconds, \n",
    "                                    throttle_secs = 45)  # evaluate every N seconds\n",
    "    tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = os.getcwd() + \"\\grir_train.csv\"\n",
    "eval_file = os.getcwd() + \"\\grir_eval.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\hrafiq\\AppData\\Local\\Temp\\tmpn6uxr1dh\n",
      "INFO:tensorflow:Using config: {'_save_summary_steps': 100, '_tf_random_seed': None, '_is_chief': True, '_master': '', '_service': None, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_task_id': 0, '_model_dir': 'C:\\\\Users\\\\hrafiq\\\\AppData\\\\Local\\\\Temp\\\\tmpn6uxr1dh', '_num_ps_replicas': 0, '_session_config': None, '_num_worker_replicas': 1, '_task_type': 'worker', '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x00000298407C7F28>, '_log_step_count_steps': 100}\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after 45 secs (eval_spec.throttle_secs) or training is finished.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\hrafiq\\AppData\\Local\\Temp\\tmpn6uxr1dh\\model.ckpt.\n",
      "INFO:tensorflow:step = 1, loss = 88.679\n",
      "INFO:tensorflow:global_step/sec: 27.9509\n",
      "INFO:tensorflow:step = 101, loss = 83.211426 (3.581 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.4934\n",
      "INFO:tensorflow:step = 201, loss = 82.67604 (3.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.8421\n",
      "INFO:tensorflow:step = 301, loss = 76.978424 (3.046 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.8003\n",
      "INFO:tensorflow:step = 401, loss = 67.50647 (2.957 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.2749\n",
      "INFO:tensorflow:step = 501, loss = 51.29055 (3.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.0926\n",
      "INFO:tensorflow:step = 601, loss = 44.273815 (3.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.6241\n",
      "INFO:tensorflow:step = 701, loss = 37.47331 (2.966 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.3486\n",
      "INFO:tensorflow:step = 801, loss = 28.227009 (3.003 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.741\n",
      "INFO:tensorflow:step = 901, loss = 32.762833 (3.052 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.8982\n",
      "INFO:tensorflow:step = 1001, loss = 47.138958 (2.951 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1054 into C:\\Users\\hrafiq\\AppData\\Local\\Temp\\tmpn6uxr1dh\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 28.089766.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2018-10-01-08:23:54\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\hrafiq\\AppData\\Local\\Temp\\tmpn6uxr1dh\\model.ckpt-1054\n",
      "INFO:tensorflow:Finished evaluation at 2018-10-01-08:23:56\n",
      "INFO:tensorflow:Saving dict for global step 1054: accuracy = 0.909697, accuracy_baseline = 0.60848486, auc = 0.96896726, auc_precision_recall = 0.95202416, average_loss = 0.2643415, global_step = 1054, label/mean = 0.39151517, loss = 33.551037, prediction/mean = 0.4158805\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\hrafiq\\AppData\\Local\\Temp\\tmpn6uxr1dh\\model.ckpt-1054\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b\"C:\\\\Users\\\\hrafiq\\\\AppData\\\\Local\\\\Temp\\\\tmpn6uxr1dh\\\\export\\\\decision\\\\temp-b'1538382241'\\\\saved_model.pb\"\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\hrafiq\\AppData\\Local\\Temp\\tmpn6uxr1dh\\model.ckpt-1054\n",
      "INFO:tensorflow:Saving checkpoints for 1055 into C:\\Users\\hrafiq\\AppData\\Local\\Temp\\tmpn6uxr1dh\\model.ckpt.\n",
      "INFO:tensorflow:step = 1055, loss = 48.01738\n",
      "INFO:tensorflow:global_step/sec: 30.5633\n",
      "INFO:tensorflow:step = 1155, loss = 59.563614 (3.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.1437\n",
      "INFO:tensorflow:step = 1255, loss = 50.9423 (3.017 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.4801\n",
      "INFO:tensorflow:step = 1355, loss = 47.922707 (3.183 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.3902\n",
      "INFO:tensorflow:step = 1455, loss = 49.57001 (3.081 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.8976\n",
      "INFO:tensorflow:step = 1555, loss = 28.487106 (3.055 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.8757\n",
      "INFO:tensorflow:step = 1655, loss = 35.027378 (3.027 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.9762\n",
      "INFO:tensorflow:step = 1755, loss = 16.564478 (3.034 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.0839\n",
      "INFO:tensorflow:step = 1855, loss = 24.281532 (2.931 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.6751\n",
      "INFO:tensorflow:step = 1955, loss = 22.843231 (3.162 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2015 into C:\\Users\\hrafiq\\AppData\\Local\\Temp\\tmpn6uxr1dh\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 23.630295.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2018-10-01-08:24:56\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\hrafiq\\AppData\\Local\\Temp\\tmpn6uxr1dh\\model.ckpt-2015\n",
      "INFO:tensorflow:Finished evaluation at 2018-10-01-08:24:57\n",
      "INFO:tensorflow:Saving dict for global step 2015: accuracy = 0.9248485, accuracy_baseline = 0.60848486, auc = 0.98519325, auc_precision_recall = 0.97702044, average_loss = 0.19996312, global_step = 2015, label/mean = 0.39151517, loss = 25.379934, prediction/mean = 0.46305746\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\hrafiq\\AppData\\Local\\Temp\\tmpn6uxr1dh\\model.ckpt-2015\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b\"C:\\\\Users\\\\hrafiq\\\\AppData\\\\Local\\\\Temp\\\\tmpn6uxr1dh\\\\export\\\\decision\\\\temp-b'1538382299'\\\\saved_model.pb\"\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\hrafiq\\AppData\\Local\\Temp\\tmpn6uxr1dh\\model.ckpt-2015\n",
      "INFO:tensorflow:Saving checkpoints for 2016 into C:\\Users\\hrafiq\\AppData\\Local\\Temp\\tmpn6uxr1dh\\model.ckpt.\n",
      "INFO:tensorflow:step = 2016, loss = 14.564761\n",
      "INFO:tensorflow:global_step/sec: 33.0506\n",
      "INFO:tensorflow:step = 2116, loss = 35.07251 (3.030 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.4473\n",
      "INFO:tensorflow:step = 2216, loss = 32.764904 (3.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.119\n",
      "INFO:tensorflow:step = 2316, loss = 29.54313 (3.102 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.691\n",
      "INFO:tensorflow:step = 2416, loss = 30.680231 (3.507 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.2636\n",
      "INFO:tensorflow:step = 2516, loss = 27.849213 (3.656 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.3889\n",
      "INFO:tensorflow:step = 2616, loss = 16.563179 (3.507 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.3108\n",
      "INFO:tensorflow:step = 2716, loss = 11.833482 (3.428 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.5153\n",
      "INFO:tensorflow:step = 2816, loss = 20.227057 (3.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.5409\n",
      "INFO:tensorflow:step = 2916, loss = 20.2594 (3.410 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2948 into C:\\Users\\hrafiq\\AppData\\Local\\Temp\\tmpn6uxr1dh\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 27.29404.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2018-10-01-08:25:57\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\hrafiq\\AppData\\Local\\Temp\\tmpn6uxr1dh\\model.ckpt-2948\n",
      "INFO:tensorflow:Finished evaluation at 2018-10-01-08:25:59\n",
      "INFO:tensorflow:Saving dict for global step 2948: accuracy = 0.9230303, accuracy_baseline = 0.60848486, auc = 0.9873517, auc_precision_recall = 0.9790263, average_loss = 0.20207979, global_step = 2948, label/mean = 0.39151517, loss = 25.648588, prediction/mean = 0.47376457\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\hrafiq\\AppData\\Local\\Temp\\tmpn6uxr1dh\\model.ckpt-2948\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b\"C:\\\\Users\\\\hrafiq\\\\AppData\\\\Local\\\\Temp\\\\tmpn6uxr1dh\\\\export\\\\decision\\\\temp-b'1538382360'\\\\saved_model.pb\"\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\hrafiq\\AppData\\Local\\Temp\\tmpn6uxr1dh\\model.ckpt-2948\n",
      "INFO:tensorflow:Saving checkpoints for 2949 into C:\\Users\\hrafiq\\AppData\\Local\\Temp\\tmpn6uxr1dh\\model.ckpt.\n",
      "INFO:tensorflow:step = 2949, loss = 19.909744\n",
      "INFO:tensorflow:global_step/sec: 26.4712\n",
      "INFO:tensorflow:step = 3049, loss = 31.101353 (3.812 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 29.3195\n",
      "INFO:tensorflow:step = 3149, loss = 29.307823 (3.396 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.7702\n",
      "INFO:tensorflow:step = 3249, loss = 29.902489 (3.342 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.7189\n",
      "INFO:tensorflow:step = 3349, loss = 21.50901 (2.879 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.9143\n",
      "INFO:tensorflow:step = 3449, loss = 17.795204 (3.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.6626\n",
      "INFO:tensorflow:step = 3549, loss = 20.105513 (3.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.6913\n",
      "INFO:tensorflow:step = 3649, loss = 16.9059 (3.618 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.0732\n",
      "INFO:tensorflow:step = 3749, loss = 16.78277 (3.554 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.4142\n",
      "INFO:tensorflow:step = 3849, loss = 14.742765 (3.412 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3863 into C:\\Users\\hrafiq\\AppData\\Local\\Temp\\tmpn6uxr1dh\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 22.832829.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2018-10-01-08:26:59\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\hrafiq\\AppData\\Local\\Temp\\tmpn6uxr1dh\\model.ckpt-3863\n",
      "INFO:tensorflow:Finished evaluation at 2018-10-01-08:27:02\n",
      "INFO:tensorflow:Saving dict for global step 3863: accuracy = 0.94242424, accuracy_baseline = 0.60848486, auc = 0.98926204, auc_precision_recall = 0.9824703, average_loss = 0.15632536, global_step = 3863, label/mean = 0.39151517, loss = 19.841295, prediction/mean = 0.43662885\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\hrafiq\\AppData\\Local\\Temp\\tmpn6uxr1dh\\model.ckpt-3863\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b\"C:\\\\Users\\\\hrafiq\\\\AppData\\\\Local\\\\Temp\\\\tmpn6uxr1dh\\\\export\\\\decision\\\\temp-b'1538382423'\\\\saved_model.pb\"\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\hrafiq\\AppData\\Local\\Temp\\tmpn6uxr1dh\\model.ckpt-3863\n",
      "INFO:tensorflow:Saving checkpoints for 3864 into C:\\Users\\hrafiq\\AppData\\Local\\Temp\\tmpn6uxr1dh\\model.ckpt.\n",
      "INFO:tensorflow:step = 3864, loss = 20.043186\n",
      "INFO:tensorflow:global_step/sec: 31.9338\n",
      "INFO:tensorflow:step = 3964, loss = 36.261627 (3.134 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.4937\n",
      "INFO:tensorflow:step = 4064, loss = 18.761791 (3.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.6334\n",
      "INFO:tensorflow:step = 4164, loss = 18.757427 (3.616 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.7732\n",
      "INFO:tensorflow:step = 4264, loss = 23.012589 (2.876 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.4013\n",
      "INFO:tensorflow:step = 4364, loss = 18.906597 (2.907 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.6633\n",
      "INFO:tensorflow:step = 4464, loss = 16.59323 (3.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.0088\n",
      "INFO:tensorflow:step = 4564, loss = 8.37801 (3.735 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.7879\n",
      "INFO:tensorflow:step = 4664, loss = 14.65452 (3.351 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.7132\n",
      "INFO:tensorflow:step = 4764, loss = 9.341794 (4.044 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4826 into C:\\Users\\hrafiq\\AppData\\Local\\Temp\\tmpn6uxr1dh\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5.3886433.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2018-10-01-08:28:00\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\hrafiq\\AppData\\Local\\Temp\\tmpn6uxr1dh\\model.ckpt-4826\n",
      "INFO:tensorflow:Finished evaluation at 2018-10-01-08:28:02\n",
      "INFO:tensorflow:Saving dict for global step 4826: accuracy = 0.92545456, accuracy_baseline = 0.60848486, auc = 0.9879183, auc_precision_recall = 0.9805488, average_loss = 0.20412809, global_step = 4826, label/mean = 0.39151517, loss = 25.908566, prediction/mean = 0.4661753\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\hrafiq\\AppData\\Local\\Temp\\tmpn6uxr1dh\\model.ckpt-4826\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b\"C:\\\\Users\\\\hrafiq\\\\AppData\\\\Local\\\\Temp\\\\tmpn6uxr1dh\\\\export\\\\decision\\\\temp-b'1538382483'\\\\saved_model.pb\"\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\hrafiq\\AppData\\Local\\Temp\\tmpn6uxr1dh\\model.ckpt-4826\n",
      "INFO:tensorflow:Saving checkpoints for 4827 into C:\\Users\\hrafiq\\AppData\\Local\\Temp\\tmpn6uxr1dh\\model.ckpt.\n",
      "INFO:tensorflow:step = 4827, loss = 10.216491\n",
      "INFO:tensorflow:global_step/sec: 32.9225\n",
      "INFO:tensorflow:step = 4927, loss = 14.565098 (3.043 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.0835\n",
      "INFO:tensorflow:step = 5027, loss = 25.322601 (3.028 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.6786\n",
      "INFO:tensorflow:step = 5127, loss = 22.863499 (3.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.2803\n",
      "INFO:tensorflow:step = 5227, loss = 10.070202 (3.099 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.0521\n",
      "INFO:tensorflow:step = 5327, loss = 19.204632 (3.134 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.0315\n",
      "INFO:tensorflow:step = 5427, loss = 5.4317374 (3.106 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.4104\n",
      "INFO:tensorflow:step = 5527, loss = 9.43956 (3.005 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.2229\n",
      "INFO:tensorflow:step = 5627, loss = 6.3946357 (3.089 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.2421\n",
      "INFO:tensorflow:step = 5727, loss = 9.9668455 (2.924 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.3966\n",
      "INFO:tensorflow:step = 5827, loss = 21.746706 (2.822 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5904 into C:\\Users\\hrafiq\\AppData\\Local\\Temp\\tmpn6uxr1dh\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 15.69346.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2018-10-01-08:28:58\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\hrafiq\\AppData\\Local\\Temp\\tmpn6uxr1dh\\model.ckpt-5904\n",
      "INFO:tensorflow:Finished evaluation at 2018-10-01-08:29:00\n",
      "INFO:tensorflow:Saving dict for global step 5904: accuracy = 0.9478788, accuracy_baseline = 0.60848486, auc = 0.9916572, auc_precision_recall = 0.9864789, average_loss = 0.14614427, global_step = 5904, label/mean = 0.39151517, loss = 18.54908, prediction/mean = 0.43849602\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\hrafiq\\AppData\\Local\\Temp\\tmpn6uxr1dh\\model.ckpt-5904\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b\"C:\\\\Users\\\\hrafiq\\\\AppData\\\\Local\\\\Temp\\\\tmpn6uxr1dh\\\\export\\\\decision\\\\temp-b'1538382541'\\\\saved_model.pb\"\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\hrafiq\\AppData\\Local\\Temp\\tmpn6uxr1dh\\model.ckpt-5904\n",
      "INFO:tensorflow:Saving checkpoints for 5905 into C:\\Users\\hrafiq\\AppData\\Local\\Temp\\tmpn6uxr1dh\\model.ckpt.\n",
      "INFO:tensorflow:step = 5905, loss = 14.300653\n",
      "INFO:tensorflow:global_step/sec: 28.9912\n",
      "INFO:tensorflow:step = 6005, loss = 15.595155 (3.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.1881\n",
      "INFO:tensorflow:step = 6105, loss = 9.951273 (3.000 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.736\n",
      "INFO:tensorflow:step = 6205, loss = 15.421358 (3.067 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.5053\n",
      "INFO:tensorflow:step = 6305, loss = 20.656002 (3.170 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.2385\n",
      "INFO:tensorflow:step = 6405, loss = 13.765383 (3.107 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.2281\n",
      "INFO:tensorflow:step = 6505, loss = 9.613232 (3.085 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.8731\n",
      "INFO:tensorflow:step = 6605, loss = 6.3001595 (2.959 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.5205\n",
      "INFO:tensorflow:step = 6705, loss = 15.910496 (2.891 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.2421\n",
      "INFO:tensorflow:step = 6805, loss = 26.136707 (2.920 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.2413\n",
      "INFO:tensorflow:step = 6905, loss = 10.268213 (3.810 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6983 into C:\\Users\\hrafiq\\AppData\\Local\\Temp\\tmpn6uxr1dh\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 15.900731.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2018-10-01-08:29:58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\hrafiq\\AppData\\Local\\Temp\\tmpn6uxr1dh\\model.ckpt-6983\n",
      "INFO:tensorflow:Finished evaluation at 2018-10-01-08:30:00\n",
      "INFO:tensorflow:Saving dict for global step 6983: accuracy = 0.93333334, accuracy_baseline = 0.60848486, auc = 0.9900336, auc_precision_recall = 0.9836386, average_loss = 0.19590385, global_step = 6983, label/mean = 0.39151517, loss = 24.86472, prediction/mean = 0.46736214\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\hrafiq\\AppData\\Local\\Temp\\tmpn6uxr1dh\\model.ckpt-6983\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b\"C:\\\\Users\\\\hrafiq\\\\AppData\\\\Local\\\\Temp\\\\tmpn6uxr1dh\\\\export\\\\decision\\\\temp-b'1538382602'\\\\saved_model.pb\"\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\hrafiq\\AppData\\Local\\Temp\\tmpn6uxr1dh\\model.ckpt-6983\n",
      "INFO:tensorflow:Saving checkpoints for 6984 into C:\\Users\\hrafiq\\AppData\\Local\\Temp\\tmpn6uxr1dh\\model.ckpt.\n",
      "INFO:tensorflow:step = 6984, loss = 10.28266\n",
      "INFO:tensorflow:global_step/sec: 28.5567\n",
      "INFO:tensorflow:step = 7084, loss = 16.830687 (3.518 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.1133\n",
      "INFO:tensorflow:step = 7184, loss = 22.347357 (2.919 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.9507\n",
      "INFO:tensorflow:step = 7284, loss = 24.486935 (2.951 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.4907\n",
      "INFO:tensorflow:step = 7384, loss = 11.721376 (3.072 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.2144\n",
      "INFO:tensorflow:step = 7484, loss = 16.987389 (3.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.9507\n",
      "INFO:tensorflow:step = 7584, loss = 12.520884 (2.942 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.2313\n",
      "INFO:tensorflow:step = 7684, loss = 2.41743 (3.039 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.4102\n",
      "INFO:tensorflow:step = 7784, loss = 6.7210355 (3.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.7809\n",
      "INFO:tensorflow:step = 7884, loss = 8.814745 (3.241 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7977 into C:\\Users\\hrafiq\\AppData\\Local\\Temp\\tmpn6uxr1dh\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 8.836589.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2018-10-01-08:30:58\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\hrafiq\\AppData\\Local\\Temp\\tmpn6uxr1dh\\model.ckpt-7977\n",
      "INFO:tensorflow:Finished evaluation at 2018-10-01-08:30:59\n",
      "INFO:tensorflow:Saving dict for global step 7977: accuracy = 0.95272726, accuracy_baseline = 0.60848486, auc = 0.99087083, auc_precision_recall = 0.985268, average_loss = 0.16155279, global_step = 7977, label/mean = 0.39151517, loss = 20.504778, prediction/mean = 0.44206446\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\hrafiq\\AppData\\Local\\Temp\\tmpn6uxr1dh\\model.ckpt-7977\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b\"C:\\\\Users\\\\hrafiq\\\\AppData\\\\Local\\\\Temp\\\\tmpn6uxr1dh\\\\export\\\\decision\\\\temp-b'1538382660'\\\\saved_model.pb\"\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\hrafiq\\AppData\\Local\\Temp\\tmpn6uxr1dh\\model.ckpt-7977\n",
      "INFO:tensorflow:Saving checkpoints for 7978 into C:\\Users\\hrafiq\\AppData\\Local\\Temp\\tmpn6uxr1dh\\model.ckpt.\n",
      "INFO:tensorflow:step = 7978, loss = 20.424044\n",
      "INFO:tensorflow:global_step/sec: 32.6533\n",
      "INFO:tensorflow:step = 8078, loss = 14.291502 (3.074 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.7057\n",
      "INFO:tensorflow:step = 8178, loss = 19.571407 (3.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.9169\n",
      "INFO:tensorflow:step = 8278, loss = 22.940575 (3.027 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.7776\n",
      "INFO:tensorflow:step = 8378, loss = 19.090107 (2.800 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.2655\n",
      "INFO:tensorflow:step = 8478, loss = 7.7785196 (2.759 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.7969\n",
      "INFO:tensorflow:step = 8578, loss = 6.4780436 (2.790 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.993\n",
      "INFO:tensorflow:step = 8678, loss = 6.6495695 (2.856 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.3778\n",
      "INFO:tensorflow:step = 8778, loss = 9.053066 (2.830 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.9853\n",
      "INFO:tensorflow:step = 8878, loss = 4.838241 (2.944 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.1968\n",
      "INFO:tensorflow:step = 8978, loss = 10.574569 (2.839 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.1276\n",
      "INFO:tensorflow:step = 9078, loss = 5.55954 (2.773 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 9150 into C:\\Users\\hrafiq\\AppData\\Local\\Temp\\tmpn6uxr1dh\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 11.174138.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2018-10-01-08:31:54\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\hrafiq\\AppData\\Local\\Temp\\tmpn6uxr1dh\\model.ckpt-9150\n",
      "INFO:tensorflow:Finished evaluation at 2018-10-01-08:31:56\n",
      "INFO:tensorflow:Saving dict for global step 9150: accuracy = 0.9460606, accuracy_baseline = 0.60848486, auc = 0.9902834, auc_precision_recall = 0.9841556, average_loss = 0.15492408, global_step = 9150, label/mean = 0.39151517, loss = 19.66344, prediction/mean = 0.44120476\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\hrafiq\\AppData\\Local\\Temp\\tmpn6uxr1dh\\model.ckpt-9150\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b\"C:\\\\Users\\\\hrafiq\\\\AppData\\\\Local\\\\Temp\\\\tmpn6uxr1dh\\\\export\\\\decision\\\\temp-b'1538382717'\\\\saved_model.pb\"\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\hrafiq\\AppData\\Local\\Temp\\tmpn6uxr1dh\\model.ckpt-9150\n",
      "INFO:tensorflow:Saving checkpoints for 9151 into C:\\Users\\hrafiq\\AppData\\Local\\Temp\\tmpn6uxr1dh\\model.ckpt.\n",
      "INFO:tensorflow:step = 9151, loss = 13.143599\n",
      "INFO:tensorflow:global_step/sec: 32.7736\n",
      "INFO:tensorflow:step = 9251, loss = 20.187645 (3.057 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.0451\n",
      "INFO:tensorflow:step = 9351, loss = 9.48539 (3.047 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.4798\n",
      "INFO:tensorflow:step = 9451, loss = 11.317246 (3.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.0667\n",
      "INFO:tensorflow:step = 9551, loss = 17.483088 (2.941 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.5649\n",
      "INFO:tensorflow:step = 9651, loss = 7.3739266 (3.066 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.5206\n",
      "INFO:tensorflow:step = 9751, loss = 4.3165045 (2.903 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.2304\n",
      "INFO:tensorflow:step = 9851, loss = 12.993844 (2.918 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.2154\n",
      "INFO:tensorflow:step = 9951, loss = 7.9029894 (2.833 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.1224\n",
      "INFO:tensorflow:step = 10051, loss = 9.537256 (2.852 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.1341\n",
      "INFO:tensorflow:step = 10151, loss = 12.033855 (2.762 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.95\n",
      "INFO:tensorflow:step = 10251, loss = 9.979825 (2.864 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10251 into C:\\Users\\hrafiq\\AppData\\Local\\Temp\\tmpn6uxr1dh\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 9.979825.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2018-10-01-08:32:51\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\hrafiq\\AppData\\Local\\Temp\\tmpn6uxr1dh\\model.ckpt-10251\n",
      "INFO:tensorflow:Finished evaluation at 2018-10-01-08:32:54\n",
      "INFO:tensorflow:Saving dict for global step 10251: accuracy = 0.9442424, accuracy_baseline = 0.60848486, auc = 0.9901231, auc_precision_recall = 0.9838781, average_loss = 0.16714822, global_step = 10251, label/mean = 0.39151517, loss = 21.214966, prediction/mean = 0.44596997\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\hrafiq\\AppData\\Local\\Temp\\tmpn6uxr1dh\\model.ckpt-10251\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b\"C:\\\\Users\\\\hrafiq\\\\AppData\\\\Local\\\\Temp\\\\tmpn6uxr1dh\\\\export\\\\decision\\\\temp-b'1538382775'\\\\saved_model.pb\"\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\hrafiq\\AppData\\Local\\Temp\\tmpn6uxr1dh\\model.ckpt-10251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 10252 into C:\\Users\\hrafiq\\AppData\\Local\\Temp\\tmpn6uxr1dh\\model.ckpt.\n",
      "INFO:tensorflow:step = 10252, loss = 5.262746\n",
      "INFO:tensorflow:global_step/sec: 32.908\n",
      "INFO:tensorflow:step = 10352, loss = 12.697644 (3.060 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.3567\n",
      "INFO:tensorflow:step = 10452, loss = 14.029115 (3.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.61\n",
      "INFO:tensorflow:step = 10552, loss = 11.35173 (3.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.067\n",
      "INFO:tensorflow:step = 10652, loss = 17.46596 (3.024 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.5234\n",
      "INFO:tensorflow:step = 10752, loss = 7.659112 (3.412 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.7814\n",
      "INFO:tensorflow:step = 10852, loss = 8.512815 (3.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.3065\n",
      "INFO:tensorflow:step = 10952, loss = 8.721714 (2.913 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.4271\n",
      "INFO:tensorflow:step = 11052, loss = 4.2872777 (2.992 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.0881\n",
      "INFO:tensorflow:step = 11152, loss = 3.370947 (3.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.5901\n",
      "INFO:tensorflow:step = 11252, loss = 6.3527107 (2.888 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.8524\n",
      "INFO:tensorflow:step = 11352, loss = 6.8553686 (2.866 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 11354 into C:\\Users\\hrafiq\\AppData\\Local\\Temp\\tmpn6uxr1dh\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 8.4658985.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2018-10-01-08:33:48\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\hrafiq\\AppData\\Local\\Temp\\tmpn6uxr1dh\\model.ckpt-11354\n",
      "INFO:tensorflow:Finished evaluation at 2018-10-01-08:33:50\n",
      "INFO:tensorflow:Saving dict for global step 11354: accuracy = 0.9412121, accuracy_baseline = 0.60848486, auc = 0.9903898, auc_precision_recall = 0.9849856, average_loss = 0.16299261, global_step = 11354, label/mean = 0.39151517, loss = 20.687523, prediction/mean = 0.4428999\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\hrafiq\\AppData\\Local\\Temp\\tmpn6uxr1dh\\model.ckpt-11354\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b\"C:\\\\Users\\\\hrafiq\\\\AppData\\\\Local\\\\Temp\\\\tmpn6uxr1dh\\\\export\\\\decision\\\\temp-b'1538382832'\\\\saved_model.pb\"\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\hrafiq\\AppData\\Local\\Temp\\tmpn6uxr1dh\\model.ckpt-11354\n",
      "INFO:tensorflow:Saving checkpoints for 11355 into C:\\Users\\hrafiq\\AppData\\Local\\Temp\\tmpn6uxr1dh\\model.ckpt.\n",
      "INFO:tensorflow:step = 11355, loss = 6.4850454\n",
      "INFO:tensorflow:global_step/sec: 32.4854\n",
      "INFO:tensorflow:step = 11455, loss = 16.742477 (3.084 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.0779\n",
      "INFO:tensorflow:step = 11555, loss = 17.042055 (3.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.1108\n",
      "INFO:tensorflow:step = 11655, loss = 13.779463 (3.839 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.2448\n",
      "INFO:tensorflow:step = 11755, loss = 2.8484523 (3.744 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.4823\n",
      "INFO:tensorflow:step = 11855, loss = 13.807457 (4.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.5127\n",
      "INFO:tensorflow:step = 11955, loss = 3.2068276 (4.062 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.6428\n",
      "INFO:tensorflow:step = 12055, loss = 3.841934 (4.414 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.0494\n",
      "INFO:tensorflow:step = 12155, loss = 10.755914 (3.837 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 12235 into C:\\Users\\hrafiq\\AppData\\Local\\Temp\\tmpn6uxr1dh\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 16.566927.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2018-10-01-08:34:46\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\hrafiq\\AppData\\Local\\Temp\\tmpn6uxr1dh\\model.ckpt-12235\n",
      "INFO:tensorflow:Finished evaluation at 2018-10-01-08:34:48\n",
      "INFO:tensorflow:Saving dict for global step 12235: accuracy = 0.9509091, accuracy_baseline = 0.60848486, auc = 0.9897038, auc_precision_recall = 0.9835615, average_loss = 0.15899591, global_step = 12235, label/mean = 0.39151517, loss = 20.18025, prediction/mean = 0.43626046\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\hrafiq\\AppData\\Local\\Temp\\tmpn6uxr1dh\\model.ckpt-12235\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b\"C:\\\\Users\\\\hrafiq\\\\AppData\\\\Local\\\\Temp\\\\tmpn6uxr1dh\\\\export\\\\decision\\\\temp-b'1538382889'\\\\saved_model.pb\"\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\hrafiq\\AppData\\Local\\Temp\\tmpn6uxr1dh\\model.ckpt-12235\n",
      "INFO:tensorflow:Saving checkpoints for 12236 into C:\\Users\\hrafiq\\AppData\\Local\\Temp\\tmpn6uxr1dh\\model.ckpt.\n",
      "INFO:tensorflow:step = 12236, loss = 10.300571\n",
      "INFO:tensorflow:global_step/sec: 32.3012\n",
      "INFO:tensorflow:step = 12336, loss = 17.992062 (3.094 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.3836\n",
      "INFO:tensorflow:step = 12436, loss = 9.576149 (3.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.7511\n",
      "INFO:tensorflow:step = 12536, loss = 13.942844 (3.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.1264\n",
      "INFO:tensorflow:step = 12636, loss = 8.972276 (3.662 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.8078\n",
      "INFO:tensorflow:step = 12736, loss = 24.700655 (3.066 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.4853\n",
      "INFO:tensorflow:step = 12836, loss = 3.9371502 (3.061 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.7347\n",
      "INFO:tensorflow:step = 12936, loss = 5.8137555 (3.382 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.0495\n",
      "INFO:tensorflow:step = 13036, loss = 3.4268708 (3.578 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.3109\n",
      "INFO:tensorflow:step = 13136, loss = 3.8602953 (3.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.2486\n",
      "INFO:tensorflow:step = 13236, loss = 7.74676 (3.009 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 13260 into C:\\Users\\hrafiq\\AppData\\Local\\Temp\\tmpn6uxr1dh\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 10.230804.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2018-10-01-08:35:49\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\hrafiq\\AppData\\Local\\Temp\\tmpn6uxr1dh\\model.ckpt-13260\n",
      "INFO:tensorflow:Finished evaluation at 2018-10-01-08:35:51\n",
      "INFO:tensorflow:Saving dict for global step 13260: accuracy = 0.9472727, accuracy_baseline = 0.60848486, auc = 0.9894725, auc_precision_recall = 0.98314077, average_loss = 0.16334221, global_step = 13260, label/mean = 0.39151517, loss = 20.731895, prediction/mean = 0.4434403\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\hrafiq\\AppData\\Local\\Temp\\tmpn6uxr1dh\\model.ckpt-13260\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b\"C:\\\\Users\\\\hrafiq\\\\AppData\\\\Local\\\\Temp\\\\tmpn6uxr1dh\\\\export\\\\decision\\\\temp-b'1538382953'\\\\saved_model.pb\"\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\hrafiq\\AppData\\Local\\Temp\\tmpn6uxr1dh\\model.ckpt-13260\n",
      "INFO:tensorflow:Saving checkpoints for 13261 into C:\\Users\\hrafiq\\AppData\\Local\\Temp\\tmpn6uxr1dh\\model.ckpt.\n",
      "INFO:tensorflow:step = 13261, loss = 7.3494463\n",
      "INFO:tensorflow:global_step/sec: 27.3533\n",
      "INFO:tensorflow:step = 13361, loss = 13.039634 (3.667 sec)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-134-766b84af4917>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Final trainer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_and_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_train_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-132-2a3347ac4358>\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[1;34m(output_dir, num_train_steps, train_file, eval_file)\u001b[0m\n\u001b[0;32m     29\u001b[0m                                     \u001b[0mstart_delay_secs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m# start evaluating after N seconds,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m                                     throttle_secs = 45)  # evaluate every N seconds\n\u001b[1;32m---> 31\u001b[1;33m     \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_and_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_spec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_spec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\hrafiq\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\estimator\\training.py\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[1;34m(estimator, train_spec, eval_spec)\u001b[0m\n\u001b[0;32m    428\u001b[0m       config.task_type != run_config_lib.TaskType.EVALUATOR):\n\u001b[0;32m    429\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Running training and evaluation locally (non-distributed).'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 430\u001b[1;33m     \u001b[0mexecutor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_local\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    431\u001b[0m     \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hrafiq\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\estimator\\training.py\u001b[0m in \u001b[0;36mrun_local\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    607\u001b[0m           \u001b[0minput_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    608\u001b[0m           \u001b[0mmax_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 609\u001b[1;33m           hooks=train_hooks)\n\u001b[0m\u001b[0;32m    610\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m       \u001b[1;31m# Final export signal: For any eval result with global_step >= train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hrafiq\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[0;32m    300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m     \u001b[0msaving_listeners\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loss for final step: %s.'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hrafiq\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m    781\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 783\u001b[1;33m           \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    784\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    785\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hrafiq\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    519\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m                           run_metadata=run_metadata)\n\u001b[0m\u001b[0;32m    522\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mshould_stop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hrafiq\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    890\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 892\u001b[1;33m                               run_metadata=run_metadata)\n\u001b[0m\u001b[0;32m    893\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[1;32mc:\\users\\hrafiq\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    950\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    951\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 952\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    953\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    954\u001b[0m       \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hrafiq\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1022\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1023\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1024\u001b[1;33m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[0;32m   1025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1026\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hrafiq\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    825\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    826\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 827\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    828\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    829\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hrafiq\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    887\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 889\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    890\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hrafiq\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1120\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1121\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hrafiq\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1315\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1317\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1318\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1319\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hrafiq\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1321\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1322\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1323\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1324\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hrafiq\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1302\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1304\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Final trainer\n",
    "train_and_evaluate(None, num_train_steps=50000, train_file=train_file, eval_file=eval_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Only DNN Deep wide classifier\n",
    "# def get_deep_wide_features():\n",
    "#     werks_c = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "#             key='WERKS',\n",
    "#             vocabulary_list=['ML01','ML02','ML03'])\n",
    "#     scenario_c = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "#             key='SCENARIO',\n",
    "#             vocabulary_list=['1','2','3','4'])\n",
    "#     ktokk_c = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "#             key='KTOKK',\n",
    "#             vocabulary_list=['1','2'])    \n",
    "#     vstatu_c = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "#             key='VSTATU',\n",
    "#             vocabulary_list=['1','2'])\n",
    "#     ekorg_c = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "#             key='EKORG',\n",
    "#             vocabulary_list=['1','2'])   \n",
    "#     ekgrp_c = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "#             key='EKGRP',\n",
    "#             vocabulary_list=['A','B','C'])\n",
    "#     deep_columns = [\n",
    "#         tf.feature_column.numeric_column('VPATD'),\n",
    "#         tf.feature_column.numeric_column(\"TOTGRQTY\"),\n",
    "#         tf.feature_column.numeric_column(\"TOTIRQTY\"),\n",
    "#         tf.feature_column.numeric_column(\"NODLGR\"),\n",
    "#         tf.feature_column.numeric_column(\"NODLIR\"),\n",
    "#         tf.feature_column.numeric_column(\"DIFGRIRD\"),\n",
    "#         tf.feature_column.numeric_column(\"DIFGRIRV\")\n",
    "#     ]\n",
    "#     wide_columns = [\n",
    "#         tf.feature_column.indicator_column(werks_c),\n",
    "#         tf.feature_column.indicator_column(scenario_c),\n",
    "#         tf.feature_column.indicator_column(ktokk_c),\n",
    "#         tf.feature_column.indicator_column(vstatu_c),\n",
    "#         tf.feature_column.indicator_column(ekorg_c),\n",
    "#         tf.feature_column.indicator_column(ekgrp_c),\n",
    "#     ]\n",
    "#     return deep_columns, wide_columns\n",
    "\n",
    "# def train_and_evaluate_deep(output_dir, num_train_steps):    \n",
    "# ##### Create Canned estimator instance\n",
    "#     #Get features\n",
    "#     deep, wide = get_deep_wide_features()\n",
    "\n",
    "#     estimator = tf.estimator.DNNLinearCombinedClassifier(\n",
    "#                                     linear_feature_columns = wide,\n",
    "#                                     dnn_feature_columns = deep,\n",
    "#                                     n_classes=2,\n",
    "#                                     dnn_hidden_units = [32,64,64,64,64,64,\n",
    "#                                                         64,64,64,64,64,64,\n",
    "#                                                         64,64,64,64,64,64,\n",
    "#                                                         32],\n",
    "#                                     dnn_dropout = 0.1,\n",
    "#                                     dnn_optimizer=tf.train.AdamOptimizer(learning_rate=0.0001))\n",
    "#     train_spec = tf.estimator.TrainSpec(input_fn = make_input_fn(traindf, None), \n",
    "#                                       max_steps = num_train_steps)\n",
    "#     exp = tf.estimator.LatestExporter(\"decision\", serving_fn)\n",
    "#     eval_spec = tf.estimator.EvalSpec(input_fn = make_input_fn(evaldf, 1), \n",
    "#                                     steps = None, \n",
    "#                                     exporters = exp,\n",
    "#                                     start_delay_secs = 1, # start evaluating after N seconds, \n",
    "#                                     throttle_secs = 40)  # evaluate every N seconds\n",
    "#     tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #setup exponential decay function for learning rates\n",
    "# def get_global_step():\n",
    "#     if tf.train.get_global_step() is None:\n",
    "#         return 1\n",
    "#     else:\n",
    "#         return tf.train.get_global_step()\n",
    "\n",
    "# def get_exp_decay_optimizer():\n",
    "#     def exp_decay(global_step=global_step):\n",
    "#         return tf.train.exponential_decay(\n",
    "#           learning_rate=0.0001, global_step=global_step,\n",
    "#           decay_steps=100, decay_rate=0.8, staircase=True)\n",
    "#     # use customized decay function in learning_rate\n",
    "#     return tf.train.AdagradOptimizer(learning_rate=exp_decay(tf.train.get_global_step()))\n",
    "\n",
    "# # setup stepwise decay function for learning rates\n",
    "# def get_stepw_decay_optimizer2():\n",
    "#     def step_decay():\n",
    "#         return tf.train.piecewise_constant(get_global_step(), \n",
    "#                                            boundaries=[10000,20000,50000,100000], \n",
    "#                                            values=[0.001,0.0005,0.0001,0.00005,0.00002])\n",
    "#     # use customized decay function in learning_rate\n",
    "#     return tf.train.AdamOptimizer(learning_rate=step_decay)#,epsilon=0.001)\n",
    "\n",
    "# # setup stepwise decay function for learning rates\n",
    "# def get_stepw_decay_optimizer():\n",
    "#     def step_decay(global_step):\n",
    "#         return tf.train.piecewise_constant(global_step, boundaries=[10000,20000,50000,100000], values=[0.001,0.0005,0.0001,0.00005,0.00002])\n",
    "#                                          # use customized decay function in learning_rate\n",
    "#     return tf.train.AdamOptimizer(learning_rate=step_decay(tf.train.get_global_step()))#,epsilon=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score = classifier.evaluate(input_fn=get_input_fn(training_set, num_epochs=1, shuffle=False))[\"accuracy\"]\n",
    "print(\"\\nTrain Accuracy: {0:f}\\n\".format(accuracy_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score = classifier.evaluate(input_fn=get_validation_input_fn(test_set, num_epochs=1, shuffle=False))[\"accuracy\"]\n",
    "print(\"\\nTest Accuracy: {0:f}\\n\".format(accuracy_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run model on Prediction data set\n",
    "predictions = classifier.predict_classes(input_fn=get_prediction_input_fn(test_set))\n",
    "for p in list(predictions):\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in list(test_set['STATUS']):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
