{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4"
    },
    "colab": {
      "name": "TF 2.0 Estimator - GRIR - Tf.Dataset + FeatEngg.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbmyXUGrCsDG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 665
        },
        "outputId": "87d57259-4608-4b3f-fd79-f7f1c7d051fb"
      },
      "source": [
        "%%bash\n",
        "pip install --upgrade tensorflow-gpu"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu\n",
            "  Downloading https://files.pythonhosted.org/packages/25/44/47f0722aea081697143fbcf5d2aa60d1aee4aaacb5869aee2b568974777b/tensorflow_gpu-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (380.8MB)\n",
            "Requirement already satisfied, skipping upgrade: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.2.2)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.33.6)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.10.0)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.8.0)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.8.1)\n",
            "Collecting tensorflow-estimator<2.1.0,>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/fc/08/8b927337b7019c374719145d1dceba21a8bb909b93b1ad6f8fb7d22c1ca1/tensorflow_estimator-2.0.1-py2.py3-none-any.whl (449kB)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.1.7)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.11.2)\n",
            "Collecting tensorboard<2.1.0,>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/9b/a6/e8ffa4e2ddb216449d34cfcb825ebb38206bee5c4553d69e7bc8bc2c5d64/tensorboard-2.0.0-py3-none-any.whl (3.8MB)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.0.8)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.17.3)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu) (41.4.0)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (3.1.1)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu) (2.8.0)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, tensorflow-gpu\n",
            "  Found existing installation: tensorflow-estimator 1.15.1\n",
            "    Uninstalling tensorflow-estimator-1.15.1:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "Successfully installed tensorboard-2.0.0 tensorflow-estimator-2.0.1 tensorflow-gpu-2.0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR: tensorflow 1.15.0 has requirement tensorboard<1.16.0,>=1.15.0, but you'll have tensorboard 2.0.0 which is incompatible.\n",
            "ERROR: tensorflow 1.15.0 has requirement tensorflow-estimator==1.15.1, but you'll have tensorflow-estimator 2.0.1 which is incompatible.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aw_k7nsP_Jd5",
        "colab_type": "code",
        "outputId": "103b98b7-30f2-4e7a-eaa7-fdf16923f40d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import scipy\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "from tensorflow.python.training import training_util\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44nC_gVrCl7A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "f5787a60-9dd5-46c1-b599-8190d65823e8"
      },
      "source": [
        "#Mount GDrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prZMoUGODQyQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Copy data to local\n",
        "%%bash\n",
        "cp '/content/drive/My Drive/Colab Notebooks/TF Keras 2.0 GRIR - CMLE + FeatEngg/GRIR_GCP_Data.csv' 'GRIR_GCP_Data.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVeqN-Fl_JeD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(\"GRIR_GCP_Data.csv\", sep=\",\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIaVWu6d_JeM",
        "colab_type": "code",
        "outputId": "9cfd62a2-1b6a-4df6-db6a-cd9e3b92958a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "source": [
        "df.head(10)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>WERKS</th>\n",
              "      <th>SCENARIO</th>\n",
              "      <th>KTOKK</th>\n",
              "      <th>VSTATU</th>\n",
              "      <th>VPATD</th>\n",
              "      <th>EKORG</th>\n",
              "      <th>EKGRP</th>\n",
              "      <th>TOTGRQTY</th>\n",
              "      <th>TOTIRQTY</th>\n",
              "      <th>NODLGR</th>\n",
              "      <th>NODLIR</th>\n",
              "      <th>DIFGRIRD</th>\n",
              "      <th>DIFGRIRV</th>\n",
              "      <th>STATUS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ML01</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>30</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>0</td>\n",
              "      <td>80</td>\n",
              "      <td>0</td>\n",
              "      <td>90</td>\n",
              "      <td>-80</td>\n",
              "      <td>-38100</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ML01</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>30</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>0</td>\n",
              "      <td>107</td>\n",
              "      <td>0</td>\n",
              "      <td>177</td>\n",
              "      <td>-107</td>\n",
              "      <td>-41600</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ML01</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>30</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>0</td>\n",
              "      <td>107</td>\n",
              "      <td>0</td>\n",
              "      <td>152</td>\n",
              "      <td>-107</td>\n",
              "      <td>-27600</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ML01</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>30</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>0</td>\n",
              "      <td>96</td>\n",
              "      <td>0</td>\n",
              "      <td>79</td>\n",
              "      <td>-96</td>\n",
              "      <td>-13800</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ML01</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>30</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>0</td>\n",
              "      <td>146</td>\n",
              "      <td>0</td>\n",
              "      <td>192</td>\n",
              "      <td>-146</td>\n",
              "      <td>-73500</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>ML01</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>60</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>0</td>\n",
              "      <td>189</td>\n",
              "      <td>0</td>\n",
              "      <td>139</td>\n",
              "      <td>-189</td>\n",
              "      <td>-26600</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>ML01</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>60</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>0</td>\n",
              "      <td>183</td>\n",
              "      <td>0</td>\n",
              "      <td>48</td>\n",
              "      <td>-183</td>\n",
              "      <td>-69200</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>ML01</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>60</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>0</td>\n",
              "      <td>159</td>\n",
              "      <td>0</td>\n",
              "      <td>195</td>\n",
              "      <td>-159</td>\n",
              "      <td>-73600</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>ML01</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>60</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>0</td>\n",
              "      <td>185</td>\n",
              "      <td>0</td>\n",
              "      <td>79</td>\n",
              "      <td>-185</td>\n",
              "      <td>-59500</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>ML01</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>60</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>0</td>\n",
              "      <td>91</td>\n",
              "      <td>0</td>\n",
              "      <td>168</td>\n",
              "      <td>-91</td>\n",
              "      <td>-4700</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  WERKS  SCENARIO  KTOKK  VSTATU  ...  NODLIR  DIFGRIRD DIFGRIRV  STATUS\n",
              "0  ML01         3      1       1  ...      90       -80   -38100       1\n",
              "1  ML01         3      1       1  ...     177      -107   -41600       0\n",
              "2  ML01         3      1       1  ...     152      -107   -27600       1\n",
              "3  ML01         3      1       1  ...      79       -96   -13800       1\n",
              "4  ML01         3      1       1  ...     192      -146   -73500       0\n",
              "5  ML01         3      1       1  ...     139      -189   -26600       1\n",
              "6  ML01         3      1       1  ...      48      -183   -69200       0\n",
              "7  ML01         3      1       1  ...     195      -159   -73600       0\n",
              "8  ML01         3      1       1  ...      79      -185   -59500       0\n",
              "9  ML01         3      1       1  ...     168       -91    -4700       1\n",
              "\n",
              "[10 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zv0m6eiT_JeU",
        "colab_type": "code",
        "outputId": "8a7eba90-fa9a-4813-a8bd-c52d8faafd0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SCENARIO</th>\n",
              "      <th>KTOKK</th>\n",
              "      <th>VSTATU</th>\n",
              "      <th>VPATD</th>\n",
              "      <th>EKORG</th>\n",
              "      <th>TOTGRQTY</th>\n",
              "      <th>TOTIRQTY</th>\n",
              "      <th>NODLGR</th>\n",
              "      <th>NODLIR</th>\n",
              "      <th>DIFGRIRD</th>\n",
              "      <th>DIFGRIRV</th>\n",
              "      <th>STATUS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>8279.000000</td>\n",
              "      <td>8279.000000</td>\n",
              "      <td>8279.000000</td>\n",
              "      <td>8279.000000</td>\n",
              "      <td>8279.000000</td>\n",
              "      <td>8279.000000</td>\n",
              "      <td>8279.000000</td>\n",
              "      <td>8279.000000</td>\n",
              "      <td>8279.000000</td>\n",
              "      <td>8279.000000</td>\n",
              "      <td>8279.000000</td>\n",
              "      <td>8279.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2.565286</td>\n",
              "      <td>1.497886</td>\n",
              "      <td>1.119097</td>\n",
              "      <td>60.264525</td>\n",
              "      <td>1.333374</td>\n",
              "      <td>65.938398</td>\n",
              "      <td>94.098563</td>\n",
              "      <td>103.070419</td>\n",
              "      <td>89.499819</td>\n",
              "      <td>-28.160164</td>\n",
              "      <td>-6716.334461</td>\n",
              "      <td>0.391835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.096595</td>\n",
              "      <td>0.500026</td>\n",
              "      <td>0.323922</td>\n",
              "      <td>24.387448</td>\n",
              "      <td>0.471447</td>\n",
              "      <td>62.960829</td>\n",
              "      <td>62.449709</td>\n",
              "      <td>81.968329</td>\n",
              "      <td>75.005213</td>\n",
              "      <td>63.224655</td>\n",
              "      <td>22797.380084</td>\n",
              "      <td>0.488190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-200.000000</td>\n",
              "      <td>-75000.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>54.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>-56.000000</td>\n",
              "      <td>-9600.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>55.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>112.000000</td>\n",
              "      <td>82.000000</td>\n",
              "      <td>-2.000000</td>\n",
              "      <td>-546.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>4.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>90.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>121.000000</td>\n",
              "      <td>146.000000</td>\n",
              "      <td>172.000000</td>\n",
              "      <td>154.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>5482.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>4.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>90.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>268.000000</td>\n",
              "      <td>242.000000</td>\n",
              "      <td>74.000000</td>\n",
              "      <td>59200.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          SCENARIO        KTOKK  ...      DIFGRIRV       STATUS\n",
              "count  8279.000000  8279.000000  ...   8279.000000  8279.000000\n",
              "mean      2.565286     1.497886  ...  -6716.334461     0.391835\n",
              "std       1.096595     0.500026  ...  22797.380084     0.488190\n",
              "min       1.000000     1.000000  ... -75000.000000     0.000000\n",
              "25%       2.000000     1.000000  ...  -9600.000000     0.000000\n",
              "50%       3.000000     1.000000  ...   -546.000000     0.000000\n",
              "75%       4.000000     2.000000  ...   5482.000000     1.000000\n",
              "max       4.000000     2.000000  ...  59200.000000     1.000000\n",
              "\n",
              "[8 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKox01CN_JeZ",
        "colab_type": "code",
        "outputId": "464c617d-8353-4bf5-8822-952708387f67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "df.columns"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['WERKS', 'SCENARIO', 'KTOKK', 'VSTATU', 'VPATD', 'EKORG', 'EKGRP',\n",
              "       'TOTGRQTY', 'TOTIRQTY', 'NODLGR', 'NODLIR', 'DIFGRIRD', 'DIFGRIRV',\n",
              "       'STATUS'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HodTmX7J_Jef",
        "colab_type": "code",
        "outputId": "a3f19e0e-7944-4143-bff4-b9269ca71271",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "#Facet1\n",
        "g = sns.FacetGrid(df, col=\"SCENARIO\")\n",
        "g = g.map(plt.hist, \"TOTGRQTY\")\n",
        "plt.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1gAAADQCAYAAAAalMCAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 864x216 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HElyPLN1_Jej",
        "colab_type": "code",
        "outputId": "966a5d55-043b-4250-9a73-a5525f31fead",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "#Facet1\n",
        "g = sns.FacetGrid(df, col=\"SCENARIO\")\n",
        "g = g.map(plt.hist, \"TOTIRQTY\")\n",
        "plt.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1gAAADQCAYAAAAalMCAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 864x216 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E26qooOX_Jen",
        "colab_type": "code",
        "outputId": "41b47f02-f1e6-4945-e375-f5b5aaa78b97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "#Filter out scenario = 3 ( It has TOTGRQTY == 0 )\n",
        "df_s1 = df[df['SCENARIO'].eq(3) & df['TOTGRQTY'].eq(0)]\n",
        "df_s1.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>WERKS</th>\n",
              "      <th>SCENARIO</th>\n",
              "      <th>KTOKK</th>\n",
              "      <th>VSTATU</th>\n",
              "      <th>VPATD</th>\n",
              "      <th>EKORG</th>\n",
              "      <th>EKGRP</th>\n",
              "      <th>TOTGRQTY</th>\n",
              "      <th>TOTIRQTY</th>\n",
              "      <th>NODLGR</th>\n",
              "      <th>NODLIR</th>\n",
              "      <th>DIFGRIRD</th>\n",
              "      <th>DIFGRIRV</th>\n",
              "      <th>STATUS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ML01</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>30</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>0</td>\n",
              "      <td>80</td>\n",
              "      <td>0</td>\n",
              "      <td>90</td>\n",
              "      <td>-80</td>\n",
              "      <td>-38100</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ML01</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>30</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>0</td>\n",
              "      <td>107</td>\n",
              "      <td>0</td>\n",
              "      <td>177</td>\n",
              "      <td>-107</td>\n",
              "      <td>-41600</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ML01</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>30</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>0</td>\n",
              "      <td>107</td>\n",
              "      <td>0</td>\n",
              "      <td>152</td>\n",
              "      <td>-107</td>\n",
              "      <td>-27600</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ML01</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>30</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>0</td>\n",
              "      <td>96</td>\n",
              "      <td>0</td>\n",
              "      <td>79</td>\n",
              "      <td>-96</td>\n",
              "      <td>-13800</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ML01</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>30</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>0</td>\n",
              "      <td>146</td>\n",
              "      <td>0</td>\n",
              "      <td>192</td>\n",
              "      <td>-146</td>\n",
              "      <td>-73500</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  WERKS  SCENARIO  KTOKK  VSTATU  ...  NODLIR  DIFGRIRD DIFGRIRV  STATUS\n",
              "0  ML01         3      1       1  ...      90       -80   -38100       1\n",
              "1  ML01         3      1       1  ...     177      -107   -41600       0\n",
              "2  ML01         3      1       1  ...     152      -107   -27600       1\n",
              "3  ML01         3      1       1  ...      79       -96   -13800       1\n",
              "4  ML01         3      1       1  ...     192      -146   -73500       0\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z55eZEyw_Jet",
        "colab_type": "code",
        "outputId": "959bc5f6-960f-4e2b-ab86-a45fdff9d208",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        }
      },
      "source": [
        "#Mark some columns as categorical so that TF treats them as categorical\n",
        "for col_cat in ['SCENARIO','KTOKK','VSTATU','EKORG']:\n",
        "    df[col_cat] = df[col_cat].astype('str') #Very important to keep this as STR -> Tensorflow treats only STR as categorical\n",
        "    \n",
        "df.info()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 8279 entries, 0 to 8278\n",
            "Data columns (total 14 columns):\n",
            "WERKS       8279 non-null object\n",
            "SCENARIO    8279 non-null object\n",
            "KTOKK       8279 non-null object\n",
            "VSTATU      8279 non-null object\n",
            "VPATD       8279 non-null int64\n",
            "EKORG       8279 non-null object\n",
            "EKGRP       8279 non-null object\n",
            "TOTGRQTY    8279 non-null int64\n",
            "TOTIRQTY    8279 non-null int64\n",
            "NODLGR      8279 non-null int64\n",
            "NODLIR      8279 non-null int64\n",
            "DIFGRIRD    8279 non-null int64\n",
            "DIFGRIRV    8279 non-null int64\n",
            "STATUS      8279 non-null int64\n",
            "dtypes: int64(8), object(6)\n",
            "memory usage: 905.6+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5etI4hqJ_Jez",
        "colab_type": "code",
        "outputId": "a61100a6-8639-4373-c7d5-965bcc2336c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "source": [
        "#Split dataset -> Split 10 times and choose the one with best P values( Significance test )\n",
        "p_res = {}\n",
        "t_res = []\n",
        "for i in range(10):\n",
        "    np.random.seed(seed=i) #makes result reproducible\n",
        "    msk = np.random.rand(len(df)) < 0.8\n",
        "    X_train = df[msk]\n",
        "    X_test = df[~msk]\n",
        "\n",
        "    #Run Significance Tests on both the distributions( Train and Test ) for all numerical attributes\n",
        "    p_res = {}\n",
        "    for c_ in X_train.columns:\n",
        "        if not X_train[c_].dtype == 'object':\n",
        "            try:\n",
        "                _, a = scipy.stats.ks_2samp(X_train[c_].values,X_test[c_].values)\n",
        "                #print('P-value for column {} is {}'.format(c_.upper(), a))\n",
        "                p_res['Random'] = i\n",
        "                p_res[c_] = a\n",
        "            except:\n",
        "                p_res['Random'] = i\n",
        "                p_res[c_] = 'Error'\n",
        "    t_res.append(p_res)\n",
        "\n",
        "p_df = pd.DataFrame(t_res)\n",
        "p_df"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Random</th>\n",
              "      <th>VPATD</th>\n",
              "      <th>TOTGRQTY</th>\n",
              "      <th>TOTIRQTY</th>\n",
              "      <th>NODLGR</th>\n",
              "      <th>NODLIR</th>\n",
              "      <th>DIFGRIRD</th>\n",
              "      <th>DIFGRIRV</th>\n",
              "      <th>STATUS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Random  VPATD  TOTGRQTY  TOTIRQTY  ...  NODLIR  DIFGRIRD  DIFGRIRV  STATUS\n",
              "0       0    1.0       1.0       1.0  ...     1.0       1.0       1.0     1.0\n",
              "1       1    1.0       1.0       1.0  ...     1.0       1.0       1.0     1.0\n",
              "2       2    1.0       1.0       1.0  ...     1.0       1.0       1.0     1.0\n",
              "3       3    1.0       1.0       1.0  ...     1.0       1.0       1.0     1.0\n",
              "4       4    1.0       1.0       1.0  ...     1.0       1.0       1.0     1.0\n",
              "5       5    1.0       1.0       1.0  ...     1.0       1.0       1.0     1.0\n",
              "6       6    1.0       1.0       1.0  ...     1.0       1.0       1.0     1.0\n",
              "7       7    1.0       1.0       1.0  ...     1.0       1.0       1.0     1.0\n",
              "8       8    1.0       1.0       1.0  ...     1.0       1.0       1.0     1.0\n",
              "9       9    1.0       1.0       1.0  ...     1.0       1.0       1.0     1.0\n",
              "\n",
              "[10 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxWOjv-3_Je4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Prepare train and test data set\n",
        "np.random.seed(seed=2) #makes result reproducible\n",
        "msk = np.random.rand(len(df)) < 0.8\n",
        "traindf = df[msk]\n",
        "evaldf = df[~msk]\n",
        "#evaldf[evaldf['STATUS'] == 1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BWytDWF_Je9",
        "colab_type": "code",
        "outputId": "e0a23273-79cb-4e4d-ec1c-f51a922c4fbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        }
      },
      "source": [
        "traindf.info()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 6629 entries, 0 to 8278\n",
            "Data columns (total 14 columns):\n",
            "WERKS       6629 non-null object\n",
            "SCENARIO    6629 non-null object\n",
            "KTOKK       6629 non-null object\n",
            "VSTATU      6629 non-null object\n",
            "VPATD       6629 non-null int64\n",
            "EKORG       6629 non-null object\n",
            "EKGRP       6629 non-null object\n",
            "TOTGRQTY    6629 non-null int64\n",
            "TOTIRQTY    6629 non-null int64\n",
            "NODLGR      6629 non-null int64\n",
            "NODLIR      6629 non-null int64\n",
            "DIFGRIRD    6629 non-null int64\n",
            "DIFGRIRV    6629 non-null int64\n",
            "STATUS      6629 non-null int64\n",
            "dtypes: int64(8), object(6)\n",
            "memory usage: 776.8+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTlicUey_JfC",
        "colab_type": "code",
        "outputId": "54d51b43-1c37-4eae-a08d-3dd271df28fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        }
      },
      "source": [
        "evaldf.info()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1650 entries, 16 to 8272\n",
            "Data columns (total 14 columns):\n",
            "WERKS       1650 non-null object\n",
            "SCENARIO    1650 non-null object\n",
            "KTOKK       1650 non-null object\n",
            "VSTATU      1650 non-null object\n",
            "VPATD       1650 non-null int64\n",
            "EKORG       1650 non-null object\n",
            "EKGRP       1650 non-null object\n",
            "TOTGRQTY    1650 non-null int64\n",
            "TOTIRQTY    1650 non-null int64\n",
            "NODLGR      1650 non-null int64\n",
            "NODLIR      1650 non-null int64\n",
            "DIFGRIRD    1650 non-null int64\n",
            "DIFGRIRV    1650 non-null int64\n",
            "STATUS      1650 non-null int64\n",
            "dtypes: int64(8), object(6)\n",
            "memory usage: 193.4+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRYzPyO7_JfF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Files To be used in Tensorflow pipeline dataset API\n",
        "traindf.to_csv(\"grir_train.csv\", index=False, header=False)\n",
        "evaldf.to_csv(\"grir_eval.csv\", index=False, header=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCPrxoyQ_JfI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######################################## Tensorflow Pipeline building and Modeling ############################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uv2BtsdYNZZE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def feature_engg_features(features):\n",
        "  #Add new features\n",
        "  features['grminusirbyvpatd'] = ( features['TOTGRQTY'] - features['TOTIRQTY'] ) / features['VPATD']\n",
        "\n",
        "  return(features)\n",
        "\n",
        "def feature_engg(features, label):\n",
        "  #Add new features\n",
        "  features = feature_engg_features(features)\n",
        "\n",
        "  return(features, label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pgct6iSr_Jfl",
        "colab_type": "code",
        "outputId": "fd8a4e1e-cdc3-4792-f61d-145bec6fd389",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "traindf.columns"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['WERKS', 'SCENARIO', 'KTOKK', 'VSTATU', 'VPATD', 'EKORG', 'EKGRP',\n",
              "       'TOTGRQTY', 'TOTIRQTY', 'NODLGR', 'NODLIR', 'DIFGRIRD', 'DIFGRIRV',\n",
              "       'STATUS'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmnkD8Bd_Jfp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Determine CSV, label, and key columns\n",
        "#Columns in training sheet -> Can have extra columns too\n",
        "CSV_COLUMNS = traindf.columns\n",
        "LABEL_COLUMN = 'STATUS'\n",
        "\n",
        "# Set default values for each CSV column( Including Y column )\n",
        "DEFAULTS = [[\"ML01\"], ['0'], ['0'],[\"0\"],[-1],[\"-1\"],[\"-1\"],[0],[0],[0],[0],[0],[0],[0]]\n",
        "\n",
        "def make_input_fn(filename, mode, vnum_epochs = None, batch_size = 512):\n",
        "    def _input_fn(v_test=False):     \n",
        "        # Create list of files that match pattern\n",
        "        file_list = tf.io.gfile.glob(filename)\n",
        "\n",
        "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "            num_epochs = vnum_epochs # indefinitely\n",
        "        else:\n",
        "            num_epochs = 1 # end-of-input after this        \n",
        "        \n",
        "        # Create dataset from file list\n",
        "        dataset = tf.compat.v1.data.experimental.make_csv_dataset(file_list,\n",
        "                                                   batch_size=batch_size,\n",
        "                                                   column_names=CSV_COLUMNS,\n",
        "                                                   column_defaults=DEFAULTS,\n",
        "                                                   label_name=LABEL_COLUMN,\n",
        "                                                   num_epochs = num_epochs,\n",
        "                                                   num_parallel_reads=30)\n",
        "        \n",
        "        #Feature engineering\n",
        "        dataset = dataset.map(feature_engg)\n",
        "\n",
        "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "            num_epochs = vnum_epochs # indefinitely\n",
        "            dataset = dataset.shuffle(buffer_size = batch_size)\n",
        "        else:\n",
        "            num_epochs = 1 # end-of-input after this\n",
        "\n",
        "        dataset = dataset.repeat(num_epochs)\n",
        "        dataset = dataset.prefetch(buffer_size = batch_size)\n",
        "        \n",
        "        #Begins - Uncomment for testing only -----------------------------------------------------<\n",
        "        if v_test == True:\n",
        "          x, y = dataset.make_one_shot_iterator().get_next()\n",
        "          #TF 2.0 has eager execution\n",
        "          print(x, y)\n",
        "          \n",
        "        #End - Uncomment for testing only -----------------------------------------------------<\n",
        "        return dataset\n",
        "    return _input_fn\n",
        "\n",
        "# Serving function for external call\n",
        "[\"ML01\"], ['0'], ['0'],[\"0\"],[-1],[\"-1\"],[\"-1\"],[0],[0],[0],[0],[0],[0],[0]\n",
        "def serving_fn():\n",
        "    feature_placeholders  = {'WERKS' : tf.compat.v1.placeholder_with_default(\"ML01\", None),\n",
        "            'SCENARIO' : tf.compat.v1.placeholder_with_default(\"0\", None),\n",
        "            'KTOKK' : tf.compat.v1.placeholder_with_default(\"0\", None),\n",
        "            'VSTATU' : tf.compat.v1.placeholder_with_default(\"0\", None),\n",
        "            'EKORG' : tf.compat.v1.placeholder_with_default(\"0\", None),\n",
        "            'EKGRP' : tf.compat.v1.placeholder_with_default(\"0\", None),\n",
        "            'VPATD' : tf.compat.v1.placeholder_with_default(0, None),\n",
        "            'TOTGRQTY' : tf.compat.v1.placeholder_with_default(0, None),\n",
        "            'TOTIRQTY' : tf.compat.v1.placeholder_with_default(0, None),\n",
        "            'NODLGR' : tf.compat.v1.placeholder_with_default(0, None),\n",
        "            'NODLIR' : tf.compat.v1.placeholder_with_default(0, None),\n",
        "            'DIFGRIRD' : tf.compat.v1.placeholder_with_default(0, None),\n",
        "            'DIFGRIRV' : tf.compat.v1.placeholder_with_default(0, None)\n",
        "    }\n",
        "\n",
        "    #Features with transformation logic\n",
        "    features = {\n",
        "                key: tf.expand_dims(tensor, -1)\n",
        "                for key, tensor in feature_placeholders.items()\n",
        "            }\n",
        "    \n",
        "    #feat_changed = add_engineered(features.copy())\n",
        "    return tf.estimator.export.ServingInputReceiver(feature_engg_features(features), feature_placeholders )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xo3g9qn1NtQA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "0df3b0a7-49ec-4453-98c8-0897a9dc505b"
      },
      "source": [
        "#Test dataset read + Feat Engg function's - output's CSV + Feature engg columns\n",
        "eval_file = \"*eval*.csv\"\n",
        "fn_d = make_input_fn(filename = eval_file,\n",
        "                    mode = tf.estimator.ModeKeys.TRAIN,\n",
        "                    vnum_epochs = 1,\n",
        "                    batch_size = 10)\n",
        "\n",
        "fn_d(v_test=True)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OrderedDict([('WERKS', <tf.Tensor: id=11254, shape=(10,), dtype=string, numpy=\n",
            "array([b'ML01', b'ML02', b'ML03', b'ML01', b'ML02', b'ML03', b'ML01',\n",
            "       b'ML02', b'ML01', b'ML03'], dtype=object)>), ('SCENARIO', <tf.Tensor: id=11249, shape=(10,), dtype=string, numpy=\n",
            "array([b'2', b'3', b'1', b'1', b'3', b'2', b'2', b'3', b'3', b'1'],\n",
            "      dtype=object)>), ('KTOKK', <tf.Tensor: id=11246, shape=(10,), dtype=string, numpy=\n",
            "array([b'2', b'2', b'2', b'1', b'2', b'1', b'2', b'2', b'2', b'1'],\n",
            "      dtype=object)>), ('VSTATU', <tf.Tensor: id=11253, shape=(10,), dtype=string, numpy=\n",
            "array([b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1', b'1'],\n",
            "      dtype=object)>), ('VPATD', <tf.Tensor: id=11252, shape=(10,), dtype=int32, numpy=array([30, 90, 30, 90, 30, 30, 30, 60, 90, 30], dtype=int32)>), ('EKORG', <tf.Tensor: id=11245, shape=(10,), dtype=string, numpy=\n",
            "array([b'1', b'1', b'2', b'1', b'1', b'2', b'1', b'1', b'1', b'2'],\n",
            "      dtype=object)>), ('EKGRP', <tf.Tensor: id=11244, shape=(10,), dtype=string, numpy=\n",
            "array([b'B', b'A', b'C', b'B', b'B', b'C', b'B', b'A', b'A', b'C'],\n",
            "      dtype=object)>), ('TOTGRQTY', <tf.Tensor: id=11250, shape=(10,), dtype=int32, numpy=array([104,   0,  28,   5,   0,  82, 105,   0,   0,  28], dtype=int32)>), ('TOTIRQTY', <tf.Tensor: id=11251, shape=(10,), dtype=int32, numpy=array([102, 154,   0,   0,  77,  76,  98, 185,  86,   0], dtype=int32)>), ('NODLGR', <tf.Tensor: id=11247, shape=(10,), dtype=int32, numpy=array([220,   0, 152, 157,   0,  78,  53,   0,   0, 169], dtype=int32)>), ('NODLIR', <tf.Tensor: id=11248, shape=(10,), dtype=int32, numpy=array([201, 106,   0,   0, 128,  56,  26, 149, 137,   0], dtype=int32)>), ('DIFGRIRD', <tf.Tensor: id=11242, shape=(10,), dtype=int32, numpy=\n",
            "array([   2, -154,   28,    5,  -77,    6,    7, -185,  -86,   28],\n",
            "      dtype=int32)>), ('DIFGRIRV', <tf.Tensor: id=11243, shape=(10,), dtype=int32, numpy=\n",
            "array([   671, -21200,  19600,   3500, -29700,   5381,   3753, -22200,\n",
            "       -20700,  19600], dtype=int32)>), ('grminusirbyvpatd', <tf.Tensor: id=11255, shape=(10,), dtype=float64, numpy=\n",
            "array([ 0.06666667, -1.71111111,  0.93333333,  0.05555556, -2.56666667,\n",
            "        0.2       ,  0.23333333, -3.08333333, -0.95555556,  0.93333333])>)]) tf.Tensor([1 0 0 1 0 0 0 0 0 0], shape=(10,), dtype=int32)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<DatasetV1Adapter shapes: (OrderedDict([(WERKS, (None,)), (SCENARIO, (None,)), (KTOKK, (None,)), (VSTATU, (None,)), (VPATD, (None,)), (EKORG, (None,)), (EKGRP, (None,)), (TOTGRQTY, (None,)), (TOTIRQTY, (None,)), (NODLGR, (None,)), (NODLIR, (None,)), (DIFGRIRD, (None,)), (DIFGRIRV, (None,)), (grminusirbyvpatd, (None,))]), (None,)), types: (OrderedDict([(WERKS, tf.string), (SCENARIO, tf.string), (KTOKK, tf.string), (VSTATU, tf.string), (VPATD, tf.int32), (EKORG, tf.string), (EKGRP, tf.string), (TOTGRQTY, tf.int32), (TOTIRQTY, tf.int32), (NODLGR, tf.int32), (NODLIR, tf.int32), (DIFGRIRD, tf.int32), (DIFGRIRV, tf.int32), (grminusirbyvpatd, tf.float64)]), tf.int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgMO6c0V_Jfh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define your feature columns\n",
        "def create_feature_cols():\n",
        "#   lat_buck = tf.feature_column.bucketized_column(tf.feature_column.numeric_column('latitude'), \n",
        "#                                                  boundaries = np.arange(32.0, 42, 1).tolist())\n",
        "#   long_buck = tf.feature_column.bucketized_column(tf.feature_column.numeric_column('longitude'),\n",
        "#                                                   boundaries = np.arange(1, 52, 1).tolist())\n",
        "    werks_c = tf.feature_column.categorical_column_with_vocabulary_list(\n",
        "            key='WERKS',\n",
        "            vocabulary_list=['ML01','ML02','ML03'])\n",
        "    scenario_c = tf.feature_column.categorical_column_with_vocabulary_list(\n",
        "            key='SCENARIO',\n",
        "            vocabulary_list=['1','2','3','4'])\n",
        "    ktokk_c = tf.feature_column.categorical_column_with_vocabulary_list(\n",
        "            key='KTOKK',\n",
        "            vocabulary_list=['1','2'])    \n",
        "    vstatu_c = tf.feature_column.categorical_column_with_vocabulary_list(\n",
        "            key='VSTATU',\n",
        "            vocabulary_list=['1','2'])\n",
        "    ekorg_c = tf.feature_column.categorical_column_with_vocabulary_list(\n",
        "            key='EKORG',\n",
        "            vocabulary_list=['1','2'])   \n",
        "    ekgrp_c = tf.feature_column.categorical_column_with_vocabulary_list(\n",
        "            key='EKGRP',\n",
        "            vocabulary_list=['A','B','C'])\n",
        "    \n",
        "#     werks_c = tf.feature_column.categorical_column_with_hash_bucket(\n",
        "#             key='WERKS',hash_bucket_size=3)\n",
        "#     scenario_c = tf.feature_column.categorical_column_with_hash_bucket(\n",
        "#             key='SCENARIO',hash_bucket_size=4)\n",
        "#     ktokk_c = tf.feature_column.categorical_column_with_hash_bucket(\n",
        "#             key='KTOKK',hash_bucket_size=2)\n",
        "#     vstatu_c = tf.feature_column.categorical_column_with_hash_bucket(\n",
        "#             key='VSTATU',hash_bucket_size=2)\n",
        "#     ekorg_c = tf.feature_column.categorical_column_with_hash_bucket(\n",
        "#             key='EKORG',hash_bucket_size=2)\n",
        "#     ekgrp_c = tf.feature_column.categorical_column_with_hash_bucket(\n",
        "#             key='EKGRP',hash_bucket_size=3)\n",
        "\n",
        "    return [\n",
        "        tf.feature_column.indicator_column(werks_c),\n",
        "        tf.feature_column.indicator_column(scenario_c),\n",
        "        tf.feature_column.indicator_column(ktokk_c),\n",
        "        tf.feature_column.indicator_column(vstatu_c),\n",
        "        tf.feature_column.indicator_column(ekorg_c),\n",
        "        tf.feature_column.indicator_column(ekgrp_c),\n",
        "        tf.feature_column.numeric_column('VPATD'),\n",
        "        tf.feature_column.numeric_column(\"TOTGRQTY\"),\n",
        "        tf.feature_column.numeric_column(\"TOTIRQTY\"),\n",
        "        tf.feature_column.numeric_column(\"NODLGR\"),\n",
        "        tf.feature_column.numeric_column(\"NODLIR\"),\n",
        "        tf.feature_column.numeric_column(\"DIFGRIRD\"),\n",
        "        tf.feature_column.numeric_column(\"grminusirbyvpatd\"),\n",
        "        tf.feature_column.numeric_column(\"DIFGRIRV\")\n",
        "  ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_I-0uxm_Jf5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create estimator train and evaluate function\n",
        "def train_and_evaluate(output_dir, num_train_steps, train_file, eval_file):    \n",
        "##### Create Canned estimator instance\n",
        "    ## setting the checkpoint interval to be much lower for this task\n",
        "    run_config = tf.estimator.RunConfig(save_checkpoints_secs = 40, \n",
        "                                        keep_checkpoint_max = 3)\n",
        "    \n",
        "    estimator = tf.estimator.DNNClassifier(feature_columns=create_feature_cols(),\n",
        "                                          n_classes=2,\n",
        "                                          hidden_units=[32,32],\n",
        "                                          dropout = 0.2,\n",
        "                                          optimizer=tf.keras.optimizers.Adam(learning_rate=0.001))\n",
        "#                                           config = run_config)\n",
        "    train_spec = tf.estimator.TrainSpec(input_fn = make_input_fn(\n",
        "                                                filename = train_file,\n",
        "                                                mode = tf.estimator.ModeKeys.TRAIN,\n",
        "                                                batch_size = 128),\n",
        "                                      max_steps = num_train_steps)\n",
        "    exp = tf.estimator.LatestExporter(\"decision\", serving_fn)\n",
        "    eval_spec = tf.estimator.EvalSpec(input_fn = make_input_fn(\n",
        "                                                filename = eval_file,\n",
        "                                                mode = tf.estimator.ModeKeys.EVAL,\n",
        "                                                batch_size = 128),\n",
        "                                    steps = None, \n",
        "                                    exporters = exp,\n",
        "                                    start_delay_secs = 20, # start evaluating after N seconds, \n",
        "                                    throttle_secs = 45)  # evaluate every N seconds\n",
        "    tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0IPruma_Jf7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_file = \"*train*.csv\"\n",
        "eval_file = \"*eval*.csv\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "SVjaQkls_Jf_",
        "colab_type": "code",
        "outputId": "bb50a7e3-f78d-427d-afe3-d572a2733a3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Final trainer\n",
        "train_and_evaluate(None, num_train_steps=1000, train_file=train_file, eval_file=eval_file)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp_zvo8y5r\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp_zvo8y5r', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f4ac694bb70>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "INFO:tensorflow:Not using Distribute Coordinator.\n",
            "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
            "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmp_zvo8y5r/model.ckpt.\n",
            "INFO:tensorflow:loss = 1194.3248, step = 0\n",
            "INFO:tensorflow:global_step/sec: 98.2363\n",
            "INFO:tensorflow:loss = 164.88542, step = 100 (1.022 sec)\n",
            "INFO:tensorflow:global_step/sec: 137.234\n",
            "INFO:tensorflow:loss = 75.78824, step = 200 (0.729 sec)\n",
            "INFO:tensorflow:global_step/sec: 136.327\n",
            "INFO:tensorflow:loss = 47.419746, step = 300 (0.731 sec)\n",
            "INFO:tensorflow:global_step/sec: 138.671\n",
            "INFO:tensorflow:loss = 20.58876, step = 400 (0.724 sec)\n",
            "INFO:tensorflow:global_step/sec: 134.836\n",
            "INFO:tensorflow:loss = 17.126722, step = 500 (0.738 sec)\n",
            "INFO:tensorflow:global_step/sec: 136.268\n",
            "INFO:tensorflow:loss = 4.052356, step = 600 (0.736 sec)\n",
            "INFO:tensorflow:global_step/sec: 141.516\n",
            "INFO:tensorflow:loss = 1.6064522, step = 700 (0.704 sec)\n",
            "INFO:tensorflow:global_step/sec: 138.643\n",
            "INFO:tensorflow:loss = 8.3384695, step = 800 (0.721 sec)\n",
            "INFO:tensorflow:global_step/sec: 140.523\n",
            "INFO:tensorflow:loss = 2.1951733, step = 900 (0.714 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 1000 into /tmp/tmp_zvo8y5r/model.ckpt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2019-10-29T11:28:46Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmp_zvo8y5r/model.ckpt-1000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2019-10-29-11:28:47\n",
            "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.71012735, accuracy_baseline = 0.6082474, auc = 0.7619193, auc_precision_recall = 0.6696278, average_loss = 0.5876461, global_step = 1000, label/mean = 0.39175257, loss = 0.5877944, precision = 0.6099476, prediction/mean = 0.44227713, recall = 0.72136223\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: /tmp/tmp_zvo8y5r/model.ckpt-1000\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict']\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
            "INFO:tensorflow:Signatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
            "INFO:tensorflow:'serving_default' : Classification input must be a single string Tensor; got {'WERKS': <tf.Tensor 'PlaceholderWithDefault:0' shape=<unknown> dtype=string>, 'SCENARIO': <tf.Tensor 'PlaceholderWithDefault_1:0' shape=<unknown> dtype=string>, 'KTOKK': <tf.Tensor 'PlaceholderWithDefault_2:0' shape=<unknown> dtype=string>, 'VSTATU': <tf.Tensor 'PlaceholderWithDefault_3:0' shape=<unknown> dtype=string>, 'EKORG': <tf.Tensor 'PlaceholderWithDefault_4:0' shape=<unknown> dtype=string>, 'EKGRP': <tf.Tensor 'PlaceholderWithDefault_5:0' shape=<unknown> dtype=string>, 'VPATD': <tf.Tensor 'PlaceholderWithDefault_6:0' shape=<unknown> dtype=int32>, 'TOTGRQTY': <tf.Tensor 'PlaceholderWithDefault_7:0' shape=<unknown> dtype=int32>, 'TOTIRQTY': <tf.Tensor 'PlaceholderWithDefault_8:0' shape=<unknown> dtype=int32>, 'NODLGR': <tf.Tensor 'PlaceholderWithDefault_9:0' shape=<unknown> dtype=int32>, 'NODLIR': <tf.Tensor 'PlaceholderWithDefault_10:0' shape=<unknown> dtype=int32>, 'DIFGRIRD': <tf.Tensor 'PlaceholderWithDefault_11:0' shape=<unknown> dtype=int32>, 'DIFGRIRV': <tf.Tensor 'PlaceholderWithDefault_12:0' shape=<unknown> dtype=int32>}\n",
            "INFO:tensorflow:'classification' : Classification input must be a single string Tensor; got {'WERKS': <tf.Tensor 'PlaceholderWithDefault:0' shape=<unknown> dtype=string>, 'SCENARIO': <tf.Tensor 'PlaceholderWithDefault_1:0' shape=<unknown> dtype=string>, 'KTOKK': <tf.Tensor 'PlaceholderWithDefault_2:0' shape=<unknown> dtype=string>, 'VSTATU': <tf.Tensor 'PlaceholderWithDefault_3:0' shape=<unknown> dtype=string>, 'EKORG': <tf.Tensor 'PlaceholderWithDefault_4:0' shape=<unknown> dtype=string>, 'EKGRP': <tf.Tensor 'PlaceholderWithDefault_5:0' shape=<unknown> dtype=string>, 'VPATD': <tf.Tensor 'PlaceholderWithDefault_6:0' shape=<unknown> dtype=int32>, 'TOTGRQTY': <tf.Tensor 'PlaceholderWithDefault_7:0' shape=<unknown> dtype=int32>, 'TOTIRQTY': <tf.Tensor 'PlaceholderWithDefault_8:0' shape=<unknown> dtype=int32>, 'NODLGR': <tf.Tensor 'PlaceholderWithDefault_9:0' shape=<unknown> dtype=int32>, 'NODLIR': <tf.Tensor 'PlaceholderWithDefault_10:0' shape=<unknown> dtype=int32>, 'DIFGRIRD': <tf.Tensor 'PlaceholderWithDefault_11:0' shape=<unknown> dtype=int32>, 'DIFGRIRV': <tf.Tensor 'PlaceholderWithDefault_12:0' shape=<unknown> dtype=int32>}\n",
            "INFO:tensorflow:'regression' : Regression input must be a single string Tensor; got {'WERKS': <tf.Tensor 'PlaceholderWithDefault:0' shape=<unknown> dtype=string>, 'SCENARIO': <tf.Tensor 'PlaceholderWithDefault_1:0' shape=<unknown> dtype=string>, 'KTOKK': <tf.Tensor 'PlaceholderWithDefault_2:0' shape=<unknown> dtype=string>, 'VSTATU': <tf.Tensor 'PlaceholderWithDefault_3:0' shape=<unknown> dtype=string>, 'EKORG': <tf.Tensor 'PlaceholderWithDefault_4:0' shape=<unknown> dtype=string>, 'EKGRP': <tf.Tensor 'PlaceholderWithDefault_5:0' shape=<unknown> dtype=string>, 'VPATD': <tf.Tensor 'PlaceholderWithDefault_6:0' shape=<unknown> dtype=int32>, 'TOTGRQTY': <tf.Tensor 'PlaceholderWithDefault_7:0' shape=<unknown> dtype=int32>, 'TOTIRQTY': <tf.Tensor 'PlaceholderWithDefault_8:0' shape=<unknown> dtype=int32>, 'NODLGR': <tf.Tensor 'PlaceholderWithDefault_9:0' shape=<unknown> dtype=int32>, 'NODLIR': <tf.Tensor 'PlaceholderWithDefault_10:0' shape=<unknown> dtype=int32>, 'DIFGRIRD': <tf.Tensor 'PlaceholderWithDefault_11:0' shape=<unknown> dtype=int32>, 'DIFGRIRV': <tf.Tensor 'PlaceholderWithDefault_12:0' shape=<unknown> dtype=int32>}\n",
            "WARNING:tensorflow:Export includes no default signature!\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmp_zvo8y5r/model.ckpt-1000\n",
            "INFO:tensorflow:Assets added to graph.\n",
            "INFO:tensorflow:No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: /tmp/tmp_zvo8y5r/export/decision/temp-b'1572348527'/saved_model.pb\n",
            "INFO:tensorflow:Loss for final step: 4.3121653.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDBsWPgI_JgB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #Only DNN Deep wide classifier\n",
        "# def get_deep_wide_features():\n",
        "#     werks_c = tf.feature_column.categorical_column_with_vocabulary_list(\n",
        "#             key='WERKS',\n",
        "#             vocabulary_list=['ML01','ML02','ML03'])\n",
        "#     scenario_c = tf.feature_column.categorical_column_with_vocabulary_list(\n",
        "#             key='SCENARIO',\n",
        "#             vocabulary_list=['1','2','3','4'])\n",
        "#     ktokk_c = tf.feature_column.categorical_column_with_vocabulary_list(\n",
        "#             key='KTOKK',\n",
        "#             vocabulary_list=['1','2'])    \n",
        "#     vstatu_c = tf.feature_column.categorical_column_with_vocabulary_list(\n",
        "#             key='VSTATU',\n",
        "#             vocabulary_list=['1','2'])\n",
        "#     ekorg_c = tf.feature_column.categorical_column_with_vocabulary_list(\n",
        "#             key='EKORG',\n",
        "#             vocabulary_list=['1','2'])   \n",
        "#     ekgrp_c = tf.feature_column.categorical_column_with_vocabulary_list(\n",
        "#             key='EKGRP',\n",
        "#             vocabulary_list=['A','B','C'])\n",
        "#     deep_columns = [\n",
        "#         tf.feature_column.numeric_column('VPATD'),\n",
        "#         tf.feature_column.numeric_column(\"TOTGRQTY\"),\n",
        "#         tf.feature_column.numeric_column(\"TOTIRQTY\"),\n",
        "#         tf.feature_column.numeric_column(\"NODLGR\"),\n",
        "#         tf.feature_column.numeric_column(\"NODLIR\"),\n",
        "#         tf.feature_column.numeric_column(\"DIFGRIRD\"),\n",
        "#         tf.feature_column.numeric_column(\"DIFGRIRV\")\n",
        "#     ]\n",
        "#     wide_columns = [\n",
        "#         tf.feature_column.indicator_column(werks_c),\n",
        "#         tf.feature_column.indicator_column(scenario_c),\n",
        "#         tf.feature_column.indicator_column(ktokk_c),\n",
        "#         tf.feature_column.indicator_column(vstatu_c),\n",
        "#         tf.feature_column.indicator_column(ekorg_c),\n",
        "#         tf.feature_column.indicator_column(ekgrp_c),\n",
        "#     ]\n",
        "#     return deep_columns, wide_columns\n",
        "\n",
        "# def train_and_evaluate_deep(output_dir, num_train_steps):    \n",
        "# ##### Create Canned estimator instance\n",
        "#     #Get features\n",
        "#     deep, wide = get_deep_wide_features()\n",
        "\n",
        "#     estimator = tf.estimator.DNNLinearCombinedClassifier(\n",
        "#                                     linear_feature_columns = wide,\n",
        "#                                     dnn_feature_columns = deep,\n",
        "#                                     n_classes=2,\n",
        "#                                     dnn_hidden_units = [32,64,64,64,64,64,\n",
        "#                                                         64,64,64,64,64,64,\n",
        "#                                                         64,64,64,64,64,64,\n",
        "#                                                         32],\n",
        "#                                     dnn_dropout = 0.1,\n",
        "#                                     dnn_optimizer=tf.train.AdamOptimizer(learning_rate=0.0001))\n",
        "#     train_spec = tf.estimator.TrainSpec(input_fn = make_input_fn(traindf, None), \n",
        "#                                       max_steps = num_train_steps)\n",
        "#     exp = tf.estimator.LatestExporter(\"decision\", serving_fn)\n",
        "#     eval_spec = tf.estimator.EvalSpec(input_fn = make_input_fn(evaldf, 1), \n",
        "#                                     steps = None, \n",
        "#                                     exporters = exp,\n",
        "#                                     start_delay_secs = 1, # start evaluating after N seconds, \n",
        "#                                     throttle_secs = 40)  # evaluate every N seconds\n",
        "#     tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4O-ZL5k_JgD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #setup exponential decay function for learning rates\n",
        "# def get_global_step():\n",
        "#     if tf.train.get_global_step() is None:\n",
        "#         return 1\n",
        "#     else:\n",
        "#         return tf.train.get_global_step()\n",
        "\n",
        "# def get_exp_decay_optimizer():\n",
        "#     def exp_decay(global_step=global_step):\n",
        "#         return tf.train.exponential_decay(\n",
        "#           learning_rate=0.0001, global_step=global_step,\n",
        "#           decay_steps=100, decay_rate=0.8, staircase=True)\n",
        "#     # use customized decay function in learning_rate\n",
        "#     return tf.train.AdagradOptimizer(learning_rate=exp_decay(tf.train.get_global_step()))\n",
        "\n",
        "# # setup stepwise decay function for learning rates\n",
        "# def get_stepw_decay_optimizer2():\n",
        "#     def step_decay():\n",
        "#         return tf.train.piecewise_constant(get_global_step(), \n",
        "#                                            boundaries=[10000,20000,50000,100000], \n",
        "#                                            values=[0.001,0.0005,0.0001,0.00005,0.00002])\n",
        "#     # use customized decay function in learning_rate\n",
        "#     return tf.train.AdamOptimizer(learning_rate=step_decay)#,epsilon=0.001)\n",
        "\n",
        "# # setup stepwise decay function for learning rates\n",
        "# def get_stepw_decay_optimizer():\n",
        "#     def step_decay(global_step):\n",
        "#         return tf.train.piecewise_constant(global_step, boundaries=[10000,20000,50000,100000], values=[0.001,0.0005,0.0001,0.00005,0.00002])\n",
        "#                                          # use customized decay function in learning_rate\n",
        "#     return tf.train.AdamOptimizer(learning_rate=step_decay(tf.train.get_global_step()))#,epsilon=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHZxMpPa_JgH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "accuracy_score = classifier.evaluate(input_fn=get_input_fn(training_set, num_epochs=1, shuffle=False))[\"accuracy\"]\n",
        "print(\"\\nTrain Accuracy: {0:f}\\n\".format(accuracy_score))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eyclr50x_JgK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "accuracy_score = classifier.evaluate(input_fn=get_validation_input_fn(test_set, num_epochs=1, shuffle=False))[\"accuracy\"]\n",
        "print(\"\\nTest Accuracy: {0:f}\\n\".format(accuracy_score))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PURX3_Lh_JgN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Run model on Prediction data set\n",
        "predictions = classifier.predict_classes(input_fn=get_prediction_input_fn(test_set))\n",
        "for p in list(predictions):\n",
        "    print(p)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rltHdnjN_JgP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in list(test_set['STATUS']):\n",
        "    print(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bcOnzQa_JgR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Predict with disk saved model\n",
        "from tensorflow.contrib import predictor\n",
        "\n",
        "export_dir = os.getcwd() + \"/tflow_grir_model\"\n",
        "predict_fn = predictor.from_saved_model(export_dir,signature_def_key='predict')\n",
        "\n",
        "predictions = predict_fn({\"DIFGRIRV\": [-38100],\"NODLIR\": [90],\"VSTATU\": [\"1\"],\"NODLGR\": [0],\"DIFGRIRD\": [-80],\"VPATD\": [30],\n",
        "                          \"WERKS\": [\"ML01\"],\n",
        "                          \"EKORG\": [\"1\"],\"TOTGRQTY\": [0],\"SCENARIO\": [\"3\"],\"TOTIRQTY\": [80],\"KTOKK\": [\"1\"],\"EKGRP\": [\"A\"]})\n",
        "print(predictions['probabilities'][0,1])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}