{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF Keras 2.0 GRIR - Tf.Dataset + FeatEngg.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jb8UuABdBeGg",
        "colab_type": "code",
        "outputId": "7e08f954-7a6a-4419-fd60-5d14c2337441",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 665
        }
      },
      "source": [
        "%%bash\n",
        "pip install --upgrade tensorflow-gpu"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu\n",
            "  Downloading https://files.pythonhosted.org/packages/25/44/47f0722aea081697143fbcf5d2aa60d1aee4aaacb5869aee2b568974777b/tensorflow_gpu-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (380.8MB)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.0.8)\n",
            "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.8.0)\n",
            "Collecting tensorflow-estimator<2.1.0,>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/fc/08/8b927337b7019c374719145d1dceba21a8bb909b93b1ad6f8fb7d22c1ca1/tensorflow_estimator-2.0.1-py2.py3-none-any.whl (449kB)\n",
            "Collecting tensorboard<2.1.0,>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/9b/a6/e8ffa4e2ddb216449d34cfcb825ebb38206bee5c4553d69e7bc8bc2c5d64/tensorboard-2.0.0-py3-none-any.whl (3.8MB)\n",
            "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.17.3)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.8.1)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.10.0)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.33.6)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.11.2)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.1.7)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.2.2)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu) (2.8.0)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (3.1.1)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (41.4.0)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, tensorflow-gpu\n",
            "  Found existing installation: tensorflow-estimator 1.15.1\n",
            "    Uninstalling tensorflow-estimator-1.15.1:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "Successfully installed tensorboard-2.0.0 tensorflow-estimator-2.0.1 tensorflow-gpu-2.0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR: tensorflow 1.15.0 has requirement tensorboard<1.16.0,>=1.15.0, but you'll have tensorboard 2.0.0 which is incompatible.\n",
            "ERROR: tensorflow 1.15.0 has requirement tensorflow-estimator==1.15.1, but you'll have tensorflow-estimator 2.0.1 which is incompatible.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMhtcN8aBthv",
        "colab_type": "code",
        "outputId": "8075e271-9b96-4eca-ef46-9403df38873a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "tf.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.0.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EN_MQsXSOEeH",
        "colab_type": "code",
        "outputId": "154e5be2-c3b4-4c6e-df11-1d71791e6c56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "#Mount GDrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_H0XbuzOZaa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Copy data to local\n",
        "%%bash\n",
        "cp '/content/drive/My Drive/Colab Notebooks/TF Keras 2.0 GRIR - CMLE + FeatEngg/GRIR_GCP_Data.csv' 'GRIR_GCP_Data.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qp8eKrUkOj-Q",
        "colab_type": "code",
        "outputId": "cd122d73-d869-45b4-f4bb-1a7cd03dd7ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "#Read data set CSV\n",
        "df = pd.read_csv(\"GRIR_GCP_Data.csv\", sep=\",\")\n",
        "df.head(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>WERKS</th>\n",
              "      <th>SCENARIO</th>\n",
              "      <th>KTOKK</th>\n",
              "      <th>VSTATU</th>\n",
              "      <th>VPATD</th>\n",
              "      <th>EKORG</th>\n",
              "      <th>EKGRP</th>\n",
              "      <th>TOTGRQTY</th>\n",
              "      <th>TOTIRQTY</th>\n",
              "      <th>NODLGR</th>\n",
              "      <th>NODLIR</th>\n",
              "      <th>DIFGRIRD</th>\n",
              "      <th>DIFGRIRV</th>\n",
              "      <th>STATUS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ML01</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>30</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>0</td>\n",
              "      <td>80</td>\n",
              "      <td>0</td>\n",
              "      <td>90</td>\n",
              "      <td>-80</td>\n",
              "      <td>-38100</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ML01</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>30</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>0</td>\n",
              "      <td>107</td>\n",
              "      <td>0</td>\n",
              "      <td>177</td>\n",
              "      <td>-107</td>\n",
              "      <td>-41600</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ML01</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>30</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>0</td>\n",
              "      <td>107</td>\n",
              "      <td>0</td>\n",
              "      <td>152</td>\n",
              "      <td>-107</td>\n",
              "      <td>-27600</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ML01</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>30</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>0</td>\n",
              "      <td>96</td>\n",
              "      <td>0</td>\n",
              "      <td>79</td>\n",
              "      <td>-96</td>\n",
              "      <td>-13800</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ML01</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>30</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>0</td>\n",
              "      <td>146</td>\n",
              "      <td>0</td>\n",
              "      <td>192</td>\n",
              "      <td>-146</td>\n",
              "      <td>-73500</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  WERKS  SCENARIO  KTOKK  VSTATU  ...  NODLIR  DIFGRIRD DIFGRIRV  STATUS\n",
              "0  ML01         3      1       1  ...      90       -80   -38100       1\n",
              "1  ML01         3      1       1  ...     177      -107   -41600       0\n",
              "2  ML01         3      1       1  ...     152      -107   -27600       1\n",
              "3  ML01         3      1       1  ...      79       -96   -13800       1\n",
              "4  ML01         3      1       1  ...     192      -146   -73500       0\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVCM4PTBO-qA",
        "colab_type": "code",
        "outputId": "bd7a851a-a7a2-4383-93a7-f8b099b980b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        }
      },
      "source": [
        "#Mark some columns as categorical\n",
        "for col_cat in ['SCENARIO','KTOKK','VSTATU','EKORG']:\n",
        "    df[col_cat] = df[col_cat].astype('category')\n",
        "    \n",
        "df.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 8279 entries, 0 to 8278\n",
            "Data columns (total 14 columns):\n",
            "WERKS       8279 non-null object\n",
            "SCENARIO    8279 non-null category\n",
            "KTOKK       8279 non-null category\n",
            "VSTATU      8279 non-null category\n",
            "VPATD       8279 non-null int64\n",
            "EKORG       8279 non-null category\n",
            "EKGRP       8279 non-null object\n",
            "TOTGRQTY    8279 non-null int64\n",
            "TOTIRQTY    8279 non-null int64\n",
            "NODLGR      8279 non-null int64\n",
            "NODLIR      8279 non-null int64\n",
            "DIFGRIRD    8279 non-null int64\n",
            "DIFGRIRV    8279 non-null int64\n",
            "STATUS      8279 non-null int64\n",
            "dtypes: category(4), int64(8), object(2)\n",
            "memory usage: 679.7+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4IjRY0MAJeB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Prepare train and output columns\n",
        "df_x = df.drop(['STATUS'],axis=1)\n",
        "df_y = df['STATUS']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B296aNP2AUkw",
        "colab_type": "code",
        "outputId": "fd87cb26-5c84-4cfe-e3eb-6830dee8ffd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        }
      },
      "source": [
        "#Split Train and Validation\n",
        "\n",
        "#Use the best split value from above after manual inspection\n",
        "x_train, x_test, y_train, y_test = train_test_split(df_x, df_y, test_size=0.1, random_state=8,stratify=df_y)\n",
        "x_train.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 7451 entries, 692 to 315\n",
            "Data columns (total 13 columns):\n",
            "WERKS       7451 non-null object\n",
            "SCENARIO    7451 non-null category\n",
            "KTOKK       7451 non-null category\n",
            "VSTATU      7451 non-null category\n",
            "VPATD       7451 non-null int64\n",
            "EKORG       7451 non-null category\n",
            "EKGRP       7451 non-null object\n",
            "TOTGRQTY    7451 non-null int64\n",
            "TOTIRQTY    7451 non-null int64\n",
            "NODLGR      7451 non-null int64\n",
            "NODLIR      7451 non-null int64\n",
            "DIFGRIRD    7451 non-null int64\n",
            "DIFGRIRV    7451 non-null int64\n",
            "dtypes: category(4), int64(7), object(2)\n",
            "memory usage: 611.7+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljYQ4vRfAkp_",
        "colab_type": "code",
        "outputId": "f5adc848-c831-4688-a20d-378c1987257c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        }
      },
      "source": [
        "#Save train and test CSV\n",
        "df_train = pd.concat([x_train, y_train], axis = 1)\n",
        "df_train.to_csv(\"train.csv\", index =False)\n",
        "\n",
        "df_test = pd.concat([x_test, y_test], axis = 1)\n",
        "df_test.to_csv(\"test.csv\", index=False)\n",
        "df_train.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 7451 entries, 692 to 315\n",
            "Data columns (total 14 columns):\n",
            "WERKS       7451 non-null object\n",
            "SCENARIO    7451 non-null category\n",
            "KTOKK       7451 non-null category\n",
            "VSTATU      7451 non-null category\n",
            "VPATD       7451 non-null int64\n",
            "EKORG       7451 non-null category\n",
            "EKGRP       7451 non-null object\n",
            "TOTGRQTY    7451 non-null int64\n",
            "TOTIRQTY    7451 non-null int64\n",
            "NODLGR      7451 non-null int64\n",
            "NODLIR      7451 non-null int64\n",
            "DIFGRIRD    7451 non-null int64\n",
            "DIFGRIRV    7451 non-null int64\n",
            "STATUS      7451 non-null int64\n",
            "dtypes: category(4), int64(8), object(2)\n",
            "memory usage: 669.9+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhxWVXCvjCxz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def feature_engg_features(features):\n",
        "  #Add new features\n",
        "  features['grminusirbyvpatd'] = ( features['TOTGRQTY'] - features['TOTIRQTY'] ) / features['VPATD']\n",
        "\n",
        "  return(features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pWEWCyDbBZt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def feature_engg(features, label):\n",
        "  #Add new features\n",
        "  features = feature_engg_features(features)\n",
        "\n",
        "  return(features, label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39sv_f_tAyqD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Determine CSV, label, and key columns\n",
        "#Columns in training sheet -> Can have extra columns too\n",
        "CSV_COLUMNS = df_train.columns\n",
        "LABEL_COLUMN = 'STATUS'\n",
        "\n",
        "# Set default values for each CSV column( Including Y column )\n",
        "DEFAULTS = [[\"ML01\"], ['0'], ['0'],[\"0\"],[-1],[\"-1\"],[\"-1\"],[0],[0],[0],[0],[0],[0],[0]]\n",
        "\n",
        "def make_input_fn(filename, mode, vnum_epochs = None, batch_size = 512):\n",
        "    def _input_fn(v_test=False):     \n",
        "        # Create list of files that match pattern\n",
        "        file_list = tf.io.gfile.glob(filename)\n",
        "\n",
        "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "            num_epochs = vnum_epochs # indefinitely\n",
        "        else:\n",
        "            num_epochs = 1 # end-of-input after this        \n",
        "        \n",
        "        # Create dataset from file list\n",
        "        dataset = tf.compat.v1.data.experimental.make_csv_dataset(file_list,\n",
        "                                                   batch_size=batch_size,\n",
        "                                                   column_names=CSV_COLUMNS,\n",
        "                                                   column_defaults=DEFAULTS,\n",
        "                                                   label_name=LABEL_COLUMN,\n",
        "                                                   num_epochs = num_epochs,\n",
        "                                                   num_parallel_reads=30)\n",
        "        \n",
        "        #Feature engineering\n",
        "        dataset = dataset.map(feature_engg)\n",
        "\n",
        "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "            num_epochs = vnum_epochs # indefinitely\n",
        "            dataset = dataset.shuffle(buffer_size = batch_size)\n",
        "        else:\n",
        "            num_epochs = 1 # end-of-input after this\n",
        "\n",
        "        dataset = dataset.repeat(num_epochs)\n",
        "        dataset = dataset.prefetch(buffer_size = batch_size)\n",
        "        \n",
        "        #Begins - Uncomment for testing only -----------------------------------------------------<\n",
        "        if v_test == True:\n",
        "          x, y = dataset.make_one_shot_iterator().get_next()\n",
        "          #TF 2.0 has eager execution\n",
        "          print(x, y)\n",
        "          \n",
        "        #End - Uncomment for testing only -----------------------------------------------------<\n",
        "        return dataset\n",
        "    return _input_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ppl1BGnDeqb",
        "colab_type": "code",
        "outputId": "2f08b219-a2a1-4b0e-d7fc-2bbec538b652",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        }
      },
      "source": [
        "#Test dataset read + Feat Engg function's - output's CSV + Feature engg columns\n",
        "eval_file = \"test*.csv\"\n",
        "fn_d = make_input_fn(filename = eval_file,\n",
        "                    mode = tf.estimator.ModeKeys.TRAIN,\n",
        "                    vnum_epochs = 1,\n",
        "                    batch_size = 10)\n",
        "\n",
        "fn_d(v_test=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/experimental/ops/readers.py:521: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "WARNING:tensorflow:From <ipython-input-12-8ef07621c964>:40: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n",
            "OrderedDict([('WERKS', <tf.Tensor: id=146, shape=(10,), dtype=string, numpy=\n",
            "array([b'ML02', b'ML01', b'ML01', b'ML03', b'ML01', b'ML03', b'ML02',\n",
            "       b'ML01', b'ML02', b'ML02'], dtype=object)>), ('SCENARIO', <tf.Tensor: id=141, shape=(10,), dtype=string, numpy=\n",
            "array([b'4', b'4', b'4', b'1', b'3', b'3', b'2', b'4', b'3', b'3'],\n",
            "      dtype=object)>), ('KTOKK', <tf.Tensor: id=138, shape=(10,), dtype=string, numpy=\n",
            "array([b'1', b'2', b'1', b'1', b'1', b'2', b'2', b'2', b'1', b'2'],\n",
            "      dtype=object)>), ('VSTATU', <tf.Tensor: id=145, shape=(10,), dtype=string, numpy=\n",
            "array([b'1', b'1', b'1', b'2', b'1', b'1', b'1', b'1', b'1', b'1'],\n",
            "      dtype=object)>), ('VPATD', <tf.Tensor: id=144, shape=(10,), dtype=int32, numpy=array([30, 30, 90, 90, 60, 60, 30, 90, 60, 30], dtype=int32)>), ('EKORG', <tf.Tensor: id=137, shape=(10,), dtype=string, numpy=\n",
            "array([b'1', b'1', b'1', b'2', b'1', b'2', b'1', b'1', b'1', b'1'],\n",
            "      dtype=object)>), ('EKGRP', <tf.Tensor: id=136, shape=(10,), dtype=string, numpy=\n",
            "array([b'C', b'C', b'C', b'B', b'C', b'A', b'A', b'C', b'A', b'C'],\n",
            "      dtype=object)>), ('TOTGRQTY', <tf.Tensor: id=142, shape=(10,), dtype=int32, numpy=array([187, 142,  70,  24,   0,   0,  71, 176,   0,   0], dtype=int32)>), ('TOTIRQTY', <tf.Tensor: id=143, shape=(10,), dtype=int32, numpy=array([191, 154,  80,   0,  74, 112,  70, 196,  81, 106], dtype=int32)>), ('NODLGR', <tf.Tensor: id=139, shape=(10,), dtype=int32, numpy=array([ 97, 224, 191, 148,   0,   0,  69,  52,   0,   0], dtype=int32)>), ('NODLIR', <tf.Tensor: id=140, shape=(10,), dtype=int32, numpy=array([ 79, 209, 173,   0,  71, 179,  46,  25, 157,  18], dtype=int32)>), ('DIFGRIRD', <tf.Tensor: id=134, shape=(10,), dtype=int32, numpy=\n",
            "array([  -4,  -12,  -10,   24,  -74, -112,    1,  -20,  -81, -106],\n",
            "      dtype=int32)>), ('DIFGRIRV', <tf.Tensor: id=135, shape=(10,), dtype=int32, numpy=\n",
            "array([  -675,  -7547,  -7237,  16800, -37600, -60100,    523,  -2972,\n",
            "       -35000, -22500], dtype=int32)>), ('grminusirbyvpatd', <tf.Tensor: id=147, shape=(10,), dtype=float64, numpy=\n",
            "array([-0.13333333, -0.4       , -0.11111111,  0.26666667, -1.23333333,\n",
            "       -1.86666667,  0.03333333, -0.22222222, -1.35      , -3.53333333])>)]) tf.Tensor([1 0 0 0 0 0 1 0 0 0], shape=(10,), dtype=int32)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<DatasetV1Adapter shapes: (OrderedDict([(WERKS, (None,)), (SCENARIO, (None,)), (KTOKK, (None,)), (VSTATU, (None,)), (VPATD, (None,)), (EKORG, (None,)), (EKGRP, (None,)), (TOTGRQTY, (None,)), (TOTIRQTY, (None,)), (NODLGR, (None,)), (NODLIR, (None,)), (DIFGRIRD, (None,)), (DIFGRIRV, (None,)), (grminusirbyvpatd, (None,))]), (None,)), types: (OrderedDict([(WERKS, tf.string), (SCENARIO, tf.string), (KTOKK, tf.string), (VSTATU, tf.string), (VPATD, tf.int32), (EKORG, tf.string), (EKGRP, tf.string), (TOTGRQTY, tf.int32), (TOTIRQTY, tf.int32), (NODLGR, tf.int32), (NODLIR, tf.int32), (DIFGRIRD, tf.int32), (DIFGRIRV, tf.int32), (grminusirbyvpatd, tf.float64)]), tf.int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uspVpQyhDtzb",
        "colab_type": "code",
        "outputId": "dba1e51f-254a-4a73-b831-dfe84877be7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "source": [
        "# Define feature columns\n",
        "def create_feature_cols():\n",
        "#   lat_buck = tf.feature_column.bucketized_column(tf.feature_column.numeric_column('latitude'), \n",
        "#                                                  boundaries = np.arange(32.0, 42, 1).tolist())\n",
        "#   long_buck = tf.feature_column.bucketized_column(tf.feature_column.numeric_column('longitude'),\n",
        "#                                                   boundaries = np.arange(1, 52, 1).tolist())\n",
        "    werks_c = tf.feature_column.categorical_column_with_vocabulary_list(\n",
        "            key='WERKS',\n",
        "            vocabulary_list=['ML01','ML02','ML03'])\n",
        "    scenario_c = tf.feature_column.categorical_column_with_vocabulary_list(\n",
        "            key='SCENARIO',\n",
        "            vocabulary_list=['1','2','3','4'])\n",
        "    ktokk_c = tf.feature_column.categorical_column_with_vocabulary_list(\n",
        "            key='KTOKK',\n",
        "            vocabulary_list=['1','2'])    \n",
        "    vstatu_c = tf.feature_column.categorical_column_with_vocabulary_list(\n",
        "            key='VSTATU',\n",
        "            vocabulary_list=['1','2'])\n",
        "    ekorg_c = tf.feature_column.categorical_column_with_vocabulary_list(\n",
        "            key='EKORG',\n",
        "            vocabulary_list=['1','2'])   \n",
        "    ekgrp_c = tf.feature_column.categorical_column_with_vocabulary_list(\n",
        "            key='EKGRP',\n",
        "            vocabulary_list=['A','B','C'])\n",
        "\n",
        "    return [\n",
        "        tf.feature_column.indicator_column(werks_c),\n",
        "        tf.feature_column.indicator_column(scenario_c),\n",
        "        tf.feature_column.indicator_column(ktokk_c),\n",
        "        tf.feature_column.indicator_column(vstatu_c),\n",
        "        tf.feature_column.indicator_column(ekorg_c),\n",
        "        tf.feature_column.indicator_column(ekgrp_c),\n",
        "        tf.feature_column.numeric_column('VPATD'),\n",
        "        tf.feature_column.numeric_column(\"TOTGRQTY\"),\n",
        "        tf.feature_column.numeric_column(\"TOTIRQTY\"),\n",
        "        tf.feature_column.numeric_column(\"NODLGR\"),\n",
        "        tf.feature_column.numeric_column(\"NODLIR\"),\n",
        "        tf.feature_column.numeric_column(\"DIFGRIRD\"),\n",
        "        tf.feature_column.numeric_column(\"DIFGRIRV\"),\n",
        "        tf.feature_column.numeric_column(\"grminusirbyvpatd\")\n",
        "  ]\n",
        "\n",
        "create_feature_cols()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='WERKS', vocabulary_list=('ML01', 'ML02', 'ML03'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
              " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='SCENARIO', vocabulary_list=('1', '2', '3', '4'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
              " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='KTOKK', vocabulary_list=('1', '2'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
              " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='VSTATU', vocabulary_list=('1', '2'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
              " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='EKORG', vocabulary_list=('1', '2'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
              " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='EKGRP', vocabulary_list=('A', 'B', 'C'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
              " NumericColumn(key='VPATD', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
              " NumericColumn(key='TOTGRQTY', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
              " NumericColumn(key='TOTIRQTY', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
              " NumericColumn(key='NODLGR', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
              " NumericColumn(key='NODLIR', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
              " NumericColumn(key='DIFGRIRD', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
              " NumericColumn(key='DIFGRIRV', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
              " NumericColumn(key='grminusirbyvpatd', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rG0p1700ZXU0",
        "colab_type": "text"
      },
      "source": [
        "# **Keras: Create dataset + model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDST7LHjWQJ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_keras_model(params, feature_cols):\n",
        "    model = tf.keras.Sequential()\n",
        "\n",
        "    #First step is feature engineering\n",
        "    # model.add(tf.keras.backend.map_fn(feature_engg_features))\n",
        "\n",
        "    #Tensorflow style feature columns\n",
        "    model.add(tf.keras.layers.DenseFeatures(feature_cols))\n",
        "\n",
        "    #Other columns\n",
        "    model.add(tf.keras.layers.Dense(32, activation='relu',kernel_initializer='he_uniform'))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "    for l_ in range(params['hidden_layers']):\n",
        "        model.add(tf.keras.layers.Dense(32, activation='relu',kernel_initializer='he_uniform'))\n",
        "        model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "    model.add(tf.keras.layers.Dense(1,   activation='sigmoid'))\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GUKtueSWZgD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def keras_train_and_evaluate(model, params, train_dataset, validation_dataset):\n",
        "  #Set optimizer\n",
        "  opt = tf.keras.optimizers.Adam(lr= params['lr'], beta_1=params['beta_1'], \n",
        "                                       beta_2=params['beta_2'], epsilon=params['epsilon'])\n",
        "\n",
        "  #Compile model\n",
        "  model.compile(loss='binary_crossentropy',  optimizer=opt, metrics =['accuracy'])\n",
        "\n",
        "  #Print Summary\n",
        "  # print(model.summary())\n",
        "\n",
        "  reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
        "                              patience=5, min_lr=0.0001, verbose = 1)\n",
        "\n",
        "  #Train\n",
        "  out = model.fit_generator(train_dataset, \n",
        "                  validation_data = validation_dataset, \n",
        "                  epochs=100,\n",
        "                  validation_steps = 2,   ###Has to be passed - Cant help it :)\n",
        "                  steps_per_epoch = 10,   ###Has to be passed - Cant help it :) [ Number of batches per epoch ]\n",
        "                  callbacks=[reduce_lr, keras.callbacks.EarlyStopping(patience=20, restore_best_weights=True)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QinNVbEDX8Ck",
        "colab_type": "code",
        "outputId": "df447149-8bfb-4430-df4d-d136e04e431f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "# epochs = 100\n",
        "#Create dataset input functions\n",
        "train_dataset = make_input_fn(filename = 'train*.csv',\n",
        "                    mode = tf.estimator.ModeKeys.TRAIN,\n",
        "                    # vnum_epochs = epochs,\n",
        "                    batch_size = 512)()\n",
        "\n",
        "validation_dataset = make_input_fn(filename = 'test*.csv',\n",
        "                    mode = tf.estimator.ModeKeys.EVAL,\n",
        "                    # vnum_epochs = 1,\n",
        "                    batch_size = 512)()\n",
        "\n",
        "#Create model\n",
        "params_default = {\n",
        "    'lr' : 0.01,\n",
        "    'beta_1' : 0.99,\n",
        "    'beta_2' : 0.999,\n",
        "    'epsilon' : 1e-08,\n",
        "    'decay' : 0.01,\n",
        "    'hidden_layers' : 1\n",
        "}\n",
        "\n",
        "m_ = create_keras_model(params = params_default, feature_cols = create_feature_cols())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/experimental/ops/readers.py:215: shuffle_and_repeat (from tensorflow.python.data.experimental.ops.shuffle_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.shuffle(buffer_size, seed)` followed by `tf.data.Dataset.repeat(count)`. Static tf.data optimizations will take care of using the fused implementation.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7a4NW8OLZcu6",
        "colab_type": "code",
        "outputId": "a786986f-e677-43e8-b5db-6fc4aed84e72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "keras_train_and_evaluate(m_, params_default, train_dataset, validation_dataset)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/feature_column/feature_column_v2.py:4276: IndicatorColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/feature_column/feature_column_v2.py:4331: VocabularyListCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
            "10/10 [==============================] - 8s 847ms/step - loss: 0.6127 - accuracy: 0.6035 - val_loss: 1.3005 - val_accuracy: 0.6087\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 2s 153ms/step - loss: 0.5159 - accuracy: 0.7252 - val_loss: 1.0906 - val_accuracy: 0.6087\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 1s 142ms/step - loss: 0.4770 - accuracy: 0.7598 - val_loss: 0.9594 - val_accuracy: 0.6087\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 1s 141ms/step - loss: 0.4499 - accuracy: 0.7694 - val_loss: 0.7988 - val_accuracy: 0.6087\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 1s 109ms/step - loss: 0.4158 - accuracy: 0.7801 - val_loss: 0.6821 - val_accuracy: 0.6014\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 1s 106ms/step - loss: 0.4124 - accuracy: 0.7974 - val_loss: 0.6671 - val_accuracy: 0.6123\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 1s 108ms/step - loss: 0.4045 - accuracy: 0.8130 - val_loss: 0.6640 - val_accuracy: 0.6087\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 1s 110ms/step - loss: 0.3840 - accuracy: 0.8136 - val_loss: 0.7660 - val_accuracy: 0.6087\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 1s 113ms/step - loss: 0.3729 - accuracy: 0.8248 - val_loss: 0.8081 - val_accuracy: 0.6087\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - 1s 120ms/step - loss: 0.3677 - accuracy: 0.8231 - val_loss: 0.7662 - val_accuracy: 0.6087\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - 1s 118ms/step - loss: 0.3813 - accuracy: 0.8185 - val_loss: 0.7933 - val_accuracy: 0.6184\n",
            "Epoch 12/100\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3595 - accuracy: 0.8455\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
            "10/10 [==============================] - 1s 117ms/step - loss: 0.3581 - accuracy: 0.8442 - val_loss: 0.7950 - val_accuracy: 0.6196\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - 1s 120ms/step - loss: 0.3570 - accuracy: 0.8389 - val_loss: 0.6612 - val_accuracy: 0.6123\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.3572 - accuracy: 0.8311 - val_loss: 0.5927 - val_accuracy: 0.6220\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - 1s 130ms/step - loss: 0.3486 - accuracy: 0.8321 - val_loss: 0.5274 - val_accuracy: 0.6703\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.3482 - accuracy: 0.8406 - val_loss: 0.4968 - val_accuracy: 0.6920\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - 1s 132ms/step - loss: 0.3406 - accuracy: 0.8504 - val_loss: 0.4883 - val_accuracy: 0.7150\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - 1s 129ms/step - loss: 0.3428 - accuracy: 0.8433 - val_loss: 0.4814 - val_accuracy: 0.7114\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - 1s 137ms/step - loss: 0.3244 - accuracy: 0.8456 - val_loss: 0.4790 - val_accuracy: 0.7246\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - 1s 135ms/step - loss: 0.3307 - accuracy: 0.8378 - val_loss: 0.4777 - val_accuracy: 0.7657\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - 1s 137ms/step - loss: 0.3363 - accuracy: 0.8351 - val_loss: 0.4211 - val_accuracy: 0.8104\n",
            "Epoch 22/100\n",
            "10/10 [==============================] - 1s 141ms/step - loss: 0.3424 - accuracy: 0.8242 - val_loss: 0.4217 - val_accuracy: 0.8080\n",
            "Epoch 23/100\n",
            "10/10 [==============================] - 1s 139ms/step - loss: 0.3482 - accuracy: 0.8252 - val_loss: 0.4424 - val_accuracy: 0.7995\n",
            "Epoch 24/100\n",
            "10/10 [==============================] - 1s 143ms/step - loss: 0.3406 - accuracy: 0.8348 - val_loss: 0.4393 - val_accuracy: 0.8116\n",
            "Epoch 25/100\n",
            "10/10 [==============================] - 1s 147ms/step - loss: 0.3429 - accuracy: 0.8300 - val_loss: 0.4426 - val_accuracy: 0.8080\n",
            "Epoch 26/100\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3279 - accuracy: 0.8442\n",
            "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
            "10/10 [==============================] - 1s 146ms/step - loss: 0.3296 - accuracy: 0.8441 - val_loss: 0.4761 - val_accuracy: 0.8116\n",
            "Epoch 27/100\n",
            "10/10 [==============================] - 2s 154ms/step - loss: 0.3292 - accuracy: 0.8381 - val_loss: 0.4768 - val_accuracy: 0.8031\n",
            "Epoch 28/100\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 0.3286 - accuracy: 0.8405 - val_loss: 0.4721 - val_accuracy: 0.8019\n",
            "Epoch 29/100\n",
            "10/10 [==============================] - 2s 155ms/step - loss: 0.3233 - accuracy: 0.8420 - val_loss: 0.4639 - val_accuracy: 0.7935\n",
            "Epoch 30/100\n",
            "10/10 [==============================] - 2s 177ms/step - loss: 0.3356 - accuracy: 0.8505 - val_loss: 0.4580 - val_accuracy: 0.7886\n",
            "Epoch 31/100\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3145 - accuracy: 0.8524\n",
            "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
            "10/10 [==============================] - 2s 172ms/step - loss: 0.3149 - accuracy: 0.8524 - val_loss: 0.4620 - val_accuracy: 0.7971\n",
            "Epoch 32/100\n",
            "10/10 [==============================] - 2s 181ms/step - loss: 0.3311 - accuracy: 0.8403 - val_loss: 0.4388 - val_accuracy: 0.8104\n",
            "Epoch 33/100\n",
            "10/10 [==============================] - 2s 178ms/step - loss: 0.3265 - accuracy: 0.8434 - val_loss: 0.4320 - val_accuracy: 0.8164\n",
            "Epoch 34/100\n",
            "10/10 [==============================] - 2s 180ms/step - loss: 0.3226 - accuracy: 0.8411 - val_loss: 0.4310 - val_accuracy: 0.8213\n",
            "Epoch 35/100\n",
            "10/10 [==============================] - 2s 180ms/step - loss: 0.3149 - accuracy: 0.8388 - val_loss: 0.4293 - val_accuracy: 0.8321\n",
            "Epoch 36/100\n",
            "10/10 [==============================] - 2s 170ms/step - loss: 0.3329 - accuracy: 0.8433 - val_loss: 0.4136 - val_accuracy: 0.8370\n",
            "Epoch 37/100\n",
            "10/10 [==============================] - 2s 180ms/step - loss: 0.3329 - accuracy: 0.8418 - val_loss: 0.4128 - val_accuracy: 0.8357\n",
            "Epoch 38/100\n",
            "10/10 [==============================] - 2s 176ms/step - loss: 0.3301 - accuracy: 0.8376 - val_loss: 0.4002 - val_accuracy: 0.8430\n",
            "Epoch 39/100\n",
            "10/10 [==============================] - 2s 181ms/step - loss: 0.3136 - accuracy: 0.8510 - val_loss: 0.3820 - val_accuracy: 0.8442\n",
            "Epoch 40/100\n",
            "10/10 [==============================] - 2s 178ms/step - loss: 0.3448 - accuracy: 0.8369 - val_loss: 0.3692 - val_accuracy: 0.8454\n",
            "Epoch 41/100\n",
            "10/10 [==============================] - 2s 180ms/step - loss: 0.3248 - accuracy: 0.8507 - val_loss: 0.3757 - val_accuracy: 0.8502\n",
            "Epoch 42/100\n",
            "10/10 [==============================] - 2s 192ms/step - loss: 0.3367 - accuracy: 0.8487 - val_loss: 0.3650 - val_accuracy: 0.8527\n",
            "Epoch 43/100\n",
            "10/10 [==============================] - 2s 184ms/step - loss: 0.3275 - accuracy: 0.8439 - val_loss: 0.3646 - val_accuracy: 0.8527\n",
            "Epoch 44/100\n",
            "10/10 [==============================] - 2s 191ms/step - loss: 0.3295 - accuracy: 0.8328 - val_loss: 0.3501 - val_accuracy: 0.8539\n",
            "Epoch 45/100\n",
            "10/10 [==============================] - 2s 186ms/step - loss: 0.3251 - accuracy: 0.8512 - val_loss: 0.3567 - val_accuracy: 0.8563\n",
            "Epoch 46/100\n",
            "10/10 [==============================] - 2s 188ms/step - loss: 0.3189 - accuracy: 0.8557 - val_loss: 0.3521 - val_accuracy: 0.8575\n",
            "Epoch 47/100\n",
            "10/10 [==============================] - 2s 202ms/step - loss: 0.3275 - accuracy: 0.8456 - val_loss: 0.3476 - val_accuracy: 0.8599\n",
            "Epoch 48/100\n",
            "10/10 [==============================] - 2s 195ms/step - loss: 0.3357 - accuracy: 0.8473 - val_loss: 0.3430 - val_accuracy: 0.8599\n",
            "Epoch 49/100\n",
            "10/10 [==============================] - 2s 209ms/step - loss: 0.3189 - accuracy: 0.8445 - val_loss: 0.3481 - val_accuracy: 0.8623\n",
            "Epoch 50/100\n",
            "10/10 [==============================] - 2s 216ms/step - loss: 0.3399 - accuracy: 0.8414 - val_loss: 0.3451 - val_accuracy: 0.8623\n",
            "Epoch 51/100\n",
            "10/10 [==============================] - 2s 209ms/step - loss: 0.3267 - accuracy: 0.8505 - val_loss: 0.3357 - val_accuracy: 0.8623\n",
            "Epoch 52/100\n",
            "10/10 [==============================] - 2s 206ms/step - loss: 0.3173 - accuracy: 0.8461 - val_loss: 0.3246 - val_accuracy: 0.8635\n",
            "Epoch 53/100\n",
            "10/10 [==============================] - 2s 209ms/step - loss: 0.3163 - accuracy: 0.8484 - val_loss: 0.3187 - val_accuracy: 0.8599\n",
            "Epoch 54/100\n",
            "10/10 [==============================] - 2s 205ms/step - loss: 0.3132 - accuracy: 0.8501 - val_loss: 0.3355 - val_accuracy: 0.8599\n",
            "Epoch 55/100\n",
            "10/10 [==============================] - 2s 230ms/step - loss: 0.3174 - accuracy: 0.8479 - val_loss: 0.3274 - val_accuracy: 0.8587\n",
            "Epoch 56/100\n",
            "10/10 [==============================] - 2s 210ms/step - loss: 0.3151 - accuracy: 0.8561 - val_loss: 0.3242 - val_accuracy: 0.8599\n",
            "Epoch 57/100\n",
            "10/10 [==============================] - 2s 214ms/step - loss: 0.3171 - accuracy: 0.8520 - val_loss: 0.3247 - val_accuracy: 0.8623\n",
            "Epoch 58/100\n",
            "10/10 [==============================] - 2s 218ms/step - loss: 0.3262 - accuracy: 0.8407 - val_loss: 0.3256 - val_accuracy: 0.8623\n",
            "Epoch 59/100\n",
            "10/10 [==============================] - 2s 228ms/step - loss: 0.3235 - accuracy: 0.8476 - val_loss: 0.3272 - val_accuracy: 0.8635\n",
            "Epoch 60/100\n",
            "10/10 [==============================] - 2s 222ms/step - loss: 0.3264 - accuracy: 0.8504 - val_loss: 0.3258 - val_accuracy: 0.8611\n",
            "Epoch 61/100\n",
            "10/10 [==============================] - 2s 232ms/step - loss: 0.3206 - accuracy: 0.8457 - val_loss: 0.3161 - val_accuracy: 0.8599\n",
            "Epoch 62/100\n",
            "10/10 [==============================] - 2s 223ms/step - loss: 0.3100 - accuracy: 0.8605 - val_loss: 0.3196 - val_accuracy: 0.8563\n",
            "Epoch 63/100\n",
            "10/10 [==============================] - 2s 230ms/step - loss: 0.3135 - accuracy: 0.8486 - val_loss: 0.3197 - val_accuracy: 0.8563\n",
            "Epoch 64/100\n",
            "10/10 [==============================] - 2s 238ms/step - loss: 0.3146 - accuracy: 0.8549 - val_loss: 0.3148 - val_accuracy: 0.8539\n",
            "Epoch 65/100\n",
            "10/10 [==============================] - 2s 230ms/step - loss: 0.3145 - accuracy: 0.8446 - val_loss: 0.3151 - val_accuracy: 0.8527\n",
            "Epoch 66/100\n",
            "10/10 [==============================] - 2s 236ms/step - loss: 0.3162 - accuracy: 0.8617 - val_loss: 0.3161 - val_accuracy: 0.8527\n",
            "Epoch 67/100\n",
            "10/10 [==============================] - 2s 233ms/step - loss: 0.3126 - accuracy: 0.8575 - val_loss: 0.3169 - val_accuracy: 0.8563\n",
            "Epoch 68/100\n",
            "10/10 [==============================] - 2s 244ms/step - loss: 0.3109 - accuracy: 0.8529 - val_loss: 0.3223 - val_accuracy: 0.8587\n",
            "Epoch 69/100\n",
            "10/10 [==============================] - 2s 244ms/step - loss: 0.3164 - accuracy: 0.8536 - val_loss: 0.3214 - val_accuracy: 0.8599\n",
            "Epoch 70/100\n",
            "10/10 [==============================] - 2s 243ms/step - loss: 0.3287 - accuracy: 0.8368 - val_loss: 0.3288 - val_accuracy: 0.8623\n",
            "Epoch 71/100\n",
            "10/10 [==============================] - 2s 246ms/step - loss: 0.3236 - accuracy: 0.8515 - val_loss: 0.3222 - val_accuracy: 0.8599\n",
            "Epoch 72/100\n",
            "10/10 [==============================] - 2s 243ms/step - loss: 0.3279 - accuracy: 0.8410 - val_loss: 0.3196 - val_accuracy: 0.8539\n",
            "Epoch 73/100\n",
            "10/10 [==============================] - 3s 254ms/step - loss: 0.3199 - accuracy: 0.8491 - val_loss: 0.3161 - val_accuracy: 0.8551\n",
            "Epoch 74/100\n",
            "10/10 [==============================] - 3s 255ms/step - loss: 0.3111 - accuracy: 0.8552 - val_loss: 0.3137 - val_accuracy: 0.8587\n",
            "Epoch 75/100\n",
            "10/10 [==============================] - 3s 251ms/step - loss: 0.3237 - accuracy: 0.8432 - val_loss: 0.3199 - val_accuracy: 0.8575\n",
            "Epoch 76/100\n",
            "10/10 [==============================] - 3s 258ms/step - loss: 0.3258 - accuracy: 0.8433 - val_loss: 0.3174 - val_accuracy: 0.8539\n",
            "Epoch 77/100\n",
            "10/10 [==============================] - 3s 259ms/step - loss: 0.3273 - accuracy: 0.8413 - val_loss: 0.3234 - val_accuracy: 0.8539\n",
            "Epoch 78/100\n",
            "10/10 [==============================] - 3s 258ms/step - loss: 0.3160 - accuracy: 0.8582 - val_loss: 0.3244 - val_accuracy: 0.8635\n",
            "Epoch 79/100\n",
            "10/10 [==============================] - 3s 263ms/step - loss: 0.3193 - accuracy: 0.8463 - val_loss: 0.3288 - val_accuracy: 0.8647\n",
            "Epoch 80/100\n",
            "10/10 [==============================] - 3s 266ms/step - loss: 0.3238 - accuracy: 0.8438 - val_loss: 0.3293 - val_accuracy: 0.8635\n",
            "Epoch 81/100\n",
            "10/10 [==============================] - 3s 266ms/step - loss: 0.3167 - accuracy: 0.8457 - val_loss: 0.3097 - val_accuracy: 0.8563\n",
            "Epoch 82/100\n",
            "10/10 [==============================] - 3s 274ms/step - loss: 0.3131 - accuracy: 0.8500 - val_loss: 0.3245 - val_accuracy: 0.8551\n",
            "Epoch 83/100\n",
            "10/10 [==============================] - 3s 274ms/step - loss: 0.3139 - accuracy: 0.8603 - val_loss: 0.3188 - val_accuracy: 0.8611\n",
            "Epoch 84/100\n",
            "10/10 [==============================] - 3s 276ms/step - loss: 0.3171 - accuracy: 0.8539 - val_loss: 0.3227 - val_accuracy: 0.8611\n",
            "Epoch 85/100\n",
            "10/10 [==============================] - 3s 284ms/step - loss: 0.3094 - accuracy: 0.8585 - val_loss: 0.3193 - val_accuracy: 0.8635\n",
            "Epoch 86/100\n",
            "10/10 [==============================] - 3s 282ms/step - loss: 0.3199 - accuracy: 0.8575 - val_loss: 0.3176 - val_accuracy: 0.8575\n",
            "Epoch 87/100\n",
            "10/10 [==============================] - 3s 287ms/step - loss: 0.3149 - accuracy: 0.8482 - val_loss: 0.3168 - val_accuracy: 0.8623\n",
            "Epoch 88/100\n",
            "10/10 [==============================] - 3s 283ms/step - loss: 0.2949 - accuracy: 0.8603 - val_loss: 0.3290 - val_accuracy: 0.8635\n",
            "Epoch 89/100\n",
            "10/10 [==============================] - 3s 293ms/step - loss: 0.3187 - accuracy: 0.8528 - val_loss: 0.3333 - val_accuracy: 0.8659\n",
            "Epoch 90/100\n",
            "10/10 [==============================] - 3s 292ms/step - loss: 0.3167 - accuracy: 0.8588 - val_loss: 0.3371 - val_accuracy: 0.8647\n",
            "Epoch 91/100\n",
            "10/10 [==============================] - 3s 291ms/step - loss: 0.3130 - accuracy: 0.8605 - val_loss: 0.3133 - val_accuracy: 0.8647\n",
            "Epoch 92/100\n",
            "10/10 [==============================] - 3s 300ms/step - loss: 0.3152 - accuracy: 0.8570 - val_loss: 0.3052 - val_accuracy: 0.8599\n",
            "Epoch 93/100\n",
            "10/10 [==============================] - 3s 302ms/step - loss: 0.3003 - accuracy: 0.8621 - val_loss: 0.3122 - val_accuracy: 0.8611\n",
            "Epoch 94/100\n",
            "10/10 [==============================] - 3s 305ms/step - loss: 0.3271 - accuracy: 0.8436 - val_loss: 0.3146 - val_accuracy: 0.8623\n",
            "Epoch 95/100\n",
            "10/10 [==============================] - 3s 301ms/step - loss: 0.3098 - accuracy: 0.8565 - val_loss: 0.3086 - val_accuracy: 0.8551\n",
            "Epoch 96/100\n",
            "10/10 [==============================] - 3s 308ms/step - loss: 0.3124 - accuracy: 0.8598 - val_loss: 0.3092 - val_accuracy: 0.8599\n",
            "Epoch 97/100\n",
            "10/10 [==============================] - 3s 308ms/step - loss: 0.3086 - accuracy: 0.8646 - val_loss: 0.3160 - val_accuracy: 0.8599\n",
            "Epoch 98/100\n",
            "10/10 [==============================] - 3s 305ms/step - loss: 0.3084 - accuracy: 0.8513 - val_loss: 0.3182 - val_accuracy: 0.8599\n",
            "Epoch 99/100\n",
            "10/10 [==============================] - 3s 314ms/step - loss: 0.3179 - accuracy: 0.8504 - val_loss: 0.3171 - val_accuracy: 0.8611\n",
            "Epoch 100/100\n",
            "10/10 [==============================] - 3s 313ms/step - loss: 0.3031 - accuracy: 0.8673 - val_loss: 0.3164 - val_accuracy: 0.8587\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmfkOF2pKQY2",
        "colab_type": "text"
      },
      "source": [
        "## **Convert to Estimator**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saCG2LaZaC39",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Serving function for external call\n",
        "def serving_fn():\n",
        "    feature_placeholders  = {'WERKS' : tf.placeholder(tf.string, [None]),\n",
        "            'SCENARIO' : tf.placeholder(tf.string, [None]),\n",
        "            'KTOKK' : tf.placeholder(tf.string, [None]),\n",
        "            'VSTATU' : tf.placeholder(tf.string, [None]),\n",
        "            'EKORG' : tf.placeholder(tf.string, [None]),\n",
        "            'EKGRP' : tf.placeholder(tf.string, [None]),\n",
        "            'VPATD' : tf.placeholder(tf.float32, [None]),\n",
        "            'TOTGRQTY' : tf.placeholder(tf.float32, [None]),\n",
        "            'TOTIRQTY' : tf.placeholder(tf.float32, [None]),\n",
        "            'NODLGR' : tf.placeholder(tf.float32, [None]),\n",
        "            'NODLIR' : tf.placeholder(tf.float32, [None]),\n",
        "            'DIFGRIRD' : tf.placeholder(tf.float32, [None]),\n",
        "            'DIFGRIRV' : tf.placeholder(tf.float32, [None])\n",
        "    }\n",
        "\n",
        "    #Features with transformation logic\n",
        "    features = {\n",
        "                key: tf.expand_dims(tensor, -1)\n",
        "                for key, tensor in feature_placeholders.items()\n",
        "            }\n",
        "    \n",
        "    #feat_changed = add_engineered(features.copy())\n",
        "    return tf.estimator.export.ServingInputReceiver(feature_engg_features(features), feature_placeholders )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyO4MoeRK-nk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create estimator train and evaluate function\n",
        "def est_train_and_evaluate(keras_model, output_dir, num_train_steps, train_file, eval_file):    \n",
        "    run_config = tf.estimator.RunConfig(save_checkpoints_secs = 40, \n",
        "                                        keep_checkpoint_max = 10)\n",
        "    \n",
        "    #Convert Keras model to TF estimator\n",
        "    keras_model.compile()\n",
        "    estimator = tf.keras.estimator.model_to_estimator(keras_model=keras_model, config=run_config)\n",
        "\n",
        "    train_spec = tf.estimator.TrainSpec(input_fn =  make_input_fn(filename = train_file,\n",
        "                                                    mode = tf.estimator.ModeKeys.TRAIN,\n",
        "                                                    batch_size = 512),\n",
        "                                        max_steps = num_train_steps)\n",
        "    \n",
        "    #Create exporter\n",
        "    # exp = tf.estimator.LatestExporter(\"decision\", serving_fn)\n",
        "    eval_spec = tf.estimator.EvalSpec(input_fn =    make_input_fn(filename = eval_file,\n",
        "                                                    mode = tf.estimator.ModeKeys.TRAIN,\n",
        "                                                    batch_size = 512),\n",
        "                                      steps = None, \n",
        "                                      # exporters = exp,\n",
        "                                      start_delay_secs = 20, # start evaluating after N seconds, \n",
        "                                      throttle_secs = 45)  # evaluate every N seconds\n",
        "\n",
        "                                \n",
        "    tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcbhO99SMWbo",
        "colab_type": "code",
        "outputId": "490d4e89-5b27-4715-fbbc-661f3c34e142",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#tf.logging.set_verbosity(tf.logging.WARN)\n",
        "train_file = \"train*.csv\"\n",
        "eval_file = \"test*.csv\"\n",
        "\n",
        "est_train_and_evaluate(m_, None, 20000, train_file, eval_file)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp9ratcs23\n",
            "INFO:tensorflow:Using the Keras model provided.\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp9ratcs23', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 40, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 10, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f342fa6cc88>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "INFO:tensorflow:Not using Distribute Coordinator.\n",
            "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
            "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 40.\n",
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-b888ec96fac4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0meval_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"test*.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mest_train_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-63-5309bc8ca4b3>\u001b[0m in \u001b[0;36mest_train_and_evaluate\u001b[0;34m(keras_model, output_dir, num_train_steps, train_file, eval_file)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(estimator, train_spec, eval_spec)\u001b[0m\n\u001b[1;32m    471\u001b[0m         '(with task id 0).  Given task id {}'.format(config.task_id))\n\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    611\u001b[0m         config.task_type != run_config_lib.TaskType.EVALUATOR):\n\u001b[1;32m    612\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Running training and evaluation locally (non-distributed).'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 613\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_local\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m     \u001b[0;31m# Distributed case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\u001b[0m in \u001b[0;36mrun_local\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0mmax_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m         \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_hooks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 714\u001b[0;31m         saving_listeners=saving_listeners)\n\u001b[0m\u001b[1;32m    715\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m     eval_result = listener_for_eval.eval_result or _EvalResult(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1158\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1160\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1188\u001b[0m       \u001b[0mworker_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1189\u001b[0m       estimator_spec = self._call_model_fn(\n\u001b[0;32m-> 1190\u001b[0;31m           features, labels, ModeKeys.TRAIN, self.config)\n\u001b[0m\u001b[1;32m   1191\u001b[0m       \u001b[0mglobal_step_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_global_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_call_model_fn\u001b[0;34m(self, features, labels, mode, config)\u001b[0m\n\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Calling model_fn.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1148\u001b[0;31m     \u001b[0mmodel_fn_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1149\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done calling model_fn.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/keras.py\u001b[0m in \u001b[0;36mmodel_fn\u001b[0;34m(features, labels, mode)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m         optimizer_config=optimizer_config)\n\u001b[0m\u001b[1;32m    289\u001b[0m     \u001b[0mmodel_output_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0;31m# We need to make sure that the output names of the last layer in the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/keras.py\u001b[0m in \u001b[0;36m_clone_and_build_model\u001b[0;34m(mode, keras_model, custom_objects, features, labels, optimizer_config)\u001b[0m\n\u001b[1;32m    209\u001b[0m   \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_learning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m   input_tensors, target_tensors, sample_weight_tensors = (\n\u001b[0;32m--> 211\u001b[0;31m       _convert_estimator_io_to_keras(keras_model, features, labels))\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m   \u001b[0mcompile_clone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/keras.py\u001b[0m in \u001b[0;36m_convert_estimator_io_to_keras\u001b[0;34m(keras_model, features, labels)\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;31m# converting input tensors into sorted list.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     input_tensors = _to_ordered_tensor_list(features, input_names, 'features',\n\u001b[0;32m--> 167\u001b[0;31m                                             'inputs')\n\u001b[0m\u001b[1;32m    168\u001b[0m   target_tensors = _to_ordered_tensor_list(\n\u001b[1;32m    169\u001b[0m       labels, output_names, 'labels', 'outputs')\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/keras.py\u001b[0m in \u001b[0;36m_to_ordered_tensor_list\u001b[0;34m(obj, key_order, obj_name, order_name)\u001b[0m\n\u001b[1;32m    138\u001b[0m                 \u001b[0morder_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0mobj_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m                 different_keys=different_keys))\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_convert_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkey_order\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"The dictionary passed into features does not have the expected inputs keys defined in the keras model.\\n\\tExpected keys: {'input_5', 'input_9', 'input_12', 'input_4', 'input_8', 'input_10', 'input_14', 'input_6', 'input_3', 'input_13', 'input_7', 'input_1', 'input_2', 'input_11'}\\n\\tfeatures keys: {'WERKS', 'TOTIRQTY', 'DIFGRIRV', 'VPATD', 'VSTATU', 'grminusirbyvpatd', 'EKORG', 'DIFGRIRD', 'EKGRP', 'TOTGRQTY', 'KTOKK', 'NODLIR', 'SCENARIO', 'NODLGR'}\\n\\tDifference: {'WERKS', 'input_5', 'DIFGRIRV', 'input_14', 'input_1', 'input_2', 'SCENARIO', 'input_10', 'grminusirbyvpatd', 'DIFGRIRD', 'input_3', 'KTOKK', 'input_7', 'input_8', 'input_9', 'NODLGR', 'TOTIRQTY', 'input_12', 'VPATD', 'input_4', 'input_11', 'VSTATU', 'input_6', 'EKORG', 'EKGRP', 'TOTGRQTY', 'input_13', 'NODLIR'}\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tiD6r356MnCN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}