{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py3env/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "usage: task.py [-h] --input_path_train INPUT_PATH_TRAIN --input_path_eval\n",
      "               INPUT_PATH_EVAL --output_dir OUTPUT_DIR\n",
      "               [--batch_size BATCH_SIZE] [--job-dir JOB_DIR]\n",
      "               [--train_examples TRAIN_EXAMPLES]\n",
      "               [--local_or_cmle LOCAL_OR_CMLE] [--eval_steps EVAL_STEPS]\n",
      "task.py: error: the following arguments are required: --output_dir\n",
      "bash: line 6: --output_dir=\\train_cache\\: command not found\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "python -m trainer.task \\\n",
    "--local_or_cmle=\"local\" \\\n",
    "--input_path_train=\"\\*train*.csv\" \\\n",
    "--input_path_eval=\"\\*eval*.csv\" \\  \n",
    "--output_dir=\"\\train_cache\\\\\" \\\n",
    "--job-dir=./tmp \\\n",
    "--train_examples=1 \\\n",
    "--eval_steps=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will train for 781.25 steps using batch_size=128\n",
      "Output path:   gs://arya_ml_storage/train_cache\n",
      "Train path:   gs://arya_ml_storage/*train*.csv\n",
      "Eval path:   gs://arya_ml_storage/*eval*.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py3env/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "INFO:tensorflow:TF_CONFIG environment variable: {'task': {}, 'environment': 'cloud', 'cluster': {}, 'job': {'job_name': 'trainer.task', 'args': ['--local_or_cmle=cmle', '--input_path_train=gs://arya_ml_storage/*train*.csv', '--input_path_eval=gs://arya_ml_storage/*eval*.csv', '--output_dir=gs://arya_ml_storage/train_cache', '--train_examples=100', '--eval_steps=1', '--job-dir', 'gs://arya_ml_storage/train_cache']}}\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'gs://arya_ml_storage/train_cache', '_keep_checkpoint_every_n_hours': 10000, '_save_checkpoints_steps': None, '_is_chief': True, '_service': None, '_num_worker_replicas': 1, '_session_config': None, '_global_id_in_cluster': 0, '_num_ps_replicas': 0, '_tf_random_seed': None, '_evaluation_master': '', '_keep_checkpoint_max': 5, '_log_step_count_steps': 100, '_task_type': 'worker', '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f14475060b8>, '_save_summary_steps': 100, '_train_distribute': None, '_master': '', '_save_checkpoints_secs': 600}\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after 45 secs (eval_spec.throttle_secs) or training is finished.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "2018-10-30 16:27:42.380338: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into gs://arya_ml_storage/train_cache/model.ckpt.\n",
      "INFO:tensorflow:step = 1, loss = 9495.217\n",
      "INFO:tensorflow:global_step/sec: 43.4119\n",
      "INFO:tensorflow:step = 101, loss = 77.03343 (2.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 60.148\n",
      "INFO:tensorflow:step = 201, loss = 77.64717 (1.662 sec)\n",
      "INFO:tensorflow:global_step/sec: 59.4644\n",
      "INFO:tensorflow:step = 301, loss = 77.28481 (1.682 sec)\n",
      "INFO:tensorflow:global_step/sec: 62.5684\n",
      "INFO:tensorflow:step = 401, loss = 70.84716 (1.598 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.8597\n",
      "INFO:tensorflow:step = 501, loss = 64.5405 (1.542 sec)\n",
      "INFO:tensorflow:global_step/sec: 61.7644\n",
      "INFO:tensorflow:step = 601, loss = 69.47203 (1.619 sec)\n",
      "INFO:tensorflow:global_step/sec: 62.5686\n",
      "INFO:tensorflow:step = 701, loss = 81.165985 (1.598 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 782 into gs://arya_ml_storage/train_cache/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 75.046326.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-10-30-16:28:16\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from gs://arya_ml_storage/train_cache/model.ckpt-782\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2018-10-30-16:28:18\n",
      "INFO:tensorflow:Saving dict for global step 782: accuracy = 0.5703125, accuracy_baseline = 0.765625, auc = 0.91972786, auc_precision_recall = 0.6639327, average_loss = 0.7034751, global_step = 782, label/mean = 0.234375, loss = 90.044815, precision = 0.3529412, prediction/mean = 0.5859246, recall = 1.0\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO:tensorflow:'serving_default' : Classification input must be a single string Tensor; got {'VPATD': <tf.Tensor 'Placeholder_6:0' shape=(?,) dtype=float32>, 'TOTIRQTY': <tf.Tensor 'Placeholder_8:0' shape=(?,) dtype=float32>, 'EKGRP': <tf.Tensor 'Placeholder_5:0' shape=(?,) dtype=string>, 'DIFGRIRD': <tf.Tensor 'Placeholder_11:0' shape=(?,) dtype=float32>, 'NODLGR': <tf.Tensor 'Placeholder_9:0' shape=(?,) dtype=float32>, 'VSTATU': <tf.Tensor 'Placeholder_3:0' shape=(?,) dtype=string>, 'SCENARIO': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=string>, 'EKORG': <tf.Tensor 'Placeholder_4:0' shape=(?,) dtype=string>, 'WERKS': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=string>, 'KTOKK': <tf.Tensor 'Placeholder_2:0' shape=(?,) dtype=string>, 'NODLIR': <tf.Tensor 'Placeholder_10:0' shape=(?,) dtype=float32>, 'TOTGRQTY': <tf.Tensor 'Placeholder_7:0' shape=(?,) dtype=float32>, 'DIFGRIRV': <tf.Tensor 'Placeholder_12:0' shape=(?,) dtype=float32>}\n",
      "INFO:tensorflow:'regression' : Regression input must be a single string Tensor; got {'VPATD': <tf.Tensor 'Placeholder_6:0' shape=(?,) dtype=float32>, 'TOTIRQTY': <tf.Tensor 'Placeholder_8:0' shape=(?,) dtype=float32>, 'EKGRP': <tf.Tensor 'Placeholder_5:0' shape=(?,) dtype=string>, 'DIFGRIRD': <tf.Tensor 'Placeholder_11:0' shape=(?,) dtype=float32>, 'NODLGR': <tf.Tensor 'Placeholder_9:0' shape=(?,) dtype=float32>, 'VSTATU': <tf.Tensor 'Placeholder_3:0' shape=(?,) dtype=string>, 'SCENARIO': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=string>, 'EKORG': <tf.Tensor 'Placeholder_4:0' shape=(?,) dtype=string>, 'WERKS': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=string>, 'KTOKK': <tf.Tensor 'Placeholder_2:0' shape=(?,) dtype=string>, 'NODLIR': <tf.Tensor 'Placeholder_10:0' shape=(?,) dtype=float32>, 'TOTGRQTY': <tf.Tensor 'Placeholder_7:0' shape=(?,) dtype=float32>, 'DIFGRIRV': <tf.Tensor 'Placeholder_12:0' shape=(?,) dtype=float32>}\n",
      "INFO:tensorflow:'classification' : Classification input must be a single string Tensor; got {'VPATD': <tf.Tensor 'Placeholder_6:0' shape=(?,) dtype=float32>, 'TOTIRQTY': <tf.Tensor 'Placeholder_8:0' shape=(?,) dtype=float32>, 'EKGRP': <tf.Tensor 'Placeholder_5:0' shape=(?,) dtype=string>, 'DIFGRIRD': <tf.Tensor 'Placeholder_11:0' shape=(?,) dtype=float32>, 'NODLGR': <tf.Tensor 'Placeholder_9:0' shape=(?,) dtype=float32>, 'VSTATU': <tf.Tensor 'Placeholder_3:0' shape=(?,) dtype=string>, 'SCENARIO': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=string>, 'EKORG': <tf.Tensor 'Placeholder_4:0' shape=(?,) dtype=string>, 'WERKS': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=string>, 'KTOKK': <tf.Tensor 'Placeholder_2:0' shape=(?,) dtype=string>, 'NODLIR': <tf.Tensor 'Placeholder_10:0' shape=(?,) dtype=float32>, 'TOTGRQTY': <tf.Tensor 'Placeholder_7:0' shape=(?,) dtype=float32>, 'DIFGRIRV': <tf.Tensor 'Placeholder_12:0' shape=(?,) dtype=float32>}\n",
      "WARNING:tensorflow:Export includes no default signature!\n",
      "INFO:tensorflow:Restoring parameters from gs://arya_ml_storage/train_cache/model.ckpt-782\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b\"gs://arya_ml_storage/train_cache/export/decision/temp-b'1540916901'/saved_model.pb\"\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "gcloud ml-engine local train --module-name trainer.task \\\n",
    "    --package-path trainer \\\n",
    "    --job-dir=gs://arya_ml_storage/train_cache \\\n",
    "    -- \\\n",
    "    --local_or_cmle=cmle \\\n",
    "    --input_path_train=gs://arya_ml_storage/*train*.csv \\\n",
    "    --input_path_eval=gs://arya_ml_storage/*eval*.csv \\\n",
    "    --output_dir=gs://arya_ml_storage/train_cache \\\n",
    "    --train_examples=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jobId: test_hasan_cmle_train3\n",
      "state: QUEUED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job [test_hasan_cmle_train3] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs describe test_hasan_cmle_train3\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs stream-logs test_hasan_cmle_train3\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "gcloud ml-engine jobs submit training 'test_hasan_cmle_train3' \\\n",
    "    --module-name trainer.task \\\n",
    "    --package-path trainer \\\n",
    "    --region us-central1 \\\n",
    "    --job-dir=gs://grir_ml_serving/data/train_jobdir \\\n",
    "    --runtime-version 1.4 \\\n",
    "    -- \\\n",
    "    --local_or_cmle=cmle \\\n",
    "    --input_path_train=gs://grir_ml_serving/data/*train*.csv \\\n",
    "    --input_path_eval=gs://grir_ml_serving/data/*eval*.csv \\\n",
    "    --output_dir=gs://grir_ml_serving/data/train_output \\\n",
    "    --train_examples=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>TensorBoard was started successfully with pid 4765. Click <a href=\"/_proxy/59485/\" target=\"_blank\">here</a> to access it.</p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "4765"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.datalab.ml import TensorBoard\n",
    "TensorBoard().start('gs://grir_ml_serving/data/train_output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopped TensorBoard with pid 4765\n"
     ]
    }
   ],
   "source": [
    "for pid in TensorBoard.list()['pid']:\n",
    "  TensorBoard().stop(pid)\n",
    "  print('Stopped TensorBoard with pid {}'.format(pid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
