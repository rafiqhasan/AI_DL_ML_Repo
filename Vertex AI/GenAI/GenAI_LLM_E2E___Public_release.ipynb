{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quaLl3PXpEWf"
      },
      "source": [
        "# Vertex SDK LLM Usage\n",
        "\n",
        "**Comprehensive Tutorial for using Vertex GenAI SDK**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhZ9jqg5qu1p"
      },
      "source": [
        "# Authenticating"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E4pQ6E_xpfmp"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth as google_auth\n",
        "google_auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eb6Pw6rNqrdx"
      },
      "source": [
        "# Installing the package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NQ6SdFxji8ks"
      },
      "outputs": [],
      "source": [
        "!pip install google-cloud-aiplatform --upgrade --user"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTVPxOKh1l-i"
      },
      "source": [
        "#### ! ^^^^ Do not forget to click the \"Restart runtime\" button above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pN1p1xEqp4fI"
      },
      "source": [
        "# Authenticating again"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hD8yqHHv1k3R"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth as google_auth\n",
        "google_auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V_lJmgNRrQz4"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = \"\"  # @param {type:\"string\"}\n",
        "LOCATION = \"\"  # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oiraqRwdooE0"
      },
      "outputs": [],
      "source": [
        "from google.cloud import aiplatform\n",
        "from vertexai.preview.language_models import TextGenerationModel, ChatModel\n",
        "\n",
        "aiplatform.init(project=PROJECT_ID, location=LOCATION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCriCYpOjZv0"
      },
      "source": [
        "# Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fkAkKn-ijJR5"
      },
      "outputs": [],
      "source": [
        "from vertexai.preview.language_models import TextGenerationModel\n",
        "\n",
        "model = TextGenerationModel.from_pretrained(\"text-bison@001\")\n",
        "\n",
        "print(model.predict(\n",
        "    \"What do you know about the universe?\",\n",
        "    # Optional:\n",
        "    #max_output_tokens=128,\n",
        "    #temperature=0,\n",
        "    #top_p=1,\n",
        "    #top_k=5,\n",
        "))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wl2AZceWjXoy"
      },
      "source": [
        "# Chat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_vLprtHAjNOO"
      },
      "outputs": [],
      "source": [
        "from vertexai.preview.language_models import ChatModel, InputOutputTextPair\n",
        "\n",
        "model = ChatModel.from_pretrained(\"chat-bison@001\")\n",
        "\n",
        "parameters = {\n",
        "    \"temperature\": 0.2,\n",
        "    \"max_output_tokens\": 256,\n",
        "    \"top_p\": 0.95,\n",
        "    \"top_k\": 40,\n",
        "    }\n",
        "\n",
        "memory = model.start_chat(\n",
        "    context=\"Your name is Miles and you are an astronomical chatbot and have knowledge about the solar system. You can only respond to queries of space, universe and not other topics\",\n",
        "    examples=[\n",
        "        InputOutputTextPair(\n",
        "            input_text='How many moons does Mars have?',\n",
        "            output_text='The planet Mars has two moons, Phobos and Deimos.',\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "\n",
        "def chat(memory, msg = \"Hello\"):\n",
        "    response = memory.send_message(msg, **parameters)\n",
        "    print(f\"Response from Model: {response.text}\")\n",
        "\n",
        "chat(memory, msg = \"Hello, my name is Hasan\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat(memory, msg = \"so what is your name\")"
      ],
      "metadata": {
        "id": "ryxUcaL4uJ6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat(memory, msg = \"and who am I ?\")"
      ],
      "metadata": {
        "id": "1j3zYd8yyAVb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text embedding"
      ],
      "metadata": {
        "id": "tmWzgmkUzgzU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from vertexai.preview.language_models import TextEmbeddingModel\n",
        "\n",
        "model = TextEmbeddingModel.from_pretrained(\"textembedding-gecko@001\")\n",
        "embeddings = model.get_embeddings([\"What is life?\"])\n",
        "for embedding in embeddings:\n",
        "    vector = embedding.values\n",
        "    print(len(vector))"
      ],
      "metadata": {
        "id": "Eara9dykkJTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dt6Cyr9B0ZOT"
      },
      "source": [
        "# Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WxmUoYfC0aJI"
      },
      "outputs": [],
      "source": [
        "from vertexai.preview.language_models import TextGenerationModel\n",
        "\n",
        "model3 = TextGenerationModel.from_pretrained(\"text-bison@001\")\n",
        "\n",
        "model3.list_tuned_model_names()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bb4HhsLc0ha4"
      },
      "outputs": [],
      "source": [
        "model3.tune_model(\n",
        "    training_data=\"gs://<GCS bucket>/examples.jsonl\",\n",
        "    # Optional:\n",
        "    train_steps=1,\n",
        "    tuning_job_location=\"europe-west4\",\n",
        "    tuned_model_location=\"us-central1\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xf7tWnMU03ZY"
      },
      "outputs": [],
      "source": [
        "print(model3.predict(\"What is your name?\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7UqoxmAd28QZ"
      },
      "outputs": [],
      "source": [
        "model3.list_tuned_model_names()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uB7RC4Sd2-vK"
      },
      "outputs": [],
      "source": [
        "tuned_model4 = model3.get_tuned_model(tuned_model_name=model3.list_tuned_model_names()[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "asNjLVy47_Ox"
      },
      "outputs": [],
      "source": [
        "print(tuned_model4.predict(\"What is your name?\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wai6L3fQowJ_"
      },
      "source": [
        "## Tuning from Pandas DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lUsZKDS3nIcJ"
      },
      "outputs": [],
      "source": [
        "import pandas\n",
        "\n",
        "training_data = pandas.DataFrame(data=[\n",
        "    {\"input_text\": \"Input 1\", \"output_text\": \"Output 1\"},\n",
        "    {\"input_text\": \"Input 2\", \"output_text\": \"Output 2\"},\n",
        "    {\"input_text\": \"Input 3\", \"output_text\": \"Output 3\"},\n",
        "    {\"input_text\": \"Input 4\", \"output_text\": \"Output 4\"},\n",
        "    {\"input_text\": \"Input 5\", \"output_text\": \"Output 5\"},\n",
        "    {\"input_text\": \"Input 6\", \"output_text\": \"Output 6\"},\n",
        "    {\"input_text\": \"Input 7\", \"output_text\": \"Output 7\"},\n",
        "    {\"input_text\": \"Input 8\", \"output_text\": \"Output 8\"},\n",
        "    {\"input_text\": \"Input 9\", \"output_text\": \"Output 9\"},\n",
        "    {\"input_text\": \"Input 10\", \"output_text\": \"Output 10\"},\n",
        "])\n",
        "\n",
        "training_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RMReD76mnAOC"
      },
      "outputs": [],
      "source": [
        "model4 = TextGenerationModel.from_pretrained(\"text-bison@001\")\n",
        "\n",
        "model4.tune_model(\n",
        "    training_data=training_data,\n",
        "    # Optional:\n",
        "    train_steps=10,\n",
        "    tuning_job_location=\"europe-west4\",\n",
        "    tuned_model_location=\"us-central1\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KWCaCpTDnL1h"
      },
      "outputs": [],
      "source": [
        "print(model4.predict(\"Hello input\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TXM72tWEtW_V"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
